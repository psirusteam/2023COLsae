
# Día 1 - Sesión 2- Censo e información satelital

```{r setup, include=FALSE, message=FALSE, error=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE)
# Paquete que trae funciones útiles para R Markdown
library(printr)
library(kableExtra)
library(knitr)                              
# Paquete que trae varios paquetes comunes en el tidyverse
library(tidyverse)                          
# Paquete que GTMmite compilar python desde R
library(reticulate)
# Paquete que nos GTMmite conectar con Google Earth Engine desde R
library(rgee)
# Paquete para la lectura de Shapefile
library(geojsonio)
library(sf)

tba <- function(dat, cap = NA){
  kable(dat,
      format = "html", digits =  4,
      caption = cap) %>% 
     kable_styling(bootstrap_options = "striped", full_width = TRUE)%>%
         kable_classic(full_width = TRUE, html_font = "Arial Narrow")
}

```

## Uso de imágenes satelitales y SAE

Uno de los artículo pioneros de estimación de áreas pequeñas fue el artículo de Singh, R, et. al. (2002) el cual abordó la estimación del rendimiento de cultivos para los tehsil (unidad subadministrativa)  del distriyo Rohtak district en Haryana (India). 


Las imágenes raster representan el mundo mediante un conjunto de celdas contiguas igualmente espaciadas conocidas como pixeles, estas imágenes tienen información como un sistema de información geográfico, Un sistema de referencia de coordenadas. Las imágenes almacenan un identificador, un valor en cada pixel (o un vector con diferentes valores) y cada celda tiene asociada una escala de colores.

Las imágenes pueden obtenerse crudas y procesadas, estas primeras contienen solamente las capas de colores, las segundas contienen también valores que han sido procesados en cada celda (índices de vegetación, intensidad lumínica, tipo de vegetación). 

La información cruda puede utilizarse para entrenar características que se desean entrenar (carreteras, tipo de cultivo, bosque / no bosque), afortunadamente en Google Earth Engine encontramos muchos indicadores  procesadas asociadas a un pixel. Estos indicadores pueden agregarse a nivel de un área geográfica.


### Fuentes de datos de imágenes satelitales

Algunas de las principales fuentes de imágenes satelitales son: 

  * http://earthexplorer.usgs.gov/

  * https://lpdaacsvc.cr.usgs.gov/appeears/

  * https://search.earthdata.nasa.gov/search

  * https://scihub.coGTMnicus.eu/

  * https://aws.amazon.com/public-data-sets/landsat/

Sin embargo la mayor parte de estas fuentes están centralizadas en **Google Earth Engine** que permite buscar fuentes de datos provenientes de imágenes satelitales. GEE se puede manejar por medio de APIS en diferentes lenguajes de programación: Javascript (por defecto), Python y R (paquete rgee).



## Google Earth Eninge


Crear una cuenta en [link](https://earthengine.google.com/), una vez que se ingrese a la cuenta puede buscarse los conjuntos de datos de interés:

```{r echo=FALSE, out.width = "500px", out.height="250px",fig.align='center'}
knitr::include_graphics("0Recursos/lights.png")
```


* Una vez se busque el conjunto de datos se puede abrir un editor de código brindado por google en  Javascript. 

*  Copiar y pegar la sintaxis que brinda el buscador de conjunto de datos para visualizar la imagen raster y disponer de sentencias que GTMmitan la obtención  del conjunto de datos de interés posteriormente en R

```{r echo=FALSE, out.width = "500px", out.height="250px",fig.align='center'}
knitr::include_graphics("0Recursos/query.png")
```

## Instalación de rgee

*  Descargar e instalar anaconda o conda. (<https://www.anaconda.com/products/individual>)

*  Abrir Anaconda prompt y configurar ambiente de trabajo (ambiente python rgee_py) con las siguientes sentencias:

```{python, echo=TRUE, eval=FALSE}
conda create -n rgee_py python=3.9
activate rgee_py
pip install google-api-python-client
pip install earthengine-api
pip install numpy
```

*  Listar los ambientes de Python disponibles en anaconda prompt

```{python, echo=TRUE, eval=FALSE}
conda env list
```


*   Una vez identificado la ruta del ambiente ambiente rgee_py definirla en R (**no se debe olvidar cambiar \\ por /**). 
*   Instalar `reticulate` y `rgee`, cargar paquetes para procesamiento espacial y configurar el ambiente de trabajo como sigue:

```{r, echo=TRUE, eval = FALSE}
library(reticulate) # Conexión con Python
library(rgee) # Conexión con Google Earth Engine
library(sf) # Paquete para manejar datos geográficos
library(dplyr) # Paquete para procesamiento de datos

rgee_environment_dir = "C://Users//sguerrero//Anaconda3//envs//rgee_py//python.exe"

# Configurar python (Algunas veces no es detectado y se debe reiniciar R)
reticulate::use_python(rgee_environment_dir, required=T)

rgee::ee_install_set_pyenv(py_path = rgee_environment_dir, py_env = "rgee_py")

Sys.setenv(RETICULATE_PYTHON = rgee_environment_dir)
Sys.setenv(EARTHENGINE_PYTHON = rgee_environment_dir)
```

*  Una vez configurado el ambiente puede iniciarlizarse una sesión de Google Earth Engine como sigue:

```{r, eval=FALSE}
rgee::ee_Initialize(drive = T)
```
```{r, echo=FALSE}
include_graphics("0Recursos/Figura1_001.PNG")
```


**Notas:** 

-   Se debe inicializar cada sesión con el comando `rgee::ee_Initialize(drive = T)`. 

-   Los comandos de javascript que invoquen métodos con "." se sustituyen por signo peso ($), por ejemplo:

```{r,eval=FALSE}
ee.ImageCollection().filterDate()  # Javascript
ee$ImageCollection()$filterDate()  # R
```

### Descargar información satelital

*   **Paso 1**: disponer de los shapefile 

```{r}
# shape <- read_sf("Shape/COL_dam2.shp")
shape <- read_sf("Shape/COL.shp")
plot(shape["geometry"])
```

*   **Paso 2**: Seleccionar el archivo de imágenes  que desea procesar, para nuestro ejemplo **luces nocturnas**.  

```{r, eval = FALSE}
luces <- ee$ImageCollection("NOAA/DMSP-OLS/NIGHTTIME_LIGHTS") %>%
  ee$ImageCollection$filterDate("2013-01-01", "2014-01-01") %>%
  ee$ImageCollection$map(function(x) x$select("stable_lights")) %>%
  ee$ImageCollection$toBands()

```

* **Paso 3**: Descargar la información

```{r, eval=FALSE}
## Tiempo 10 minutos 
shape_luces <- map(unique(shape$dam),
                 ~tryCatch(ee_extract(
                   x = luces,
                   y = shape["dam"] %>% filter(dam == .x),
                   ee$Reducer$mean(),
                   sf = FALSE
                 ) %>% mutate(dam = .x),
                 error = function(e)data.frame(dam = .x)))

shape_luces %<>% bind_rows()

tba(shape_luces, cap = "Promedio de luces nocturnasa")
```

Repetir la rutina para: 

-   Tipo de suelo: **crops-coverfraction** (Porcentaje de cubrimiento cultivos) y **urban-coverfraction** (Porcentaje de cobertura urbana) disponibles en <https://develoGTMs.google.com/earth-engine/datasets/catalog/COGTMNICUS_Landcover_100m_Proba-V-C3_Global#description> 


- Tiempo de viaje al hospital o clínica más cercana (**accessibility**) y tiempo de viaje al hospital o clínica más cercana utilizando transporte no motorizado (**accessibility_walking_only**) información disponible en <https://develoGTMs.google.com/earth-engine/datasets/catalog/Oxford_MAP_accessibility_to_healthcare_2019> 

- Modificación humana, donde se consideran los asentamiento humano, la agricultura, el transporte, la minería y producción de energía e infraestructura eléctrica. En el siguiente link encuentra la información satelital  <https://develoGTMs.google.com/earth-engine/datasets/catalog/CSP_HM_GlobalHumanModification#description>


* **Paso 4**  consolidar la información. 

```{r, eval=TRUE, echo=FALSE}
predictors_satelital <-
  readRDS("Data/predictors_satelital_dam.rds")

tba(head(predictors_satelital, 10))
```

Los resultados se muestran en los siguientes mapas

```{r, echo=FALSE}
temp <- inner_join(shape["dam"], predictors_satelital) 
```

### Luces nocturnas 

```{r echo=FALSE, out.width = "500px", out.height="350px",fig.align='center'}
knitr::include_graphics("0Recursos/luces_nocturnas.png")
```


```{r echo=FALSE, out.width = "850px", out.height="550px",fig.align='center'}
plot(
    temp["luces_nocturnas"], 
       key.pos = 4, 
       breaks = quantile(temp$luces_nocturnas))
```

### Cubrimiento cultivos 

```{r echo=FALSE, out.width = "500px", out.height="350px",fig.align='center'}
knitr::include_graphics("0Recursos/suelo_cultivos.png")
```


```{r echo=FALSE, out.width = "850px", out.height="550px",fig.align='center'}
plot(
    temp["cubrimiento_cultivo"], 
       key.pos = 4, 
       breaks = quantile(temp$cubrimiento_cultivo))
```

### Cubrimiento urbanos

```{r echo=FALSE, out.width = "500px", out.height="350px",fig.align='center'}
knitr::include_graphics("0Recursos/suelo_urbanos.png")
```


```{r echo=FALSE, out.width = "850px", out.height="550px",fig.align='center'}
plot(
    temp["cubrimiento_urbano"], 
       key.pos = 4, 
       breaks = quantile(temp$cubrimiento_urbano))
```

### Modificación humana 

```{r echo=FALSE, out.width = "500px", out.height="350px",fig.align='center'}
knitr::include_graphics("0Recursos/modifica_humana.png")
```


```{r echo=FALSE, out.width = "850px", out.height="550px",fig.align='center'}
plot(
    temp["modificacion_humana"], 
       key.pos = 4, 
       breaks = quantile(temp$modificacion_humana))
```

### Tiempo promedio al hospital 

```{r echo=FALSE, out.width = "500px", out.height="350px",fig.align='center'}
knitr::include_graphics("0Recursos/tiempo_hospital.png")
```

```{r echo=FALSE, out.width = "850px", out.height="550px",fig.align='center'}
plot(
    temp["accesibilidad_hospitales"], 
       key.pos = 4, 
       breaks = quantile(temp$accesibilidad_hospitales))
```

### Tiempo promedio al hospital en vehiculo no motorizado

```{r echo=FALSE, out.width = "500px", out.height="350px",fig.align='center'}
knitr::include_graphics("0Recursos/tiempo_hospital_no_motor.png")
```


```{r echo=FALSE, out.width = "850px", out.height="550px",fig.align='center'}
plot(
    temp["accesibilidad_hosp_caminado"], 
       key.pos = 4, 
       breaks = quantile(temp$accesibilidad_hosp_caminado))
```

## Censos de población y vivienda

Es necesario definir las variables del país con los que se desea trabajar. De acuerdo a esto, como primer paso se debe tener acceso al censo del país, para ello puede acceder desde el siguiente enlace <https://redatam.org/en/microdata> en el cual dispondrá de un archivo *.zip* con los microdatos del país. Ahora bien, para leer el conjunto de datos, es necesario emplear la función redatam.open de la librería `redatam`, la cual depende directamente del diccionario censal del software REDATAM, este es un archivo con extensión dicx y que debe encontrarse en la carpeta sobre los datos que se están leyendo. Así, es como se crea un objeto dentro de `R` que hace la respectiva unión del diccionario con los microdatos de la base de datos censal. La siguiente sintaxis muestra la lectura del diccionario en `R` y los cálculos iniciales

 

```{r, eval=FALSE}
# https://redatamr.ideasybits.com/
library(redatam)
colombia <-  redatam.open( "UNFPA/D6/Data/cpv2018col-cde.dicX")

CONTEOS <- redatam.query(colombia, "freq DEPTO.REDCODEN
                      by CLASE.AREA
                      by PERSONA.P_SEXO
                      by PERSONA.P_EDAD
                      by PERSONA.UnidasR
                      by PERSONA.EDUCA
                      by PERSONA.PBLOPER
                      ", tot.omit = FALSE)
```

Después de realizar algunas validaciones se estandarizan las variables como muestra el siguiente código.

```{r, eval=FALSE}
CONTEOS <- readRDS(file = "Data/CONTEOS.RDS")
# Eliminando totales de la tabla
CONTEOS2 <- CONTEOS %>% filter_at(vars(matches("_label")),all_vars(. !=  "__tot__"))

censo_mrp <- CONTEOS2 %>%
  transmute(dam =str_pad(string = REDCODEN1_value, width = 2, pad = "0"),
            area = case_when(AREA2_value == 1 ~ "1", # 1 = Urbana
                             TRUE ~ "0"),
            sexo = as.character(P_SEXO3_value),
            edad = case_when(
              P_EDAD4_value %in% 0:14 ~ "1", # 0 a 14
              P_EDAD4_value %in% 15:29 ~ "2", # 15 a 29
              P_EDAD4_value %in% 30:44 ~ "3", # 30 a 44
              P_EDAD4_value %in% 45:64~ "4", # 45 a 64
              TRUE ~ "5"), # 65 o mas
            etnia = case_when(
               PBLOPER5_value %in% c(1) ~ "1", # Indigena
               PBLOPER5_value %in% c(2)~ "2",  # Afro
               TRUE ~ "3"), # Otro

            anoest = case_when(
              P_EDAD4_value < 6 | is.na(ANEST6_value) ~ "98",     # No aplica
              ANEST6_value == 99 ~ "99", #NS/NR
              ANEST6_value %in% 0 ~ "1",  # Sin educacion
              ANEST6_value %in% c(1:6) ~ "2",  # 1-6
              ANEST6_value %in% c(7:12) ~ "3",  # 7-12
              ANEST6_value > 12 ~ "4" ,  # 12 o mas
              TRUE ~ "Error"
            ),
            value) %>%
  group_by(dam, area, sexo, edad, etnia, anoest) %>%
  summarise(n = sum(value), .groups = "drop")
```

A partir de la base estandarizada es posible construir algunas covariables para el departamento. 

```{r}
censo_mrp <- readRDS("Data/censo_mrp_dam.rds")
tasa_censo <- model.matrix(dam ~ -1 +.,
                           data = censo_mrp %>% select(-n)) %>% 
  data.frame() %>%
  mutate(dam = censo_mrp$dam, 
         n = censo_mrp$n) %>% 
  group_by(dam) %>%
  summarise_all(~weighted.mean(x = .,w = n)) %>%
  mutate(etnia1 = 1-etnia3-etnia2) %>% 
  select(-area0,-anoest99, -anoest98,-etnia3,-n) 
tba(tasa_censo)
```

El indicador es posible definirlo a partir de una variable del censo, haciendo que el proceso seá hace más corto, para este caso es empleada la variable `VIVIENDA.VC_ALC`, agregada por departamento. 

En el primer bloque que código usando la función `redatam.query()` se realiza el conteo de viviendas que tienen el servicio de acueducto. Seguido de esto, eliminamos los registros que no son de interés, por ejemplo, el total en el departamento o total nacional, los cuales se identifican dentro de la base con la etiqueta `__tot__`. 

El siguiente paso es contar el número de viviendas por departamento que *NO* cuentan con acueducto en el censo (`Pobx`) y el total de viviendas que respondieron a la pregunta (`PobT`), para finalmente realizar el cociente de estas dos preguntas.  

```{r, eval=FALSE}
CONTEOS <- redatam.query(Colombia,
                         "freq DEPTO.REDCODEN
                          by VIVIENDA.VB_ACU",
                         tot.omit = FALSE)

ACUEDUCTO <- CONTEOS %>% 
  filter_at(vars(matches("_label")),
            all_vars(!. %in%  c("__tot__") ))
# 1 = Si
# 2 = No
tasa_agua <- ACUEDUCTO %>%
  mutate(Pobx = ifelse(!VB_ACU2_value %in% c(1), value, 0),
         PobT = value) %>%
  group_by(
    dam = str_pad(string = REDCODEN1_value, width = 2, pad = "0")
  ) %>%
  summarise(PobT = sum(PobT),
            Pobx = sum(Pobx)) %>% 
  transmute(dam,
            tiene_acueducto = Pobx/PobT)
```
La tabla resultante se muestra a continuación. 
```{r, echo=FALSE}
readRDS("Data/predictors_censo_dam.rds") %>% 
  dplyr::select(dam,tiene_acueducto) %>% 
  tba()
```


El proceso se repite con otras preguntas del censo hasta consolidar la tabla siguiente. 

```{r}
predictors_censo_dam <- readRDS("Data/predictors_censo_dam.rds")
tba(predictors_censo_dam)
```


### Mapas de las variables con información censal. 

```{r}
temp2 <- inner_join(shape["dam"], predictors_censo_dam) 
for(ii in names(predictors_censo_dam[,-1])){
  plot(
    temp2[ii], 
       key.pos = 4, 
       breaks = quantile(temp2[[ii]]))
}
```

