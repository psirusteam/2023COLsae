[["index.html", "Desagregación de datos en encuestas de hogares: metodologías bayesianas para modelos de estimación en áreas pequeñas Agenda", " Desagregación de datos en encuestas de hogares: metodologías bayesianas para modelos de estimación en áreas pequeñas Andrés Gutiérrez1, Stalyn Guerrero2 2023-03-21 Agenda Experto Regional en Estadísticas Sociales - Comisión Económica para América Latina y el Caribe (CEPAL) - andres.gutierrez@cepal.org↩︎ Consultor - Comisión Económica para América Latina y el Caribe (CEPAL), guerrerostalyn@gmail.com↩︎ "],["día-1---sesión-1--no-dejar-a-nadie-atrás---ods-y-la-agenda-2030.html", "Capítulo 1 Día 1 - Sesión 1- No dejar a nadie atrás - ODS y la Agenda 2030", " Capítulo 1 Día 1 - Sesión 1- No dejar a nadie atrás - ODS y la Agenda 2030 Ver presentación "],["día-1---sesión-2--limitaciones-de-las-encuestas-de-hogares.html", "Capítulo 2 Día 1 - Sesión 2- Limitaciones de las encuestas de hogares", " Capítulo 2 Día 1 - Sesión 2- Limitaciones de las encuestas de hogares Ver presentación "],["día-1---sesión-3--censo-e-información-satelital.html", "Capítulo 3 Día 1 - Sesión 3- Censo e información satelital ", " Capítulo 3 Día 1 - Sesión 3- Censo e información satelital "],["uso-de-imágenes-satelitales-y-sae.html", "3.1 Uso de imágenes satelitales y SAE", " 3.1 Uso de imágenes satelitales y SAE Uno de los artículo pioneros de estimación de áreas pequeñas fue el artículo de Singh, R, et. al. (2002) el cual abordó la estimación del rendimiento de cultivos para los tehsil (unidad subadministrativa) del distriyo Rohtak district en Haryana (India). Las imágenes raster representan el mundo mediante un conjunto de celdas contiguas igualmente espaciadas conocidas como pixeles, estas imágenes tienen información como un sistema de información geográfico, Un sistema de referencia de coordenadas. Las imágenes almacenan un identificador, un valor en cada pixel (o un vector con diferentes valores) y cada celda tiene asociada una escala de colores. Las imágenes pueden obtenerse crudas y procesadas, estas primeras contienen solamente las capas de colores, las segundas contienen también valores que han sido procesados en cada celda (índices de vegetación, intensidad lumínica, tipo de vegetación). La información cruda puede utilizarse para entrenar características que se desean entrenar (carreteras, tipo de cultivo, bosque / no bosque), afortunadamente en Google Earth Engine encontramos muchos indicadores procesadas asociadas a un pixel. Estos indicadores pueden agregarse a nivel de un área geográfica. 3.1.1 Fuentes de datos de imágenes satelitales Algunas de las principales fuentes de imágenes satelitales son: http://earthexplorer.usgs.gov/ https://lpdaacsvc.cr.usgs.gov/appeears/ https://search.earthdata.nasa.gov/search https://scihub.coGTMnicus.eu/ https://aws.amazon.com/public-data-sets/landsat/ Sin embargo la mayor parte de estas fuentes están centralizadas en Google Earth Engine que permite buscar fuentes de datos provenientes de imágenes satelitales. GEE se puede manejar por medio de APIS en diferentes lenguajes de programación: Javascript (por defecto), Python y R (paquete rgee). "],["google-earth-eninge.html", "3.2 Google Earth Eninge", " 3.2 Google Earth Eninge Crear una cuenta en link, una vez que se ingrese a la cuenta puede buscarse los conjuntos de datos de interés: Una vez se busque el conjunto de datos se puede abrir un editor de código brindado por google en Javascript. Copiar y pegar la sintaxis que brinda el buscador de conjunto de datos para visualizar la imagen raster y disponer de sentencias que GTMmitan la obtención del conjunto de datos de interés posteriormente en R "],["instalación-de-rgee.html", "3.3 Instalación de rgee", " 3.3 Instalación de rgee Descargar e instalar anaconda o conda. (https://www.anaconda.com/products/individual) Abrir Anaconda prompt y configurar ambiente de trabajo (ambiente python rgee_py) con las siguientes sentencias: conda create -n rgee_py python=3.9 activate rgee_py pip install google-api-python-client pip install earthengine-api pip install numpy Listar los ambientes de Python disponibles en anaconda prompt conda env list Una vez identificado la ruta del ambiente ambiente rgee_py definirla en R (no se debe olvidar cambiar \\ por /). Instalar reticulate y rgee, cargar paquetes para procesamiento espacial y configurar el ambiente de trabajo como sigue: library(reticulate) # Conexión con Python library(rgee) # Conexión con Google Earth Engine library(sf) # Paquete para manejar datos geográficos library(dplyr) # Paquete para procesamiento de datos rgee_environment_dir = &quot;C://Users//sguerrero//Anaconda3//envs//rgee_py//python.exe&quot; # Configurar python (Algunas veces no es detectado y se debe reiniciar R) reticulate::use_python(rgee_environment_dir, required=T) rgee::ee_install_set_pyenv(py_path = rgee_environment_dir, py_env = &quot;rgee_py&quot;) Sys.setenv(RETICULATE_PYTHON = rgee_environment_dir) Sys.setenv(EARTHENGINE_PYTHON = rgee_environment_dir) Una vez configurado el ambiente puede iniciarlizarse una sesión de Google Earth Engine como sigue: rgee::ee_Initialize(drive = T) Notas: Se debe inicializar cada sesión con el comando rgee::ee_Initialize(drive = T). Los comandos de javascript que invoquen métodos con “.” se sustituyen por signo peso ($), por ejemplo: ee.ImageCollection().filterDate() # Javascript ee$ImageCollection()$filterDate() # R 3.3.1 Descargar información satelital Paso 1: disponer de los shapefile # shape &lt;- read_sf(&quot;Shape/COL_dam2.shp&quot;) shape &lt;- read_sf(&quot;Recursos/Día1/Sesion3/Shape/COL.shp&quot;) plot(shape[&quot;geometry&quot;]) Paso 2: Seleccionar el archivo de imágenes que desea procesar, para nuestro ejemplo luces nocturnas. luces &lt;- ee$ImageCollection(&quot;NOAA/DMSP-OLS/NIGHTTIME_LIGHTS&quot;) %&gt;% ee$ImageCollection$filterDate(&quot;2013-01-01&quot;, &quot;2014-01-01&quot;) %&gt;% ee$ImageCollection$map(function(x) x$select(&quot;stable_lights&quot;)) %&gt;% ee$ImageCollection$toBands() Paso 3: Descargar la información ## Tiempo 10 minutos shape_luces &lt;- map(unique(shape$dam), ~tryCatch(ee_extract( x = luces, y = shape[&quot;dam&quot;] %&gt;% filter(dam == .x), ee$Reducer$mean(), sf = FALSE ) %&gt;% mutate(dam = .x), error = function(e)data.frame(dam = .x))) shape_luces %&lt;&gt;% bind_rows() tba(shape_luces, cap = &quot;Promedio de luces nocturnasa&quot;) Repetir la rutina para: Tipo de suelo: crops-coverfraction (Porcentaje de cubrimiento cultivos) y urban-coverfraction (Porcentaje de cobertura urbana) disponibles en https://develoGTMs.google.com/earth-engine/datasets/catalog/COGTMNICUS_Landcover_100m_Proba-V-C3_Global#description Tiempo de viaje al hospital o clínica más cercana (accessibility) y tiempo de viaje al hospital o clínica más cercana utilizando transporte no motorizado (accessibility_walking_only) información disponible en https://develoGTMs.google.com/earth-engine/datasets/catalog/Oxford_MAP_accessibility_to_healthcare_2019 Modificación humana, donde se consideran los asentamiento humano, la agricultura, el transporte, la minería y producción de energía e infraestructura eléctrica. En el siguiente link encuentra la información satelital https://develoGTMs.google.com/earth-engine/datasets/catalog/CSP_HM_GlobalHumanModification#description Paso 4 consolidar la información. dam luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 05 2.3809 1.2755 0.6900 0.2947 181.1119 420.4946 08 13.0102 9.7734 4.7396 0.4943 28.2639 154.5701 11 21.5163 9.7879 19.8337 0.5509 60.7259 267.8848 13 1.9374 1.9246 0.6285 0.2911 216.2115 501.9515 15 2.6495 13.8033 0.5758 0.2965 115.8310 309.3832 17 4.4541 2.5939 0.8696 0.3639 62.2349 228.6569 18 0.0877 0.2771 0.0456 0.1248 1218.6141 2505.8205 19 1.4020 4.0623 0.3414 0.2231 214.3356 406.7882 20 2.6586 10.6343 0.4973 0.3349 99.1499 365.6516 23 2.2205 10.5568 0.5211 0.3331 141.3763 441.9516 Los resultados se muestran en los siguientes mapas 3.3.2 Luces nocturnas 3.3.3 Cubrimiento cultivos 3.3.4 Cubrimiento urbanos 3.3.5 Modificación humana 3.3.6 Tiempo promedio al hospital 3.3.7 Tiempo promedio al hospital en vehiculo no motorizado "],["censos-de-población-y-vivienda.html", "3.4 Censos de población y vivienda", " 3.4 Censos de población y vivienda Es necesario definir las variables del país con los que se desea trabajar. De acuerdo a esto, como primer paso se debe tener acceso al censo del país, para ello puede acceder desde el siguiente enlace https://redatam.org/en/microdata en el cual dispondrá de un archivo .zip con los microdatos del país. Ahora bien, para leer el conjunto de datos, es necesario emplear la función redatam.open de la librería redatam, la cual depende directamente del diccionario censal del software REDATAM, este es un archivo con extensión dicx y que debe encontrarse en la carpeta sobre los datos que se están leyendo. Así, es como se crea un objeto dentro de R que hace la respectiva unión del diccionario con los microdatos de la base de datos censal. La siguiente sintaxis muestra la lectura del diccionario en R y los cálculos iniciales library(redatam) colombia &lt;- redatam.open( &quot;UNFPA/D6/Data/cpv2018col-cde.dicX&quot;) CONTEOS &lt;- redatam.query(colombia, &quot;freq DEPTO.REDCODEN by CLASE.AREA by PERSONA.P_SEXO by PERSONA.P_EDAD by PERSONA.UnidasR by PERSONA.EDUCA by PERSONA.PBLOPER &quot;, tot.omit = FALSE) # Eliminando totales de la tabla CONTEOS2 &lt;- CONTEOS %&gt;% filter_at(vars(matches(&quot;_label&quot;)),all_vars(. != &quot;__tot__&quot;)) Después de realizar algunas validaciones se estandarizan las variables como muestra el siguiente código. censo_mrp &lt;- CONTEOS2 %&gt;% transmute(dam =str_pad(string = REDCODEN1_value, width = 2, pad = &quot;0&quot;), area = case_when(AREA2_value == 1 ~ &quot;1&quot;, # 1 = Urbana TRUE ~ &quot;0&quot;), sexo = as.character(P_SEXO3_value), edad = case_when( P_EDAD4_value %in% 0:14 ~ &quot;1&quot;, # 0 a 14 P_EDAD4_value %in% 15:29 ~ &quot;2&quot;, # 15 a 29 P_EDAD4_value %in% 30:44 ~ &quot;3&quot;, # 30 a 44 P_EDAD4_value %in% 45:64~ &quot;4&quot;, # 45 a 64 TRUE ~ &quot;5&quot;), # 65 o mas etnia = case_when( PBLOPER5_value %in% c(1) ~ &quot;1&quot;, # Indigena PBLOPER5_value %in% c(2)~ &quot;2&quot;, # Afro TRUE ~ &quot;3&quot;), # Otro anoest = case_when( P_EDAD4_value &lt; 6 | is.na(ANEST6_value) ~ &quot;98&quot;, # No aplica ANEST6_value == 99 ~ &quot;99&quot;, #NS/NR ANEST6_value %in% 0 ~ &quot;1&quot;, # Sin educacion ANEST6_value %in% c(1:6) ~ &quot;2&quot;, # 1-6 ANEST6_value %in% c(7:12) ~ &quot;3&quot;, # 7-12 ANEST6_value &gt; 12 ~ &quot;4&quot; , # 12 o mas TRUE ~ &quot;Error&quot; ), value) %&gt;% group_by(dam, area, sexo, edad, etnia, anoest) %&gt;% summarise(n = sum(value), .groups = &quot;drop&quot;) A partir de la base estandarizada es posible construir algunas covariables para el departamento. censo_mrp &lt;- readRDS(&quot;Recursos/Día1/Sesion3/Data/censo_mrp_dam.rds&quot;) tasa_censo &lt;- model.matrix(dam ~ -1 +., data = censo_mrp %&gt;% select(-n)) %&gt;% data.frame() %&gt;% mutate(dam = censo_mrp$dam, n = censo_mrp$n) %&gt;% group_by(dam) %&gt;% summarise_all(~weighted.mean(x = .,w = n)) %&gt;% mutate(etnia1 = 1-etnia3-etnia2) %&gt;% select(-area0,-anoest99, -anoest98,-etnia3,-n) tba(tasa_censo) dam area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 05 0.8000 0.5171 0.2620 0.2159 0.2273 0.0976 0.0522 0.3148 0.3802 0.1780 0.0063 08 0.9503 0.5131 0.2613 0.2108 0.2059 0.0843 0.0598 0.2556 0.4169 0.1847 0.0167 11 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 13 0.7529 0.5037 0.2600 0.1988 0.1915 0.0806 0.1673 0.3149 0.3749 0.1334 0.0027 15 0.6017 0.5077 0.2390 0.2018 0.2224 0.1136 0.0037 0.3712 0.3368 0.1487 0.0063 17 0.7535 0.5154 0.2374 0.2013 0.2518 0.1243 0.0159 0.3569 0.3664 0.1562 0.0604 18 0.6764 0.4928 0.2813 0.1962 0.1708 0.0643 0.0141 0.4132 0.3170 0.0834 0.0245 19 0.3958 0.5048 0.2688 0.2081 0.1867 0.0890 0.1973 0.4067 0.3344 0.0992 0.2481 20 0.7591 0.5050 0.2707 0.2000 0.1684 0.0645 0.1297 0.3214 0.3528 0.1227 0.0466 23 0.5617 0.5022 0.2570 0.1944 0.1939 0.0839 0.0659 0.3384 0.3469 0.1164 0.1303 25 0.7312 0.5059 0.2557 0.2162 0.2155 0.0924 0.0047 0.3181 0.3904 0.1622 0.0036 27 0.4934 0.5060 0.2709 0.1841 0.1463 0.0568 0.7383 0.3450 0.2785 0.0889 0.1496 41 0.6101 0.5010 0.2636 0.2005 0.1985 0.0852 0.0051 0.3953 0.3379 0.1094 0.0121 44 0.4748 0.5103 0.2799 0.1846 0.1381 0.0498 0.0733 0.3395 0.2769 0.0934 0.4782 47 0.7110 0.4995 0.2640 0.1937 0.1812 0.0739 0.0841 0.3273 0.3707 0.1085 0.0166 50 0.7655 0.4942 0.2656 0.2152 0.1973 0.0726 0.0096 0.3374 0.3630 0.1418 0.0223 52 0.4849 0.5105 0.2670 0.2134 0.1984 0.0975 0.1745 0.4223 0.3120 0.1045 0.1546 54 0.7904 0.5069 0.2654 0.2100 0.2001 0.0820 0.0041 0.3633 0.3482 0.1253 0.0034 63 0.8807 0.5180 0.2416 0.2015 0.2518 0.1281 0.0119 0.3136 0.4014 0.1668 0.0057 66 0.7832 0.5215 0.2442 0.2068 0.2394 0.1169 0.0199 0.3370 0.3782 0.1631 0.0356 68 0.7680 0.5104 0.2497 0.2125 0.2215 0.0981 0.0113 0.3281 0.3594 0.1743 0.0006 70 0.6502 0.4972 0.2557 0.1946 0.1948 0.0873 0.1190 0.3367 0.3459 0.1099 0.1214 73 0.7096 0.5044 0.2388 0.1927 0.2308 0.1173 0.0042 0.3655 0.3575 0.1324 0.0368 76 0.8555 0.5249 0.2461 0.2114 0.2369 0.1124 0.1709 0.2927 0.4084 0.1809 0.0081 81 0.6687 0.4945 0.2825 0.2065 0.1701 0.0585 0.0420 0.3898 0.3237 0.1002 0.0274 85 0.7266 0.4945 0.2749 0.2257 0.1782 0.0550 0.0161 0.3602 0.3617 0.1170 0.0181 86 0.5602 0.4954 0.2915 0.2098 0.1660 0.0625 0.0362 0.3967 0.3516 0.0913 0.1790 88 0.6658 0.5171 0.2415 0.2124 0.2561 0.0752 0.5564 0.2161 0.4525 0.2167 0.0004 91 0.5237 0.4789 0.2933 0.1792 0.1313 0.0428 0.0074 0.3517 0.3615 0.0734 0.5772 94 0.4350 0.4775 0.2902 0.1595 0.1182 0.0353 0.0104 0.4679 0.2266 0.0589 0.7490 95 0.5939 0.4653 0.2859 0.1972 0.1780 0.0524 0.0409 0.4169 0.3011 0.0917 0.0938 97 0.3066 0.4748 0.2743 0.1330 0.1129 0.0380 0.0076 0.4650 0.2663 0.0525 0.8168 99 0.3204 0.4690 0.2877 0.1697 0.1250 0.0349 0.0076 0.4315 0.2250 0.0526 0.5816 El indicador es posible definirlo a partir de una variable del censo, haciendo que el proceso seá hace más corto, para este caso es empleada la variable VIVIENDA.VC_ALC, agregada por departamento. En el primer bloque que código usando la función redatam.query() se realiza el conteo de viviendas que tienen el servicio de acueducto. Seguido de esto, eliminamos los registros que no son de interés, por ejemplo, el total en el departamento o total nacional, los cuales se identifican dentro de la base con la etiqueta __tot__. El siguiente paso es contar el número de viviendas por departamento que NO cuentan con acueducto en el censo (Pobx) y el total de viviendas que respondieron a la pregunta (PobT), para finalmente realizar el cociente de estas dos preguntas. CONTEOS &lt;- redatam.query(Colombia, &quot;freq DEPTO.REDCODEN by VIVIENDA.VB_ACU&quot;, tot.omit = FALSE) ACUEDUCTO &lt;- CONTEOS %&gt;% filter_at(vars(matches(&quot;_label&quot;)), all_vars(!. %in% c(&quot;__tot__&quot;) )) # 1 = Si # 2 = No tasa_agua &lt;- ACUEDUCTO %&gt;% mutate(Pobx = ifelse(!VB_ACU2_value %in% c(1), value, 0), PobT = value) %&gt;% group_by( dam = str_pad(string = REDCODEN1_value, width = 2, pad = &quot;0&quot;) ) %&gt;% summarise(PobT = sum(PobT), Pobx = sum(Pobx)) %&gt;% transmute(dam, tiene_acueducto = Pobx/PobT) La tabla resultante se muestra a continuación. dam tiene_acueducto 05 0.2508 08 0.1543 11 0.0759 13 0.3312 15 0.3930 17 0.2757 18 0.4201 19 0.4776 20 0.2930 23 0.3979 25 0.2825 27 0.7639 41 0.3443 44 0.5824 47 0.4155 50 0.3881 52 0.3873 54 0.3328 63 0.1720 66 0.2503 68 0.3330 70 0.2716 73 0.3293 76 0.1900 81 0.4102 85 0.3558 86 0.5738 91 0.6481 94 0.8221 95 0.6513 97 0.6797 99 0.6887 88 0.6776 El proceso se repite con otras preguntas del censo hasta consolidar la tabla siguiente. predictors_censo_dam &lt;- readRDS(&quot;Recursos/Día1/Sesion3/Data/predictors_censo_dam.rds&quot;) tba(predictors_censo_dam) dam area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion 05 0.8000 0.5171 0.2620 0.2159 0.2273 0.0976 0.0522 0.3148 0.3802 0.1780 0.0063 0.2508 0.0286 0.0447 0.1159 0.0904 08 0.9503 0.5131 0.2613 0.2108 0.2059 0.0843 0.0598 0.2556 0.4169 0.1847 0.0167 0.1543 0.0211 0.0367 0.2359 0.1359 11 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 0.0759 0.0024 0.0131 0.0848 0.0889 13 0.7529 0.5037 0.2600 0.1988 0.1915 0.0806 0.1673 0.3149 0.3749 0.1334 0.0027 0.3312 0.1367 0.0787 0.2872 0.1448 15 0.6017 0.5077 0.2390 0.2018 0.2224 0.1136 0.0037 0.3712 0.3368 0.1487 0.0063 0.3930 0.0562 0.0587 0.1323 0.1039 17 0.7535 0.5154 0.2374 0.2013 0.2518 0.1243 0.0159 0.3569 0.3664 0.1562 0.0604 0.2757 0.0150 0.0511 0.0996 0.0763 18 0.6764 0.4928 0.2813 0.1962 0.1708 0.0643 0.0141 0.4132 0.3170 0.0834 0.0245 0.4201 0.0801 0.0689 0.1773 0.0928 19 0.3958 0.5048 0.2688 0.2081 0.1867 0.0890 0.1973 0.4067 0.3344 0.0992 0.2481 0.4776 0.2088 0.0760 0.1692 0.1207 20 0.7591 0.5050 0.2707 0.2000 0.1684 0.0645 0.1297 0.3214 0.3528 0.1227 0.0466 0.2930 0.1125 0.0880 0.3177 0.1445 23 0.5617 0.5022 0.2570 0.1944 0.1939 0.0839 0.0659 0.3384 0.3469 0.1164 0.1303 0.3979 0.2975 0.1174 0.2971 0.1143 25 0.7312 0.5059 0.2557 0.2162 0.2155 0.0924 0.0047 0.3181 0.3904 0.1622 0.0036 0.2825 0.0204 0.0337 0.1152 0.0797 27 0.4934 0.5060 0.2709 0.1841 0.1463 0.0568 0.7383 0.3450 0.2785 0.0889 0.1496 0.7639 0.0560 0.1451 0.2189 0.1419 41 0.6101 0.5010 0.2636 0.2005 0.1985 0.0852 0.0051 0.3953 0.3379 0.1094 0.0121 0.3443 0.0741 0.0565 0.1689 0.0914 44 0.4748 0.5103 0.2799 0.1846 0.1381 0.0498 0.0733 0.3395 0.2769 0.0934 0.4782 0.5824 0.3918 0.1716 0.4535 0.1931 47 0.7110 0.4995 0.2640 0.1937 0.1812 0.0739 0.0841 0.3273 0.3707 0.1085 0.0166 0.4155 0.1320 0.0924 0.3424 0.1404 50 0.7655 0.4942 0.2656 0.2152 0.1973 0.0726 0.0096 0.3374 0.3630 0.1418 0.0223 0.3881 0.0514 0.0423 0.1368 0.1101 52 0.4849 0.5105 0.2670 0.2134 0.1984 0.0975 0.1745 0.4223 0.3120 0.1045 0.1546 0.3873 0.1362 0.0841 0.2128 0.1418 54 0.7904 0.5069 0.2654 0.2100 0.2001 0.0820 0.0041 0.3633 0.3482 0.1253 0.0034 0.3328 0.0688 0.0645 0.2450 0.1194 63 0.8807 0.5180 0.2416 0.2015 0.2518 0.1281 0.0119 0.3136 0.4014 0.1668 0.0057 0.1720 0.0077 0.0441 0.0853 0.1048 66 0.7832 0.5215 0.2442 0.2068 0.2394 0.1169 0.0199 0.3370 0.3782 0.1631 0.0356 0.2503 0.0065 0.0448 0.0916 0.0816 68 0.7680 0.5104 0.2497 0.2125 0.2215 0.0981 0.0113 0.3281 0.3594 0.1743 0.0006 0.3330 0.0413 0.0438 0.1414 0.1096 70 0.6502 0.4972 0.2557 0.1946 0.1948 0.0873 0.1190 0.3367 0.3459 0.1099 0.1214 0.2716 0.2175 0.1257 0.3204 0.1379 73 0.7096 0.5044 0.2388 0.1927 0.2308 0.1173 0.0042 0.3655 0.3575 0.1324 0.0368 0.3293 0.0539 0.0611 0.1430 0.0932 76 0.8555 0.5249 0.2461 0.2114 0.2369 0.1124 0.1709 0.2927 0.4084 0.1809 0.0081 0.1900 0.0080 0.0347 0.0910 0.0953 81 0.6687 0.4945 0.2825 0.2065 0.1701 0.0585 0.0420 0.3898 0.3237 0.1002 0.0274 0.4102 0.1742 0.0669 0.2458 0.1455 85 0.7266 0.4945 0.2749 0.2257 0.1782 0.0550 0.0161 0.3602 0.3617 0.1170 0.0181 0.3558 0.0605 0.0500 0.1934 0.1572 86 0.5602 0.4954 0.2915 0.2098 0.1660 0.0625 0.0362 0.3967 0.3516 0.0913 0.1790 0.5738 0.0303 0.0604 0.1764 0.1316 91 0.5237 0.4789 0.2933 0.1792 0.1313 0.0428 0.0074 0.3517 0.3615 0.0734 0.5772 0.6481 0.0470 0.0565 0.3585 0.0782 94 0.4350 0.4775 0.2902 0.1595 0.1182 0.0353 0.0104 0.4679 0.2266 0.0589 0.7490 0.8221 0.3130 0.0872 0.3781 0.1196 95 0.5939 0.4653 0.2859 0.1972 0.1780 0.0524 0.0409 0.4169 0.3011 0.0917 0.0938 0.6513 0.1052 0.0635 0.1645 0.0799 97 0.3066 0.4748 0.2743 0.1330 0.1129 0.0380 0.0076 0.4650 0.2663 0.0525 0.8168 0.6797 0.3105 0.1008 0.4443 0.1040 99 0.3204 0.4690 0.2877 0.1697 0.1250 0.0349 0.0076 0.4315 0.2250 0.0526 0.5816 0.6887 0.4305 0.1137 0.4338 0.1838 88 0.6658 0.5171 0.2415 0.2124 0.2561 0.0752 0.5564 0.2161 0.4525 0.2167 0.0004 0.6776 0.0107 0.0122 0.1879 0.0358 3.4.1 Mapas de las variables con información censal. temp2 &lt;- inner_join(shape[&quot;dam&quot;], predictors_censo_dam) for(ii in names(predictors_censo_dam[,-1])){ plot( temp2[ii], key.pos = 4, breaks = quantile(temp2[[ii]])) } "],["día-1---sesión-4--fundamentos-de-la-inferencia-bayesiana-en-r-y-stan.html", "Capítulo 4 Día 1 - Sesión 4- Fundamentos de la inferencia Bayesiana en R y STAN ", " Capítulo 4 Día 1 - Sesión 4- Fundamentos de la inferencia Bayesiana en R y STAN "],["regla-de-bayes.html", "4.1 Regla de Bayes", " 4.1 Regla de Bayes En términos de inferencia para \\(\\boldsymbol{\\theta}\\), es necesario encontrar la distribución de los parámetros condicionada a la observación de los datos. Para este fin, es necesario definir la distribución conjunta de la variable de interés con el vector de parámetros. \\[ p(\\boldsymbol{\\theta},\\mathbf{Y})=p(\\boldsymbol{\\theta})p(\\mathbf{Y} \\mid \\boldsymbol{\\theta}) \\] La distribución \\(p(\\boldsymbol{\\theta})\\) se le conoce con el nombre de distribución previa. El término \\(p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})\\) es la distribución de muestreo, verosimilitud o distribución de los datos. La distribución del vector de parámetros condicionada a los datos observados está dada por \\[ p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})=\\frac{p(\\boldsymbol{\\theta},\\mathbf{Y})}{p(\\mathbf{Y})}=\\frac{p(\\boldsymbol{\\theta})p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})}{p(\\mathbf{Y})} \\] A la distribución \\(p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})\\) se le conoce con el nombre de distribución posterior. Nótese que el denominador no depende del vector de parámetros y considerando a los datos observados como fijos, corresponde a una constante y puede ser obviada. Por lo tanto, otra representación de la regla de Bayes está dada por \\[ p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})\\propto p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) \\] "],["inferencia-bayesiana..html", "4.2 Inferencia Bayesiana.", " 4.2 Inferencia Bayesiana. En términos de estimación, inferencia y predicción, el enfoque Bayesiano supone dos momentos o etapas: Antes de la recolección de las datos, en donde el investigador propone, basado en su conocimiento, experiencia o fuentes externas, una distribución de probabilidad previa para el parámetro de interés. Después de la recolección de los datos. Siguiendo el teorema de Bayes, el investigador actualiza su conocimiento acerca del comportamiento probabilístico del parámetro de interés mediante la distribución posterior de este. "],["modelos-uniparamétricos.html", "4.3 Modelos uniparamétricos", " 4.3 Modelos uniparamétricos Los modelos que están definidos en términos de un solo parámetro que pertenece al conjunto de los números reales se definen como modelos uniparamétricos. "],["modelo-bernoulli.html", "4.4 Modelo Bernoulli", " 4.4 Modelo Bernoulli Suponga que \\(Y\\) es una variable aleatoria con distribución Bernoulli dada por: \\[ p(Y \\mid \\theta)=\\theta^y(1-\\theta)^{1-y}I_{\\{0,1\\}}(y) \\] Como el parámetro \\(\\theta\\) está restringido al espacio \\(\\Theta=[0,1]\\), entonces es posible formular varias opciones para la distribución previa del parámetro. En particular, la distribución uniforme restringida al intervalo \\([0,1]\\) o la distribución Beta parecen ser buenas opciones. Puesto que la distribución uniforme es un caso particular de la distribución Beta. Por lo tanto la distribución previa del parámetro \\(\\theta\\) estará dada por \\[ \\begin{equation} p(\\theta \\mid \\alpha,\\beta)= \\frac{1}{Beta(\\alpha,\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}I_{[0,1]}(\\theta). \\end{equation} \\] y la distribución posterior del parámetro \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta \\mid Y \\sim Beta(y+\\alpha,\\beta-y+1) \\end{equation*} \\] Cuando se tiene una muestra aleatoria \\(Y_1,\\ldots,Y_n\\) de variables con distribución Bernoulli de parámetro \\(\\theta\\), entonces la distribución posterior del parámetro de interés es \\[ \\begin{equation*} \\theta \\mid Y_1,\\ldots,Y_n \\sim Beta\\left(\\sum_{i=1}^ny_i+\\alpha,\\beta-\\sum_{i=1}^ny_i+n\\right) \\end{equation*} \\] 4.4.1 Práctica en R library(tidyverse) encuesta &lt;- readRDS(&quot;Recursos/Día1/Sesion4/Data/encuestaCOL18N1.rds&quot;) Sea \\(Y\\) la variable aleatoria \\[ Y_{i}=\\begin{cases} 1 &amp; ingreso&lt;lp\\\\ 0 &amp; ingreso\\geq lp \\end{cases} \\] El tamaño de la muestra es de 19877 Indígena datay &lt;- encuesta %&gt;% filter(etnia_ee == 1) %&gt;% transmute(y = ifelse(ingcorte &lt; lp, 1,0)) addmargins(table(datay$y)) 0 1 Sum 9579 10298 19877 Un grupo de estadístico experto decide utilizar una distribución previa Beta, definiendo los parámetros de la distribución previa como \\(Beta(\\alpha=1, \\beta=1)\\). La distribución posterior del parámetro de interés, que representa la probabilidad de estar por debajo de la linea de pobreza, es \\(Beta(1.0298\\times 10^{4} + 1, 1 - 1.0298\\times 10^{4} + 19877)=Beta(1.0299\\times 10^{4}, 9580)\\) Figura 4.1: Distribución previa (línea roja) y distribución posterior (línea negra) La estimación del parámetro estaría dado por: \\[ E(X) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{1.0299\\times 10^{4}}{1.0299\\times 10^{4}+ 9580} = 0.5180844 \\] luego, el intervalo de credibilidad para la distribución posterior es. n = length(datay$y) n1 = sum(datay$y) qbeta(c(0.025, 0.975), shape1 = 1 + n1, shape2 = 1 - n1 + n) ## [1] 0.5111369 0.5250285 4.4.2 Práctica en STAN En STAN es posible obtener el mismo tipo de inferencia creando cuatro cadenas cuya distribución de probabilidad coincide con la distribución posterior del ejemplo. data { // Entrada el modelo int&lt;lower=0&gt; n; // Numero de observaciones int y[n]; // Vector de longitud n real a; real b; } parameters { // Definir parámetro real&lt;lower=0, upper=1&gt; theta; } model { // Definir modelo y ~ bernoulli(theta); theta ~ beta(a, b); // Distribución previa } generated quantities { real ypred[n]; // vector de longitud n for (ii in 1:n){ ypred[ii] = bernoulli_rng(theta); } } Para compilar STAN debemos definir los parámetros de entrada sample_data &lt;- list(n = nrow(datay), y = datay$y, a = 1, b = 1) Para ejecutar STAN en R tenemos la librería rstan library(cmdstanr) library(rstan) Bernoulli &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/1Bernoulli.stan&quot; options(mc.cores = parallel::detectCores()) model_Bernoulli &lt;- stan( file = Bernoulli, # Stan program data = sample_data, # named list of data verbose = FALSE, warmup = 500, # number of warmup iterations per chain iter = 1000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) La estimación del parámetro \\(\\theta\\) es: summary(model_Bernoulli, pars = &quot;theta&quot;)$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 0.5179 1e-04 0.0035 0.5109 0.5155 0.5178 0.5201 0.5246 799.1369 1.002 Para observar las cadenas compilamos las lineas de código library(posterior) library(ggplot2) temp &lt;- as_draws_df(as.array(model_Bernoulli,pars = &quot;theta&quot;)) ggplot(data = temp, aes(x = theta))+ geom_density(color = &quot;blue&quot;, size = 2) + stat_function(fun = posterior1, args = list(y = datay$y), size = 2) + theme_bw(base_size = 20) + labs(x = latex2exp::TeX(&quot;\\\\theta&quot;), y = latex2exp::TeX(&quot;f(\\\\theta)&quot;)) Figura 4.2: Resultado con STAN (línea azul) y posterior teórica (línea negra) Para validar las cadenas library(bayesplot) posterior_theta &lt;- as.array(model_Bernoulli, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) Predicción de \\(Y\\) en cada una de las iteraciones de las cadenas. y_pred_B &lt;- as.array(model_Bernoulli, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, 1:n] ppc_dens_overlay(y = datay$y, y_pred2) "],["modelo-binomial.html", "4.5 Modelo Binomial", " 4.5 Modelo Binomial Cuando se dispone de una muestra aleatoria de variables con distribución Bernoulli \\(Y_1,\\ldots,Y_n\\), la inferencia Bayesiana se puede llevar a cabo usando la distribución Binomial, puesto que es bien sabido que la suma de variables aleatorias Bernoulli \\[ \\begin{equation*} S=\\sum_{i=1}^nY_i \\end{equation*} \\] sigue una distribución Binomial. Es decir: \\[ \\begin{equation} p(S \\mid \\theta)=\\binom{n}{s}\\theta^s(1-\\theta)^{n-s}I_{\\{0,1,\\ldots,n\\}}(s), \\end{equation} \\] Nótese que la distribución Binomial es un caso general para la distribución Bernoulli, cuando \\(n=1\\). Por lo tanto es natural suponer que distribución previa del parámetro \\(\\theta\\) estará dada por \\[ \\begin{equation} p(\\theta \\mid \\alpha,\\beta)= \\frac{1}{Beta(\\alpha,\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}I_{[0,1]}(\\theta). \\end{equation} \\] La distribución posterior del parámetro \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta \\mid S \\sim Beta(s+\\alpha,\\beta-s+n) \\end{equation*} \\] Ahora, cuando se tiene una sucesión de variables aleatorias \\(S_1,\\ldots,S_i, \\ldots,S_k\\) independientes y con distribución \\(Binomial(n_i,\\theta_i)\\) para \\(i=1,\\ldots,k\\), entonces la distribución posterior del parámetro de interés \\(\\theta_i\\) es \\[ \\begin{equation*} \\theta_i \\mid s_i \\sim Beta\\left(s_i+\\alpha,\\ \\beta+ n_i- s_i\\right) \\end{equation*} \\] 4.5.1 Práctica en STAN Sea \\(S_k\\) el conteo de personas en condición de pobreza en el \\(k-ésimo\\) departamento en la muestra. dataS &lt;- encuesta %&gt;% transmute( dam = dam_ee, y = ifelse(ingcorte &lt; lp, 1,0) ) %&gt;% group_by(dam) %&gt;% summarise(nd = n(), #Número de ensayos Sd = sum(y) #Número de éxito ) tba(dataS) dam nd Sd 05 45467 7301 08 44321 10297 11 32213 4128 13 35610 10560 15 26485 5717 17 30764 4524 18 28842 11134 19 34357 12348 20 32454 12203 23 31986 10528 25 9068 1516 27 26828 12934 41 30728 8188 44 35618 16412 47 37634 13500 50 29317 6653 52 28927 8949 54 31384 12663 63 28276 6195 66 29199 4664 68 31778 5127 70 35525 11881 73 28416 6295 76 37556 7073 Creando código de STAN data { int&lt;lower=0&gt; K; // Número de provincia int&lt;lower=0&gt; n[K]; // Número de ensayos int&lt;lower=0&gt; s[K]; // Número de éxitos real a; real b; } parameters { real&lt;lower=0, upper=1&gt; theta[K]; // theta_d|s_d } model { for(kk in 1:K) { s[kk] ~ binomial(n[kk], theta[kk]); } to_vector(theta) ~ beta(a, b); } generated quantities { real spred[K]; // vector de longitud K for(kk in 1:K){ spred[kk] = binomial_rng(n[kk],theta[kk]); } } Preparando el código de STAN Binomial2 &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/3Binomial.stan&quot; Organizando datos para STAN sample_data &lt;- list(K = nrow(dataS), s = dataS$Sd, n = dataS$nd, a = 1, b = 1) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_Binomial2 &lt;- stan( file = Binomial2, # Stan program data = sample_data, # named list of data verbose = FALSE, warmup = 500, # number of warmup iterations per chain iter = 1000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) La estimación del parámetro \\(\\theta\\) es: summary(model_Binomial2, pars = &quot;theta&quot;)$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta[1] 0.1606 0e+00 0.0018 0.1572 0.1593 0.1606 0.1618 0.1641 4995.662 0.9987 theta[2] 0.2323 0e+00 0.0020 0.2285 0.2309 0.2323 0.2338 0.2362 5068.657 0.9991 theta[3] 0.1281 0e+00 0.0019 0.1246 0.1269 0.1281 0.1294 0.1318 4302.302 0.9989 theta[4] 0.2965 0e+00 0.0023 0.2920 0.2949 0.2965 0.2981 0.3009 5872.753 0.9982 theta[5] 0.2159 0e+00 0.0026 0.2109 0.2141 0.2158 0.2176 0.2210 4494.272 0.9993 theta[6] 0.1471 0e+00 0.0019 0.1433 0.1458 0.1471 0.1484 0.1509 6398.598 0.9992 theta[7] 0.3861 0e+00 0.0028 0.3807 0.3842 0.3861 0.3880 0.3914 5415.280 0.9986 theta[8] 0.3594 0e+00 0.0025 0.3547 0.3577 0.3594 0.3612 0.3642 4735.259 0.9985 theta[9] 0.3760 0e+00 0.0027 0.3708 0.3741 0.3760 0.3779 0.3814 4213.212 0.9986 theta[10] 0.3292 0e+00 0.0025 0.3243 0.3275 0.3292 0.3308 0.3341 5643.390 0.9989 theta[11] 0.1673 1e-04 0.0039 0.1600 0.1647 0.1673 0.1699 0.1751 4524.756 0.9998 theta[12] 0.4821 0e+00 0.0030 0.4760 0.4802 0.4820 0.4841 0.4883 6602.060 0.9987 theta[13] 0.2665 0e+00 0.0025 0.2615 0.2647 0.2665 0.2683 0.2715 6158.453 0.9989 theta[14] 0.4608 0e+00 0.0027 0.4555 0.4590 0.4608 0.4626 0.4661 5894.068 0.9983 theta[15] 0.3587 0e+00 0.0025 0.3539 0.3570 0.3587 0.3605 0.3637 5052.024 0.9988 theta[16] 0.2270 0e+00 0.0025 0.2221 0.2253 0.2271 0.2287 0.2317 4553.205 0.9985 theta[17] 0.3094 0e+00 0.0028 0.3040 0.3075 0.3093 0.3113 0.3148 5761.156 0.9983 theta[18] 0.4035 0e+00 0.0028 0.3978 0.4015 0.4035 0.4055 0.4091 4766.386 0.9999 theta[19] 0.2191 0e+00 0.0024 0.2144 0.2174 0.2190 0.2207 0.2240 5580.557 0.9987 theta[20] 0.1597 0e+00 0.0022 0.1553 0.1583 0.1598 0.1612 0.1640 4125.715 0.9988 theta[21] 0.1614 0e+00 0.0020 0.1574 0.1601 0.1614 0.1627 0.1653 5438.808 0.9990 theta[22] 0.3345 0e+00 0.0024 0.3297 0.3329 0.3344 0.3361 0.3395 4989.644 0.9994 theta[23] 0.2216 0e+00 0.0024 0.2168 0.2200 0.2216 0.2232 0.2263 4874.975 0.9993 theta[24] 0.1883 0e+00 0.0020 0.1844 0.1870 0.1883 0.1896 0.1922 4294.990 0.9984 Para validar las cadenas mcmc_areas(as.array(model_Binomial2, pars = &quot;theta&quot;)) mcmc_trace(as.array(model_Binomial2, pars = &quot;theta&quot;)) y_pred_B &lt;- as.array(model_Binomial2, pars = &quot;spred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 200) y_pred2 &lt;- y_pred_B[rowsrandom, ] g1 &lt;- ggplot(data = dataS, aes(x = Sd))+ geom_histogram(aes(y = ..density..)) + geom_density(size = 2, color = &quot;blue&quot;) + labs(y = &quot;&quot;)+ theme_bw(20) g2 &lt;- ppc_dens_overlay(y = dataS$Sd, y_pred2) g1/g2 "],["modelo-normal-con-media-desconocida.html", "4.6 Modelo Normal con media desconocida", " 4.6 Modelo Normal con media desconocida Suponga que \\(Y_1,\\cdots,Y_n\\) son variables independientes e idénticamente distribuidos con distribución \\(Normal(\\theta,\\sigma^2)\\) con \\(\\theta\\) desconocido pero \\(\\sigma^2\\) conocido. De esta forma, la función de verosimilitud de los datos está dada por \\[ \\begin{align*} p(\\mathbf{Y} \\mid \\theta) &amp;=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_i-\\theta)^2\\right\\}I_\\mathbb{R}(y) \\\\ &amp;=(2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(y_i-\\theta)^2\\right\\} \\end{align*} \\] Como el parámetro \\(\\theta\\) puede tomar cualquier valor en los reales, es posible asignarle una distribución previa \\(\\theta \\sim Normal(\\mu,\\tau^2)\\). Bajo este marco de referencia se tienen los siguientes resultados La distribución posterior del parámetro de interés \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta|\\mathbf{Y} \\sim Normal(\\mu_n,\\tau^2_n) \\end{equation*} \\] En donde \\[ \\begin{equation} \\mu_n=\\frac{\\frac{n}{\\sigma^2}\\bar{Y}+\\frac{1}{\\tau^2}\\mu}{\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}} \\ \\ \\ \\ \\ \\ \\ \\text{y} \\ \\ \\ \\ \\ \\ \\ \\tau_n^2=\\left(\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}\\right)^{-1} \\end{equation} \\] 4.6.1 Práctica en STAN Sea \\(Y\\) el logaritmo del ingreso dataNormal &lt;- encuesta %&gt;% transmute( dam_ee , logIngreso = log(ingcorte +1)) %&gt;% filter(dam_ee == &quot;08&quot;) #3 media &lt;- mean(dataNormal$logIngreso) Sd &lt;- sd(dataNormal$logIngreso) g1 &lt;- ggplot(dataNormal,aes(x = logIngreso))+ geom_density(size =2, color = &quot;blue&quot;) + stat_function(fun =dnorm, args = list(mean = media, sd = Sd), size =2) + theme_bw(base_size = 20) + labs(y = &quot;&quot;, x = (&quot;Log(Ingreso)&quot;)) g2 &lt;- ggplot(dataNormal, aes(sample = logIngreso)) + stat_qq() + stat_qq_line() + theme_bw(base_size = 20) g1|g2 Figura 4.3: Resultado en la muestra (línea azul) y distribución teórica (línea negra) Creando código de STAN data { int&lt;lower=0&gt; n; // Número de observaciones real y[n]; // LogIngreso real &lt;lower=0&gt; Sigma; // Desviación estándar } parameters { real theta; } model { y ~ normal(theta, Sigma); theta ~ normal(0, 1000); // Distribución previa } generated quantities { real ypred[n]; // Vector de longitud n for(kk in 1:n){ ypred[kk] = normal_rng(theta,Sigma); } } Preparando el código de STAN NormalMedia &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/4NormalMedia.stan&quot; Organizando datos para STAN sample_data &lt;- list(n = nrow(dataNormal), Sigma = sd(dataNormal$logIngreso), y = dataNormal$logIngreso) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_NormalMedia &lt;- stan( file = NormalMedia, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) La estimación del parámetro \\(\\theta\\) es: summary(model_NormalMedia, pars = &quot;theta&quot;)$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 13.1148 1e-04 0.0039 13.1071 13.1122 13.1147 13.1175 13.1224 694.8215 1.0002 posterior_theta &lt;- as.array(model_NormalMedia, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) y_pred_B &lt;- as.array(model_NormalMedia, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(dataNormal$logIngreso), y_pred2)/ ppc_dens_overlay(y = exp(as.numeric(dataNormal$logIngreso))-1, exp(y_pred2)-1) + xlim(0,5000000) "],["modelos-multiparamétricos.html", "4.7 Modelos multiparamétricos", " 4.7 Modelos multiparamétricos La distribución normal univariada que tiene dos parámetros: la media \\(\\theta\\) y la varianza \\(\\sigma^2\\). La distribución multinomial cuyo parámetro es un vector de probabilidades \\(\\boldsymbol{\\theta}\\). "],["modelo-normal-con-media-y-varianza-desconocida.html", "4.8 Modelo Normal con media y varianza desconocida", " 4.8 Modelo Normal con media y varianza desconocida Supongamos que se dispone de realizaciones de un conjunto de variables independientes e idénticamente distribuidas \\(Y_1,\\cdots,Y_n\\sim N(\\theta,\\sigma^2)\\). Cuando se desconoce tanto la media como la varianza de la distribución es necesario plantear diversos enfoques y situarse en el más conveniente, según el contexto del problema. En términos de la asignación de las distribuciones previas para \\(\\theta\\) y \\(\\sigma^2\\) es posible: Suponer que la distribución previa \\(p(\\theta)\\) es independiente de la distribución previa \\(p(\\sigma^2)\\) y que ambas distribuciones son informativas. Suponer que la distribución previa \\(p(\\theta)\\) es independiente de la distribución previa \\(p(\\sigma^2)\\) y que ambas distribuciones son no informativas. Suponer que la distribución previa para \\(\\theta\\) depende de \\(\\sigma^2\\) y escribirla como \\(p(\\theta \\mid \\sigma^2)\\), mientras que la distribución previa de \\(\\sigma^2\\) no depende de \\(\\theta\\) y se puede escribir como \\(p(\\sigma^2)\\). "],["parámetros-independientes.html", "4.9 Parámetros independientes", " 4.9 Parámetros independientes La distribución previa para el parámetro \\(\\theta\\) será \\[ \\begin{equation*} \\theta \\sim Normal(\\mu,\\tau^2) \\end{equation*} \\] Y la distribución previa para el parámetro \\(\\sigma^2\\) será \\[ \\begin{equation*} \\sigma^2 \\sim Inversa-Gamma(n_0/2,n_0\\sigma^2_0/2) \\end{equation*} \\] Asumiendo independencia previa, la distribución previa conjunta estará dada por \\[ \\begin{equation} p(\\theta,\\sigma^2)\\propto (\\sigma^2)^{-n_0/2-1}\\exp\\left\\{-\\dfrac{n_0\\sigma^2_0}{2\\sigma^2}\\right\\} \\exp\\left\\{-\\frac{1}{2\\tau^2}(\\theta-\\mu)^2\\right\\} \\end{equation} \\] La distribución posterior conjunta de los parámetros de interés está dada por \\[ \\begin{align} p(\\theta,\\sigma^2 \\mid \\mathbf{Y})&amp;\\propto (\\sigma^2)^{-(n+n_0)/2-1} \\notag \\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left[n_0\\sigma^2_0+(n-1)S^2+n(\\bar{y}-\\theta)^2\\right]-\\frac{1}{2\\tau^2}(\\theta-\\mu)^2\\right\\} \\end{align} \\] La distribución posterior condicional de \\(\\theta\\) es \\[ \\begin{equation} \\theta \\mid \\sigma^2,\\mathbf{Y} \\sim Normal(\\mu_n,\\tau_n^2) \\end{equation} \\] En donde las expresiones para \\(\\mu_n\\) y \\(\\tau_n^2\\) están dados previamente. Por otro lado, la distribución posterior condicional de \\(\\sigma^2\\) es \\[ \\begin{equation} \\sigma^2 \\mid \\theta,\\mathbf{Y} \\sim Inversa-Gamma\\left(\\dfrac{n_0+n}{2},\\dfrac{v_0}{2}\\right) \\end{equation} \\] con \\(v_0=n_0\\sigma^2_0+(n-1)S^2+n(\\bar{y}-\\theta)^2\\). 4.9.1 Práctica en STAN Sea \\(Y\\) el logaritmo del ingreso dataNormal &lt;- encuesta %&gt;% transmute(dam_ee, logIngreso = log(ingcorte +1)) %&gt;% filter(dam_ee == &quot;08&quot;) Creando código de STAN data { int&lt;lower=0&gt; n; real y[n]; } parameters { real sigma; real theta; } transformed parameters { real sigma2; sigma2 = pow(sigma, 2); } model { y ~ normal(theta, sigma); theta ~ normal(0, 1000); sigma2 ~ inv_gamma(0.001, 0.001); } generated quantities { real ypred[n]; // vector de longitud n for(kk in 1:n){ ypred[kk] = normal_rng(theta,sigma); } } Preparando el código de STAN NormalMeanVar &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/5NormalMeanVar.stan&quot; Organizando datos para STAN sample_data &lt;- list(n = nrow(dataNormal), y = dataNormal$logIngreso) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_NormalMedia &lt;- stan( file = NormalMeanVar, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) La estimación del parámetro \\(\\theta\\) y \\(\\sigma^2\\) es: summary(model_NormalMedia, pars = c(&quot;theta&quot;, &quot;sigma2&quot;, &quot;sigma&quot;))$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 13.1147 1e-04 0.0041 13.1067 13.1119 13.1148 13.1175 13.1226 1127.412 1.0010 sigma2 0.6987 1e-04 0.0046 0.6898 0.6955 0.6987 0.7016 0.7078 1612.814 1.0017 sigma 0.8359 1e-04 0.0028 0.8305 0.8340 0.8359 0.8376 0.8413 1613.833 1.0017 posterior_theta &lt;- as.array(model_NormalMedia, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) posterior_sigma2 &lt;- as.array(model_NormalMedia, pars = &quot;sigma2&quot;) (mcmc_dens_chains(posterior_sigma2) + mcmc_areas(posterior_sigma2) ) / mcmc_trace(posterior_sigma2) posterior_sigma &lt;- as.array(model_NormalMedia, pars = &quot;sigma&quot;) (mcmc_dens_chains(posterior_sigma) + mcmc_areas(posterior_sigma) ) / mcmc_trace(posterior_sigma) y_pred_B &lt;- as.array(model_NormalMedia, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(exp(dataNormal$logIngreso)-1), y_pred2) + xlim(0,5000000) "],["modelo-multinomial.html", "4.10 Modelo Multinomial", " 4.10 Modelo Multinomial En esta sección discutimos el modelamiento bayesiano de datos provenientes de una distribución multinomial que corresponde a una extensión multivariada de la distribución binomial. Suponga que \\(\\textbf{Y}=(Y_1,\\ldots,Y_p)&#39;\\) es un vector aleatorio con distribución multinomial, así, su distribución está parametrizada por el vector \\(\\boldsymbol{\\theta}=(\\theta_1,\\ldots,\\theta_p)&#39;\\) y está dada por la siguiente expresión \\[ \\begin{equation} p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})=\\binom{n}{y_1,\\ldots,y_p}\\prod_{i=1}^p\\theta_i^{y_i} \\ \\ \\ \\ \\ \\theta_i&gt;0 \\texttt{ , } \\sum_{i=1}^py_i=n \\texttt{ y } \\sum_{i=1}^p\\theta_i=1 \\end{equation} \\] Donde \\[ \\begin{equation*} \\binom{n}{y_1,\\ldots,y_p}=\\frac{n!}{y_1!\\cdots y_p!}. \\end{equation*} \\] Como cada parámetro \\(\\theta_i\\) está restringido al espacio \\(\\Theta=[0,1]\\), entonces es posible asignar a la distribución de Dirichlet como la distribución previa del vector de parámetros. Por lo tanto la distribución previa del vector de parámetros \\(\\boldsymbol{\\theta}\\), parametrizada por el vector de hiperparámetros \\(\\boldsymbol{\\alpha}=(\\alpha_1,\\ldots,\\alpha_p)&#39;\\), está dada por \\[ \\begin{equation} p(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\alpha})=\\frac{\\Gamma(\\alpha_1+\\cdots+\\alpha_p)}{\\Gamma(\\alpha_1)\\cdots\\Gamma(\\alpha_p)} \\prod_{i=1}^p\\theta_i^{\\alpha_i-1} \\ \\ \\ \\ \\ \\alpha_i&gt;0 \\texttt{ y } \\sum_{i=1}^p\\theta_i=1 \\end{equation} \\] La distribución posterior del parámetro \\(\\boldsymbol{\\theta}\\) sigue una distribución \\(Dirichlet(y_1+\\alpha_1,\\ldots,y_p+\\alpha_p)\\) 4.10.1 Práctica en STAN Sea \\(Y\\) condición de actividad laboral dataMult &lt;- encuesta %&gt;% filter(condact3 %in% 1:3) %&gt;% transmute( empleo = as_factor(condact3)) %&gt;% group_by(empleo) %&gt;% tally() %&gt;% mutate(theta = n/sum(n)) tba(dataMult) empleo n theta 1 348015 0.5537 2 42045 0.0669 3 238426 0.3794 donde 1 corresponde a Ocupado, 2 son los Desocupado y 3 son Inactivo Creando código de STAN data { int&lt;lower=0&gt; k; // Número de cátegoria int y[k]; // Número de exitos vector[k] alpha; // Parámetro de las distribción previa } parameters { simplex[k] theta; } transformed parameters { real delta; // Tasa de desocupación delta = theta[2]/ (theta[2] + theta[1]); // (Desocupado)/(Desocupado + Ocupado) } model { y ~ multinomial(theta); theta ~ dirichlet(alpha); } generated quantities { int ypred[k]; ypred = multinomial_rng(theta, sum(y)); } Preparando el código de STAN Multinom &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/6Multinom.stan&quot; Organizando datos para STAN sample_data &lt;- list(k = nrow(dataMult), y = dataMult$n, alpha = c(0.5, 0.5, 0.5)) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_Multinom &lt;- stan( file = Multinom, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) La estimación del parámetro \\(\\theta\\) y \\(\\delta\\) es: summary(model_Multinom, pars = c(&quot;delta&quot;, &quot;theta&quot;))$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat delta 0.1078 0 5e-04 0.1068 0.1075 0.1078 0.1082 0.1088 1097.4077 1.0019 theta[1] 0.5537 0 6e-04 0.5525 0.5533 0.5537 0.5542 0.5549 1978.4575 1.0006 theta[2] 0.0669 0 3e-04 0.0663 0.0667 0.0669 0.0671 0.0675 993.4809 1.0020 theta[3] 0.3794 0 6e-04 0.3782 0.3789 0.3794 0.3798 0.3806 1556.6998 1.0007 posterior_theta1 &lt;- as.array(model_Multinom, pars = &quot;theta[1]&quot;) (mcmc_dens_chains(posterior_theta1) + mcmc_areas(posterior_theta1) ) / mcmc_trace(posterior_theta1) posterior_theta2 &lt;- as.array(model_Multinom, pars = &quot;theta[2]&quot;) (mcmc_dens_chains(posterior_theta2) + mcmc_areas(posterior_theta2) ) / mcmc_trace(posterior_theta2) posterior_theta3 &lt;- as.array(model_Multinom, pars = &quot;theta[3]&quot;) (mcmc_dens_chains(posterior_theta3) + mcmc_areas(posterior_theta3) ) / mcmc_trace(posterior_theta3) posterior_delta &lt;- as.array(model_Multinom, pars = &quot;delta&quot;) (mcmc_dens_chains(posterior_delta) + mcmc_areas(posterior_delta) ) / mcmc_trace(posterior_delta) La imagen es muy pesada no se carga al repositorio. n &lt;- nrow(dataMult) y_pred_B &lt;- as.array(model_Multinom, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 50) y_pred2 &lt;- y_pred_B[, 1:n] ppc_dens_overlay(y = as.numeric(dataMult$n), y_pred2) "],["día-2---sesión-1--estimaciones-geih-y-función-generalizada-de-varianza.html", "Capítulo 5 Día 2 - Sesión 1- Estimaciones GEIH y Función Generalizada de Varianza", " Capítulo 5 Día 2 - Sesión 1- Estimaciones GEIH y Función Generalizada de Varianza Uno de los insumos más importantes en el modelo de áreas es la varianza del estimador directo, a nivel de dominio, la cual no puede calcularse de ningún modo. En correspondencia, este valor debe estimarse desde los datos recolectados en cada dominio. Sin embargo, en dominios en las que se cuenta con un tamaño de muestra muy pequeño, estas estimaciones no tendrán un buen comportamiento. Por ende, es muy útil utilizar un modelo de suavizamiento de las varianzas para eliminar el ruido y la volatilidad de estas estimaciones y extraer la verdadera señal del proceso Hidiroglou (2019) afirma que \\(E_{mp}\\left(\\hat{\\theta}^{dir}_d\\right)=\\boldsymbol{x}_{d}\\boldsymbol{\\beta}\\) y \\(V_{mp}\\left(\\hat{\\theta}^{dir}_d\\right)=\\sigma_{u}^2+\\tilde{\\psi}^2_{d}\\), en donde el subíndice \\(mp\\) hace referencia a la inferencia doble que se debe tener en cuenta en este tipo de ajustes y define la medida de probabilidad conjunta entre el modelo y el diseño de muestreo. \\(m\\) hace referencia a la medida de probabilidad inducida por el modelamiento y la inclusión de las covariables auxiliares (\\(\\boldsymbol{x}_{d}\\)). \\(p\\) hacer referencia a la medida de probabilidad inducida por el diseño de muestreo complejo que induce las estimaciones directas. La solución que acá se plantea se conoce con el nombre de Función Generalizada de Varianza, la cual consiste en ajustar un modelo log-lineal a la varianza directa estimada. Partiendo del hecho de que se tiene acceso a un estimador insesgado de \\(\\psi^2\\), denotado por \\(\\hat{\\psi}^2\\) se tiene que: \\[ E_{mp}\\left(\\hat{\\psi}_{d}^{2}\\right)=E_{m}\\left(E_{p}\\left(\\psi_{d}^{2}\\right)\\right)=E_{m}\\left(\\psi_{d}^{2}\\right)=\\tilde{\\psi}_{d}^{2} \\] La anterior igualdad puede interpretarse como que un estimador insesgado y simple de \\(\\tilde{\\psi}_{d}^{2}\\) puede ser \\(\\hat{\\psi}_{d}^{2}\\). Sin embargo, este estimador de muestreo es inestable cuando el tamaño de muestra es pequeño, que es justo el paradigma dominante en la estimación de áreas pequeñas. Rivest and Belmonte (2000) consideran modelos de suavizamiento para la estimación de las varianzas directas definidos de la siguiente manera: \\[ \\log\\left(\\hat{\\psi}_{d}^{2}\\right)=\\boldsymbol{z}_{d}^{t}\\boldsymbol{\\alpha}+\\boldsymbol{\\varepsilon}_{d} \\] En donde \\(\\boldsymbol{z}_{d}\\) es un vector de covariables explicativas que son funciones de \\(\\boldsymbol{x}_{d}\\), \\(\\boldsymbol{\\alpha}\\) es un vector de parámetros que deben ser estimados, \\(\\boldsymbol{\\varepsilon}_{d}\\) son errores aleatorios con media cero y varianza constante, que se asumen idénticamente distribuidos condicionalmente sobre \\(\\boldsymbol{z}_{d}\\). Del anterior modelo, la estimación suavizada de la varianza de muestreo está dada por: \\[ \\tilde{\\psi}_{d}^{2}=E_{mp}\\left(\\psi_{d}^{2}\\right)=\\exp\\left(\\boldsymbol{z}_{d}^{t}\\boldsymbol{\\alpha}\\right)\\times\\Delta \\] En donde, \\(E_{mp}\\left(\\varepsilon_{d}\\right)=\\Delta\\). No hay necesidad de especificar una distribución paramétrica para los errores de este modelo. Al utilizar el método de los momentos, se tiene el siguiente estimador insesgado para \\(\\Delta\\): \\[ \\hat{\\Delta}=\\frac{\\sum_{d=1}^{D}\\hat{\\psi}_{d}^{2}}{\\sum_{d=1}^{D}\\exp\\left(\\boldsymbol{z}_{d}^{t}\\boldsymbol{\\alpha}\\right)} \\] De la misma forma, al utilizar los procedimientos estándar en una regresión lineal, la estimación del coeficiente de parámetros de regresión está dada por la siguiente expresión: \\[ \\hat{\\boldsymbol{\\alpha}}=\\left(\\sum_{d=1}^{D}\\boldsymbol{z}_{d}\\boldsymbol{z}_{d}^{t}\\right)^{-1}\\sum_{d=1}^{D}\\boldsymbol{z}_{d}\\log\\left(\\hat{\\psi}_{d}^{2}\\right) \\] Por último, el estimador suavizado de la varianza muestral está definido por: \\[ \\hat{\\tilde{\\psi}}_{d}^{2}=\\exp\\left(\\boldsymbol{z}_{d}^{t}\\hat{\\boldsymbol{\\alpha}}\\right)\\hat{\\Delta} \\] "],["datos-de-la-encuesta.html", "5.1 Datos de la encuesta", " 5.1 Datos de la encuesta El siguiente bloque de código utiliza varias librerías en R (tidyverse y magrittr), así como también utiliza una función definida en otro archivo (source(“Recursos/Día2/Sesion1/0Recursos/0Source_FH.R”)). Luego, el código carga la encuesta que esta almacenada en un archivo de datos en formato RDS y utiliza la función %&gt;% para encadenar una serie de transformaciones en los datos: transmute() se utiliza para seleccionar y renombrar columnas. En este caso, se seleccionan las columnas dam_ee, dam2, _fep y segmento, y se renombran a dam, dam2, wkx, y upm, respectivamente. Se crea una nueva variable llamada estrato que combina la variable dam con la variable area_ee después de convertir area_ee en una variable de factor utilizando haven::as_factor(). La función paste0() se utiliza para concatenar las dos variables. Se crea una nueva variable llamada pobreza que se establece en 1 si la variable ingcorte(ingreso percapital) es menor que la variable lp, y en 0 en caso contrario. La función ifelse() se utiliza para asignar valores a la variable “pobreza” en función de si el ingreso de un individuo es menor o mayor que el umbral de pobreza. library(tidyverse) library(magrittr) source(&quot;Recursos/Día2/Sesion1/0Recursos/0Source_FH.R&quot;) encuesta &lt;- readRDS(&quot;Recursos/Día2/Sesion1/Data/encuestaCOL18N1.rds&quot;) %&gt;% transmute( dam = dam_ee, dam2, wkx = `_fep`, upm = segmento, estrato = paste0(dam, haven::as_factor(area_ee,levels = &quot;values&quot;)), pobreza = ifelse(ingcorte &lt; lp, 1 , 0)) dam: Corresponde al código asignado a la división administrativa mayor del país. dam2: Corresponde al código asignado a la segunda división administrativa del país. lp linea de pobreza definida por CEPAL. Factor de expansión por persona (wkx) dam dam2 wkx upm estrato pobreza 05 05360 127.2220 010126005360 051 0 05 05360 127.2220 010126005360 051 0 05 05360 127.2220 010126005360 051 0 05 05360 127.2220 010126005360 051 0 05 05360 127.2220 010126005360 051 0 05 05360 125.7202 010126005360 051 1 05 05360 125.7202 010126005360 051 1 05 05360 125.7202 010126005360 051 1 05 05360 125.7202 010126005360 051 1 05 05360 115.8661 010126005360 051 1 Definir el diseño muestral haciendo uso de las librerías srvyr y survey library(survey) library(srvyr) options(survey.lonely.psu = &quot;adjust&quot;) diseno &lt;- as_survey_design( ids = upm, weights = wkx, strata = estrato, nest = TRUE, .data = encuesta ) summary(diseno) ## Stratified 1 - level Cluster Sampling design (with replacement) ## With (21869) clusters. ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.001089 0.012313 0.037623 0.057119 0.080947 0.783027 ## Stratum Sizes: ## 051 052 081 082 111 112 131 132 151 152 171 172 ## obs 41761 3706 43299 1022 32177 36 32757 2853 23299 3186 27959 2805 ## design.PSU 1247 123 926 29 972 1 828 83 762 131 905 101 ## actual.PSU 1247 123 926 29 972 1 828 83 762 131 905 101 ## 181 182 191 192 201 202 231 232 251 252 271 272 ## obs 23698 5144 28826 5531 30225 2229 29181 2805 6271 2797 22812 4016 ## design.PSU 760 130 852 180 832 81 650 83 181 106 699 140 ## actual.PSU 760 130 852 180 832 81 650 83 181 106 699 140 ## 411 412 441 442 471 472 501 502 521 522 541 542 ## obs 27446 3282 32062 3556 34690 2944 26381 2936 24656 4271 27554 3830 ## design.PSU 866 105 790 120 889 84 803 96 734 131 793 134 ## actual.PSU 866 105 790 120 889 84 803 96 734 131 793 134 ## 631 632 661 662 681 682 701 702 731 732 761 762 ## obs 26616 1660 25945 3254 28390 3388 32471 3054 25315 3101 35065 2491 ## design.PSU 864 55 818 103 749 108 737 96 788 91 1027 86 ## actual.PSU 864 55 818 103 749 108 737 96 788 91 1027 86 ## Data variables: ## [1] &quot;dam&quot; &quot;dam2&quot; &quot;wkx&quot; &quot;upm&quot; &quot;estrato&quot; &quot;pobreza&quot; Para la estimación directa de la proporción se emplea la función direct.supr, disponible en el archivo 0Source_FH.R. Está función realiza las estimaciones y criterios de calidad en una encuesta de muestreo complejo con diseño estratificado y por conglomerados. Toma cinco argumentos: design.base, variable, group, upm y estrato. La función comienza cargando varios paquetes, como rlang, tidyverse, dplyr, survey y srvyr. Luego, los argumentos group, variable, upm y estrato se convierten en argumentos utilizando la función enquo. La función utiliza la encuesta de muestreo complejo design.base para calcular las estimaciones de los parámetros y los criterios de calidad. Utiliza la función survey_mean() de la librería survey para calcular la media y los intervalos de confianza de la variable de interés. La función también calcula otros indicadores de calidad, como el coeficiente de variación, el tamaño de muestra efectivo y el efecto del diseño. Luego, utiliza la función as.data.frame() para convertir los resultados en un objeto de marco de datos. Además, la función calcula otros criterios de calidad para determinar si las estimaciones son confiables. En particular, evalúa si se cumple un umbral mínimo para el número de grados de libertad, si la muestra es suficientemente grande y si el efecto del diseño es razonable. La función también tiene la opción de incluir o excluir ciertos grupos de muestreo basados en sus características. directodam2 &lt;- direct.supr(design.base = diseno, variable = pobreza, group = dam2, upm = upm, estrato = estrato) directodam2 %&gt;% group_by(Flag) %&gt;% summarise(n = n()) %&gt;% arrange(n) %&gt;% tba() Flag n Excluir 59 Incluir 379 Para los dominios que no son excluidos se hace la transformación arcoseno, calculo del DEFF y varianza base_sae &lt;- directodam2 %&gt;% filter(Flag != &quot;Excluir&quot;) %&gt;% transmute( dam2 = dam2, # Id para los dominios nd = n, # Número de observaciones por dominios n_effec = n.eff, # n efectivo. pobreza = p, # Estimación de la variable pobreza_T = asin(sqrt(pobreza)), # Transformación arcoseno vardir = ee ^ 2, # Estimación de la varianza directa cv = CV, var_zd = 1 / (4 * n_effec), # Varianza para la tranformación arcsin deff_dam2 = deff # Deff por dominio ) # View(base_sae) tba(head(base_sae)) dam2 nd n_effec pobreza pobreza_T vardir cv var_zd deff_dam2 05001 27432 1914.8077 0.1597 0.4111 0.0000 4.1932 0.0001 14.3262 05002 257 21.3006 0.4049 0.6897 0.0032 14.0276 0.0117 12.0654 05031 199 7.8051 0.3817 0.6660 0.0042 17.0554 0.0320 25.4963 05034 223 25.8934 0.4731 0.7585 0.0018 8.8997 0.0097 8.6122 05045 480 5.0044 0.2876 0.5661 0.0064 27.9009 0.0500 95.9148 05079 191 22.5008 0.4001 0.6848 0.0063 19.8514 0.0111 8.4886 seguidamente se realiza la transformación \\(\\log(\\hat{\\sigma}^2_d)\\), además se realiza la selección de las columnas identificador del municipio (dam2), la estimación directa (pobreza), El número de personas en el dominio (nd) y la varianza estimada del para la estimación directa vardir,siendo esta la que transforma mediante la función log(). baseFGV &lt;- base_sae %&gt;% select(dam2, pobreza, nd, vardir) %&gt;% mutate(ln_sigma2 = log(vardir)) "],["análisis-gráfico.html", "5.2 Análisis gráfico", " 5.2 Análisis gráfico El primer gráfico, p1, muestra una gráfica de dispersión de la variable ln_sigma2 en función de la variable pobreza, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como pobreza. El segundo gráfico, p2, muestra una gráfica de dispersión de la variable ln_sigma2 en función de la variable nd, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como Tamaño de muestra. El tercer gráfico, p3, muestra una gráfica de dispersión de la variable ln_sigma2 en función del producto de pobreza y nd, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como Número de pobres. El cuarto gráfico, p4, muestra una gráfica de dispersión de la variable ln_sigma2 en función de la raíz cuadrada de la variable pobreza, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como Raiz cuadrada de pobreza. En general, los gráficos estan diseñados para explorar la relación entre ln_sigma2 y diferentes variables independientes, como pobreza, nd, y la raíz cuadrada de la pobreza. La elección de utilizar la función “loess” para suavizar las líneas en lugar de una línea recta puede ayudar a visualizar mejor las tendencias generales en los datos. theme_set(theme_bw()) # pobreza vs Ln_sigma2 # p1 &lt;- ggplot(baseFGV, aes(x = pobreza, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;pobreza&quot;) # Tamaño de muestra vs Ln_sigma2 # p2 &lt;- ggplot(baseFGV, aes(x = nd, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Tamaño de muestra&quot;) # Número de pobres vs Ln_sigma2 # p3 &lt;- ggplot(baseFGV, aes(x = pobreza * nd, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Número de pobres&quot;) # Raiz_pobreza vs Ln_sigma2 # p4 &lt;- ggplot(baseFGV, aes(x = sqrt(pobreza), y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Raiz cuadrada de pobreza&quot;) library(patchwork) (p1 | p2) / (p3 | p4) "],["modelo-para-la-varianza.html", "5.3 Modelo para la varianza", " 5.3 Modelo para la varianza El código ajusta un modelo de regresión lineal múltiple (utilizando la función lm()), donde ln_sigma2 es la variable respuesta y las variables predictoras son pobreza, nd, y varias transformaciones de éstas. El objetivo de este modelo es estimar la función generalizada de varianza (FGV) para los dominios observados. library(gtsummary) FGV1 &lt;- lm(ln_sigma2 ~ pobreza + I(nd^2) + I(sqrt(pobreza)), data = baseFGV) tbl_regression(FGV1) %&gt;% add_glance_table(include = c(r.squared, adj.r.squared)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #srxmuctavx .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #srxmuctavx .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #srxmuctavx .gt_caption { padding-top: 4px; padding-bottom: 4px; } #srxmuctavx .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #srxmuctavx .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #srxmuctavx .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #srxmuctavx .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #srxmuctavx .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #srxmuctavx .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #srxmuctavx .gt_column_spanner_outer:first-child { padding-left: 0; } #srxmuctavx .gt_column_spanner_outer:last-child { padding-right: 0; } #srxmuctavx .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #srxmuctavx .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #srxmuctavx .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #srxmuctavx .gt_from_md > :first-child { margin-top: 0; } #srxmuctavx .gt_from_md > :last-child { margin-bottom: 0; } #srxmuctavx .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #srxmuctavx .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #srxmuctavx .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #srxmuctavx .gt_row_group_first td { border-top-width: 2px; } #srxmuctavx .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #srxmuctavx .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #srxmuctavx .gt_first_summary_row.thick { border-top-width: 2px; } #srxmuctavx .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #srxmuctavx .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #srxmuctavx .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #srxmuctavx .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #srxmuctavx .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #srxmuctavx .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #srxmuctavx .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #srxmuctavx .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #srxmuctavx .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #srxmuctavx .gt_left { text-align: left; } #srxmuctavx .gt_center { text-align: center; } #srxmuctavx .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #srxmuctavx .gt_font_normal { font-weight: normal; } #srxmuctavx .gt_font_bold { font-weight: bold; } #srxmuctavx .gt_font_italic { font-style: italic; } #srxmuctavx .gt_super { font-size: 65%; } #srxmuctavx .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #srxmuctavx .gt_asterisk { font-size: 100%; vertical-align: 0; } #srxmuctavx .gt_indent_1 { text-indent: 5px; } #srxmuctavx .gt_indent_2 { text-indent: 10px; } #srxmuctavx .gt_indent_3 { text-indent: 15px; } #srxmuctavx .gt_indent_4 { text-indent: 20px; } #srxmuctavx .gt_indent_5 { text-indent: 25px; } Characteristic Beta 95% CI1 p-value pobreza -12 -14, -9.5 I(nd^2) 0.00 0.00, 0.00 I(sqrt(pobreza)) 16 14, 19 R² 0.608 Adjusted R² 0.604 1 CI = Confidence Interval Después de tener la estimación del modelo se debe obtener el valor de la constante \\(\\Delta\\) para lo cual se usa el siguiente código. delta.hat = sum(baseFGV$vardir) / sum(exp(fitted.values(FGV1))) De donde se obtiene que \\(\\Delta = 1.303171\\). Final es posible obtener la varianza suavizada ejecutando el siguiente comando. hat.sigma &lt;- data.frame(dam2 = baseFGV$dam2, hat_var = delta.hat * exp(fitted.values(FGV1))) baseFGV &lt;- left_join(baseFGV, hat.sigma) tba(head(baseFGV, 10)) dam2 pobreza nd vardir ln_sigma2 hat_var 05001 0.1597 27432 0.0000 -10.0123 0.0001 05002 0.4049 257 0.0032 -5.7366 0.0060 05031 0.3817 199 0.0042 -5.4635 0.0058 05034 0.4731 223 0.0018 -6.3351 0.0062 05045 0.2876 480 0.0064 -5.0451 0.0047 05079 0.4001 191 0.0063 -5.0660 0.0060 05088 0.1314 4457 0.0002 -8.5360 0.0016 05093 0.3273 168 0.0063 -5.0724 0.0052 05120 0.7049 180 0.0061 -5.0921 0.0048 05129 0.1140 554 0.0014 -6.5515 0.0014 Validación del modelo para la FGV par(mfrow = c(2, 2)) plot(FGV1) Comparación entre la varianza estimada versus la pronosticada por la FGV ggplot(baseFGV , aes(y = vardir, x = hat_var)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + labs(x = &quot;FGV&quot;, y = &quot;VarDirEst&quot;) + ylab(&quot;Varianza del Estimador Directo&quot;) Predicción de la varianza suavizada base_sae &lt;- base_sae %&gt;% left_join(hat.sigma, by = &quot;dam2&quot;) El siguiente código utiliza la función mutate() del paquete dplyr para crear nuevas variables de la base de datos base_sae y luego guarda el resultado en un archivo RDS llamado base_FH_2018.rds. En concreto, el código realiza las siguientes operaciones: La variable deff_dam2 se ajusta a 1 cuando es NaN. La variable deff_FGV se calcula a partir de otras dos variables hat_var y vardir. Si vardir es 0, entonces deff_FGV se ajusta a 1. En caso contrario, se divide hat_var por vardir / deff_dam2 para obtener deff_FGV. La variable deff_FGV se regulariza utilizando el criterio MDS: si deff_FGV es menor que 1, se ajusta a 1. Finalmente, se calcula la variable n_eff_FGV dividiendo nd (el tamaño de la muestra) por deff_FGV. base_FH &lt;- base_sae %&gt;% mutate( deff_dam2 = ifelse(is.nan(deff_dam2), 1, deff_dam2), deff_FGV = ifelse( vardir == 0 , 1, hat_var / (vardir / deff_dam2) ), # Criterio MDS para regularizar el DeffFGV deff_FGV = ifelse(deff_FGV &lt; 1, 1, deff_FGV), n_eff_FGV = nd / deff_FGV ) saveRDS(object = base_FH, &quot;Recursos/Día2/Sesion1/Data/base_FH_2018.rds&quot;) "],["día-2---sesión-2--modelo-de-fay-herriot---estimación-de-la-pobreza.html", "Capítulo 6 Día 2 - Sesión 2- Modelo de Fay Herriot - Estimación de la pobreza", " Capítulo 6 Día 2 - Sesión 2- Modelo de Fay Herriot - Estimación de la pobreza El modelo de Fay Herriot FH, propuesto por Fay y Herriot (1979), es un modelo estadístico de área y es el más comúnmente utilizado, cabe tener en cuenta, que dentro de la metodología de estimación en áreas pequeñas, los modelos de área son los de mayor aplicación, ya que lo más factible es no contar con la información a nivel de individuo, pero si encontrar no solo los datos a nivel de área, sino también información auxiliar asociada a estos datos. Este modelo lineal mixto, fue el primero en incluir efectos aleatorios a nivel de área, lo que implica que la mayoría de la información que se introduce al modelo corresponde a agregaciaciones usualmente, departamentos, regiones, provincias, municipios entre otros, donde las estimaciones que se logran con el modelo se obtienen sobre estas agregaciones o subpoblaciones. El modelo FH enlaza indicadores de las áreas \\(\\delta_d\\), \\(d = 1, \\cdots , D\\), asumiendo que varían respeto a un vector de \\(p\\) covariables, \\(\\boldsymbol{x}_d\\) , de forma constante. El modelo esta dado por la ecuación \\[ \\delta_d = \\boldsymbol{x^T}_d\\boldsymbol{\\beta} + u_d ,\\ \\ \\ \\ \\ d = 1, \\cdots , D \\] \\(u_d\\) es el término de error, o el efecto aleatorio, diferente para cada área dado por \\[ \\begin{eqnarray*} u_{d} &amp; \\stackrel{iid}{\\sim} &amp; \\left(0,\\sigma_{u}^{2}\\right) \\end{eqnarray*} \\] Sin embargo, los verdaderos valores de los indicadores \\(\\delta_d\\) no son observables. Entonces, usamos el estimador directo \\(\\hat{\\delta}^{DIR}_d\\) para \\(\\delta_d\\) , lo que conlleva un error debido al muestro. \\(\\hat{\\delta}^{DIR}_d\\) todavía se considera insesgado bajo el diseño muestral. Podemos definir, entonces, \\[ \\hat{\\delta}^{DIR}_d = \\delta_d + e_d, \\ \\ \\ \\ \\ \\ d = 1, \\cdots , D \\] donde \\(e_d\\) es el error debido al muestreo, \\(e_{d} \\stackrel{ind}{\\sim} \\left(0,\\psi\\right)\\) Dichas varianzas \\(\\psi_d = var_{\\pi}\\left(\\hat{\\delta}^{DIR}_d\\mid\\delta_d\\right)\\), \\(d = 1,\\cdots,D\\) se estiman con los microdatos de la encuesta. Por tanto, el modelo se hace, \\[ \\hat{\\delta}^{DIR}_d = \\boldsymbol{x^T}_d\\boldsymbol{\\beta} + u_d + e_d, \\ \\ \\ \\ \\ \\ d = 1, \\cdots , D \\] El BLUP (best linear unbiased predictor) bajo el modelo FH de \\(\\delta_d\\) viene dado por \\[ \\begin{eqnarray*} \\tilde{\\delta}_{d}^{FH} &amp; = &amp; \\boldsymbol{x_d}^{T}\\tilde{\\boldsymbol{\\beta}}+\\tilde{u}_{d} \\end{eqnarray*} \\] Si sustituimos \\(\\tilde{u}_d = \\gamma_d\\left(\\hat{\\delta}^{DIR}_d - \\boldsymbol{x_d}^{T}\\tilde{\\boldsymbol{\\beta}} \\right)\\) en el BLUP bajo el modelo FH, obtenemos \\[ \\begin{eqnarray*} \\tilde{\\delta}_{d}^{FH} &amp; = &amp; \\gamma_d\\hat{\\delta}^{DIR}_{d}+(1-\\gamma_d)\\boldsymbol{x_d}^{T}\\tilde{\\boldsymbol{\\beta}} \\end{eqnarray*} \\] siendo \\(\\gamma_d=\\frac{\\sigma^2_u}{\\sigma^2_u + \\psi_d}\\). Habitualmente, no sabemos el verdadero valor de \\(\\sigma^2_u\\) efectos aleatorios \\(u_d\\). Sea \\(\\hat{\\sigma}^2_u\\) un estimador consistente para \\(\\sigma^2_u\\). Entonces, obtenemos el BLUP empírico (empirical BLUP, EBLUP) de \\(\\delta_d\\) , \\[ \\begin{eqnarray*} \\tilde{\\delta}_{d}^{FH} &amp; = &amp; \\hat{\\gamma_d}\\hat{\\delta}^{DIR}_{d}+(1-\\hat{\\gamma_d})\\boldsymbol{x_d}^{T}\\hat{\\boldsymbol{\\beta}} \\end{eqnarray*} \\] donde \\(\\hat{\\gamma_d}=\\frac{\\hat{\\sigma}^2_u}{\\hat{\\sigma}^2_u + \\psi_d}\\). \\[ \\begin{eqnarray*} Y\\mid\\mu,\\sigma_{e} &amp; \\sim &amp; N\\left(\\mu,\\sigma_{e}\\right)\\\\ \\mu &amp; = &amp; \\boldsymbol{X\\beta}+V \\end{eqnarray*} \\] donde \\(V \\sim N(0 , \\sigma_v)\\). Las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma^2_v\\) \\[ \\begin{eqnarray*} \\beta_k &amp; \\sim &amp; N(0, 10000)\\\\ \\sigma^2_v &amp;\\sim &amp; IG(0.0001, 0.0001) \\end{eqnarray*} \\] "],["procedimiento-de-estimación.html", "6.1 Procedimiento de estimación", " 6.1 Procedimiento de estimación Este código utiliza las librerías tidyverse y magrittr para procesamiento y analizar datos. La función readRDS() es utilizada para cargar un archivo de datos en formato RDS, que contiene las estimaciones directas y la varianza suvizada para la proporción de personas en condición de pobreza correspondientes al año 2018. Luego, se utiliza el operador %&gt;% de la librería magrittr para encadenar la selección de las columnas de interés, que corresponden a los nombres dam2, nd, pobreza, vardir y hat_var. library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día2/Sesion2/Data/base_FH_2018.rds&quot;) %&gt;% select(dam2, nd, pobreza, vardir, hat_var) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día2/Sesion2/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Ahora, se realiza una unión completa (full_join) entre el conjunto de datos base_FH y los predictores statelevel_predictors_df utilizando la variable dam2 como clave de unión. Se utiliza la función tba() para imprimir las primeras 10 filas y 8 columnas del conjunto de datos resultante de la unión anterior. La unión completa (full_join) combina los datos de ambos conjuntos, manteniendo todas las filas de ambos, y llenando con valores faltantes (NA) en caso de no encontrar coincidencias en la variable de unión (dam2 en este caso). La función tba() imprime una tabla en formato HTML en la consola de R que muestra las primeras 10 filas y 8 columnas del conjunto de datos resultante de la unión. base_FH &lt;- full_join(base_FH, statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[1:10,1:8]) dam2 nd pobreza vardir hat_var dam area1 sexo2 05001 27432 0.1597 0.0000 0.0001 05 0.9832 0.5299 05002 257 0.4049 0.0032 0.0060 05 0.3953 0.4807 05031 199 0.3817 0.0042 0.0058 05 0.5766 0.4978 05034 223 0.4731 0.0018 0.0062 05 0.5029 0.4815 05045 480 0.2876 0.0064 0.0047 05 0.8091 0.5078 05079 191 0.4001 0.0063 0.0060 05 0.4821 0.5038 05088 4457 0.1314 0.0002 0.0016 05 0.9569 0.5186 05093 168 0.3273 0.0063 0.0052 05 0.2776 0.4862 05120 180 0.7049 0.0061 0.0048 05 0.1989 0.4787 05129 554 0.1140 0.0014 0.0014 05 0.8065 0.5202 # View(base_FH) "],["preparando-los-insumos-para-stan.html", "6.2 Preparando los insumos para STAN", " 6.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados. Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[1:10,1:8]) dam2 nd pobreza vardir hat_var dam area1 sexo2 05004 NA NA NA NA 05 0.3279 0.4576 05021 NA NA NA NA 05 0.5770 0.5020 05030 NA NA NA NA 05 0.4859 0.5063 05036 NA NA NA NA 05 0.3931 0.4951 05038 NA NA NA NA 05 0.2256 0.4927 05040 NA NA NA NA 05 0.4858 0.4826 05042 NA NA NA NA 05 0.6688 0.5031 05044 NA NA NA NA 05 0.1847 0.4828 05051 NA NA NA NA 05 0.3660 0.4970 05055 NA NA NA NA 05 0.4431 0.4825 Definir matriz de efectos fijos. Define un modelo lineal utilizando la función formula(), que incluye varias variables predictoras, como la edad, la etnia, la tasa de desocupación, entre otras. Utiliza la función model.matrix() para generar matrices de diseño (Xdat y Xs) a partir de los datos observados (data_dir) y no observados (data_syn) para utilizar en la construcción de modelos de regresión. La función model.matrix() convierte las variables categóricas en variables binarias (dummy), de manera que puedan ser utilizadas. formula_mod &lt;- formula(~ sexo2 + anoest2 + anoest3 + anoest4 + edad2 + edad3 + edad4 + edad5 + etnia1 + etnia2 + tasa_desocupacion + luces_nocturnas + cubrimiento_cultivo + alfabeta) ## Dominios observados Xdat &lt;- model.matrix(formula_mod, data = data_dir) ## Dominios no observados Xs &lt;- model.matrix(formula_mod, data = data_syn) Ahora, se utiliza la función setdiff() para identificar las columnas de Xdat que no están presentes en \\(X_s\\), es decir, las variables que no se encuentran en los datos no observados. A continuación, se crea una matriz temporal (temp) con ceros para las columnas faltantes de \\(X_s\\), y se agregan estas columnas a \\(X_s\\) utilizando cbind(). El resultado final es una matriz Xs con las mismas variables que Xdat, lo que asegura que se puedan realizar comparaciones adecuadas entre los datos observados y no observados en la construcción de modelos de regresión. En general, este código es útil para preparar los datos para su posterior análisis y asegurar que los modelos de regresión sean adecuados para su uso. temp &lt;- setdiff(colnames(Xdat),colnames(Xs)) temp &lt;- matrix( 0, nrow = nrow(Xs), ncol = length(temp), dimnames = list(1:nrow(Xs), temp) ) Xs &lt;- cbind(Xs,temp)[,colnames(Xdat)] Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados y = as.numeric(data_dir$pobreza), # Estimación directa sigma_e = sqrt(data_dir$hat_var) # Error de estimación ) Rutina implementada en STAN data { int&lt;lower=0&gt; N1; // number of data items int&lt;lower=0&gt; N2; // number of data items for prediction int&lt;lower=0&gt; p; // number of predictors matrix[N1, p] X; // predictor matrix matrix[N2, p] Xs; // predictor matrix vector[N1] y; // predictor matrix vector[N1] sigma_e; // known variances } // The parameters accepted by the model. Our model // accepts two parameters &#39;mu&#39; and &#39;sigma&#39;. parameters { vector[p] beta; // coefficients for predictors real&lt;lower=0&gt; sigma2_v; vector[N1] v; } transformed parameters{ vector[N1] theta; vector[N1] thetaSyn; vector[N1] thetaFH; vector[N1] gammaj; real&lt;lower=0&gt; sigma_v; thetaSyn = X * beta; theta = thetaSyn + v; sigma_v = sqrt(sigma2_v); gammaj = to_vector(sigma_v ./ (sigma_v + sigma_e)); thetaFH = (gammaj) .* y + (1-gammaj).*thetaSyn; } model { // likelihood y ~ normal(theta, sigma_e); // priors beta ~ normal(0, 100); v ~ normal(0, sigma_v); sigma2_v ~ inv_gamma(0.0001, 0.0001); } generated quantities{ vector[N2] y_pred; for(j in 1:N2) { y_pred[j] = normal_rng(Xs[j] * beta, sigma_v); } } Compilando el modelo en STAN. A continuación mostramos la forma de compilar el código de STAN desde R. En este código se utiliza la librería rstan para ajustar un modelo bayesiano utilizando el archivo 17FH_normal.stan que contiene el modelo escrito en el lenguaje de modelado probabilístico Stan. En primer lugar, se utiliza la función stan() para ajustar el modelo a los datos de sample_data. Los argumentos que se pasan a stan() incluyen el archivo que contiene el modelo (fit_FH_normal), los datos (sample_data), y los argumentos para controlar el proceso de ajuste del modelo, como el número de iteraciones para el período de calentamiento (warmup) y el período de muestreo (iter), y el número de núcleos de la CPU para utilizar en el proceso de ajuste (cores). Además, se utiliza la función parallel::detectCores() para detectar automáticamente el número de núcleos disponibles en la CPU, y se establece la opción mc.cores para aprovechar el número máximo de núcleos disponibles para el ajuste del modelo. El resultado del ajuste del modelo es almacenado en model_FH_normal, que contiene una muestra de la distribución posterior del modelo, la cual puede ser utilizada para realizar inferencias sobre los parámetros del modelo y las predicciones. En general, este código es útil para ajustar modelos bayesianos utilizando Stan y realizar inferencias posteriores. library(rstan) fit_FH_normal &lt;- &quot;Recursos/Día2/Sesion2/Data/modelosStan/17FH_normal.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_normal &lt;- stan( file = fit_FH_normal, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(object = model_FH_normal, file = &quot;Recursos/Día2/Sesion2/Data/model_FH_normal.rds&quot;) Leer el modelo model_FH_normal&lt;- readRDS(&quot;Recursos/Día2/Sesion2/Data/model_FH_normal.rds&quot;) 6.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(posterior) library(patchwork) y_pred_B &lt;- as.array(model_FH_normal, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma^2_V\\). posterior_sigma2_v &lt;- as.array(model_FH_normal, pars = &quot;sigma2_v&quot;) (mcmc_dens_chains(posterior_sigma2_v) + mcmc_areas(posterior_sigma2_v) ) / mcmc_trace(posterior_sigma2_v) Como método de validación se comparan las diferentes elementos de la estimación del modelo de FH obtenidos en STAN theta &lt;- summary(model_FH_normal,pars = &quot;theta&quot;)$summary %&gt;% data.frame() thetaSyn &lt;- summary(model_FH_normal,pars = &quot;thetaSyn&quot;)$summary %&gt;% data.frame() theta_FH &lt;- summary(model_FH_normal,pars = &quot;thetaFH&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate( thetadir = pobreza, theta_pred = theta$mean, thetaSyn = thetaSyn$mean, thetaFH = theta_FH$mean, theta_pred_EE = theta$sd, Cv_theta_pred = theta_pred_EE/theta_pred ) # Estimación predicción del modelo vs ecuación ponderada de FH p11 &lt;- ggplot(data_dir, aes(x = theta_pred, y = thetaFH)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) # Estimación con la ecuación ponderada de FH Vs estimación sintética p12 &lt;- ggplot(data_dir, aes(x = thetaSyn, y = thetaFH)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) # Estimación con la ecuación ponderada de FH Vs estimación directa p21 &lt;- ggplot(data_dir, aes(x = thetadir, y = thetaFH)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) # Estimación directa Vs estimación sintética p22 &lt;- ggplot(data_dir, aes(x = thetadir, y = thetaSyn)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) (p11+p12)/(p21+p22) Estimación del FH de la pobreza en los dominios NO observados. theta_syn_pred &lt;- summary(model_FH_normal,pars = &quot;y_pred&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate( theta_pred = theta_syn_pred$mean, thetaSyn = theta_pred, thetaFH = theta_pred, theta_pred_EE = theta_syn_pred$sd, Cv_theta_pred = theta_pred_EE/theta_pred) tba(data_syn %&gt;% slice(1:10) %&gt;% select(dam2:hat_var,theta_pred:Cv_theta_pred)) dam2 nd pobreza vardir hat_var theta_pred thetaSyn thetaFH theta_pred_EE Cv_theta_pred 05004 NA NA NA NA 0.3515 0.3515 0.3515 0.1055 0.3002 05021 NA NA NA NA 0.4323 0.4323 0.4323 0.1045 0.2419 05030 NA NA NA NA 0.2837 0.2837 0.2837 0.1027 0.3620 05036 NA NA NA NA 0.3843 0.3843 0.3843 0.1013 0.2636 05038 NA NA NA NA 0.5248 0.5248 0.5248 0.1028 0.1959 05040 NA NA NA NA 0.5419 0.5419 0.5419 0.1037 0.1913 05042 NA NA NA NA 0.3892 0.3892 0.3892 0.1054 0.2708 05044 NA NA NA NA 0.5291 0.5291 0.5291 0.1084 0.2048 05051 NA NA NA NA 0.5071 0.5071 0.5071 0.1041 0.2052 05055 NA NA NA NA 0.4901 0.4901 0.4901 0.1019 0.2078 consolidando las bases de estimaciones para dominios observados y NO observados. estimacionesPre &lt;- bind_rows(data_dir, data_syn) %&gt;% select(dam, dam2, theta_pred) "],["proceso-de-benchmark.html", "6.3 Proceso de Benchmark", " 6.3 Proceso de Benchmark Del censo extraer el total de personas por DAM2 total_pp &lt;- readRDS(file = &quot;Recursos/Día2/Sesion2/Data/total_personas_dam2.rds&quot;) N_dam_pp &lt;- total_pp %&gt;% ungroup() %&gt;% mutate(dam_pp = sum(total_pp) ) tba(N_dam_pp %&gt;% slice(1:20)) dam dam2 total_pp dam_pp 05 05001 2372330 44164417 05 05002 17599 44164417 05 05004 2159 44164417 05 05021 3839 44164417 05 05030 26821 44164417 05 05031 20265 44164417 05 05034 38144 44164417 05 05036 5027 44164417 05 05038 10500 44164417 05 05040 14502 44164417 05 05042 23216 44164417 05 05044 6388 44164417 05 05045 113469 44164417 05 05051 26289 44164417 05 05055 6752 44164417 05 05059 3819 44164417 05 05079 44757 44164417 05 05086 5349 44164417 05 05088 481901 44164417 05 05091 8589 44164417 Obtener las estimaciones directa por DAM o el nivel de agregación en el cual la encuesta es representativa. En este código, se lee un archivo RDS de una encuesta (encuestaCOL18N1.rds) y se utilizan las funciones transmute() y paste0() para seleccionar y transformar las variables de interés. En primer lugar, se crea una variable dam que corresponde al identificador de la división administrativa mayor de la encuesta. A continuación, se utiliza la columna dam_ee para crear una variable dam, se selecciona la variable dam2 que corresponde al identificador de la división administrativa municipal de segundo nivel (subdivisión del departamento) de la encuesta. Luego, se crea una variable wkx que corresponde al peso de la observación en la encuesta, y una variable upm que corresponde al identificador del segmento muestral en la encuesta. La variable estrato se crea utilizando la función paste0(), que concatena los valores de dam y area_ee (una variable que indica el área geográfica en la que se encuentra la vivienda de la encuesta). Finalmente, se crea una variable pobreza que toma el valor 1 si el ingreso de la vivienda es menor que un umbral lp, y 0 en caso contrario. encuesta &lt;- readRDS(&quot;Recursos/Día2/Sesion2/Data/encuestaCOL18N1.rds&quot;)%&gt;% transmute( dam = dam_ee, dam2, wkx = `_fep`, upm = segmento, estrato = paste0(dam, haven::as_factor(area_ee,levels = &quot;values&quot;)), pobreza = ifelse(ingcorte &lt; lp, 1 , 0)) El código está realizando un análisis de datos de encuestas utilizando el paquete survey de R. Primero, se crea un objeto diseno de diseño de encuestas usando la función as_survey_design() del paquete srvyr, que incluye los identificadores de la unidad primaria de muestreo (upm), los pesos (wkx), las estratos (estrato) y los datos de la encuesta (encuesta). Posteriormente, se agrupa el objeto diseno por la variable “Agregado” y se calcula la media de la variable pobreza con un intervalo de confianza para toda la población utilizando la función survey_mean(). El resultado se guarda en el objeto directoDam y se muestra en una tabla. library(survey) library(srvyr) options(survey.lonely.psu = &quot;adjust&quot;) diseno &lt;- as_survey_design( ids = upm, weights = wkx, strata = estrato, nest = TRUE, .data = encuesta ) directoDam &lt;- diseno %&gt;% group_by(Agregado = &quot;Nacional&quot;) %&gt;% summarise( theta_dir = survey_mean(pobreza, vartype = c(&quot;ci&quot;)) ) tba(directoDam) Agregado theta_dir theta_dir_low theta_dir_upp Nacional 0.2986 0.2935 0.3038 Realizar el consolidando información obtenida en 1 y 2. temp &lt;- estimacionesPre %&gt;% inner_join(N_dam_pp ) %&gt;% mutate(theta_dir = directoDam$theta_dir ) tba(temp %&gt;% slice(1:10)) dam dam2 theta_pred total_pp dam_pp theta_dir 05 05001 0.1596 2372330 44164417 0.2986 05 05002 0.4158 17599 44164417 0.2986 05 05031 0.4132 20265 44164417 0.2986 05 05034 0.4428 38144 44164417 0.2986 05 05045 0.3107 113469 44164417 0.2986 05 05079 0.3465 44757 44164417 0.2986 05 05088 0.1331 481901 44164417 0.2986 05 05093 0.3910 15097 44164417 0.2986 05 05120 0.6753 26460 44164417 0.2986 05 05129 0.1181 76260 44164417 0.2986 Con la información organizada realizar el calculo de los pesos para el Benchmark R_dam2 &lt;- temp %&gt;% summarise( R_dam_RB = unique(theta_dir) / sum((total_pp / dam_pp) * theta_pred), R_dam_DB = unique(theta_dir) - sum((total_pp / dam_pp) * theta_pred) ) tba(R_dam2) R_dam_RB R_dam_DB 1.0148 0.0044 calculando los pesos para cada dominio. pesos &lt;- temp %&gt;% mutate(W_i = total_pp / dam_pp) %&gt;% select(dam2, W_i) tba(pesos %&gt;% slice(1:10)) dam2 W_i 05001 0.0537 05002 0.0004 05031 0.0005 05034 0.0009 05045 0.0026 05079 0.0010 05088 0.0109 05093 0.0003 05120 0.0006 05129 0.0017 Realizar la estimación FH Benchmark En este proceso, se realiza la adición de una nueva columna denominada R_dam_RB, que es obtenida a partir de un objeto denominado R_dam2. Posteriormente, se agrega una nueva columna denominada theta_pred_RBench, la cual es igual a la multiplicación de R_dam_RB y theta_pred. Finalmente, se hace un left_join con el dataframe pesos, y se seleccionan únicamente las columnas dam, dam2, W_i, theta_pred y theta_pred_RBench para ser presentadas en una tabla (tba) que muestra únicamente las primeras 10 filas. estimacionesBench &lt;- estimacionesPre %&gt;% mutate(R_dam_RB = R_dam2$R_dam_RB) %&gt;% mutate(theta_pred_RBench = R_dam_RB * theta_pred) %&gt;% left_join(pesos) %&gt;% select(dam, dam2, W_i, theta_pred, theta_pred_RBench) tba(estimacionesBench %&gt;% slice(1:10)) dam dam2 W_i theta_pred theta_pred_RBench 05 05001 0.0537 0.1596 0.1619 05 05002 0.0004 0.4158 0.4220 05 05031 0.0005 0.4132 0.4193 05 05034 0.0009 0.4428 0.4494 05 05045 0.0026 0.3107 0.3153 05 05079 0.0010 0.3465 0.3516 05 05088 0.0109 0.1331 0.1351 05 05093 0.0003 0.3910 0.3968 05 05120 0.0006 0.6753 0.6853 05 05129 0.0017 0.1181 0.1199 Validación: Estimación FH con Benchmark estimacionesBench %&gt;% summarise(theta_reg_RB = sum(W_i * theta_pred_RBench)) %&gt;% mutate(theta_dir = directoDam$theta_dir) theta_reg_RB theta_dir 0.2986344 0.2986344 "],["validación-de-los-resultados..html", "6.4 Validación de los resultados.", " 6.4 Validación de los resultados. Este código junta las estimaciones del modelo con pesos de benchmarking con los valores observados y sintéticos, y luego resume las estimaciones combinadas para compararlas con la estimación directa obtenida anteriormente. temp &lt;- estimacionesBench %&gt;% left_join( bind_rows( data_dir %&gt;% select(dam2, thetaSyn, thetaFH), data_syn %&gt;% select(dam2, thetaSyn, thetaFH))) %&gt;% summarise(thetaSyn = sum(W_i * thetaSyn), thetaFH = sum(W_i * theta_pred), theta_RBench = sum(W_i * theta_pred_RBench) ) %&gt;% mutate(theta_dir = directoDam$theta_dir, theta_dir_low =directoDam$theta_dir_low, theta_dir_upp = directoDam$theta_dir_upp) temp %&lt;&gt;% gather(key = &quot;Metodo&quot;,value = &quot;Estimacion&quot;, -theta_dir_low,-theta_dir_upp) tba(temp) theta_dir_low theta_dir_upp Metodo Estimacion 0.2935 0.3038 thetaSyn 0.2965 0.2935 0.3038 thetaFH 0.2943 0.2935 0.3038 theta_RBench 0.2986 0.2935 0.3038 theta_dir 0.2986 "],["mapa-de-pobreza.html", "6.5 Mapa de pobreza", " 6.5 Mapa de pobreza Este es un bloque de código se cargan varios paquetes (sp, sf, tmap) y realiza algunas operaciones. Primero, realiza una unión (left_join) entre las estimaciones de ajustadas por el Benchmarking (estimacionesBench) y las estimaciones del modelo (data_dir, data_syn), utilizando la variable dam2 como clave para la unión. Luego, lee un archivo Shapefile que contiene información geoespacial del país. A continuación, crea un mapa temático (tmap) utilizando la función tm_shape() y agregando capas con la función tm_polygons(). El mapa representa una variable theta_pred_RBench utilizando una paleta de colores llamada “YlOrRd” y establece los cortes de los intervalos de la variable con la variable brks_lp. Finalmente, la función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). library(sp) library(sf) library(tmap) estimacionesBench %&lt;&gt;% left_join( bind_rows( data_dir %&gt;% select(dam2, theta_pred_EE , Cv_theta_pred), data_syn %&gt;% select(dam2, theta_pred_EE , Cv_theta_pred))) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día2/Sesion2/Shape/COL_dam2.shp&quot;) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(estimacionesBench, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.1,0.15, 0.2, 0.3, 0.4, 0.6, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;theta_pred_RBench&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 1.5) Mapa_lp "],["día-2---sesión-3--modelos-de-área---estimación-de-la-pobreza-y-la-transformación-arcoseno..html", "Capítulo 7 Día 2 - Sesión 3- Modelos de área - Estimación de la pobreza y la transformación ArcoSeno.", " Capítulo 7 Día 2 - Sesión 3- Modelos de área - Estimación de la pobreza y la transformación ArcoSeno. En su concepción más básica, el modelo de Fay-Herriot es una combinación lineal de covariables. Sin embargo, el resultado de esta combinación pueden tomar valores que se salen del rango aceptable en el que puede estar una proporción; es decir, en general el estimador de Fay-Herriot \\(\\theta \\in R\\), mientras que el estimador directo \\(\\theta \\in (0,1)\\). La transformación arcoseno esta dada por: \\[ \\hat{z}_d = arcsin\\left( \\sqrt{ \\hat{\\theta}_d} \\right) \\] donde \\[ Var\\left( \\hat{z}_d \\right) = \\frac{\\widehat{DEFF}_d}{4\\times n_d} = \\frac{1}{4\\times n_{d,efectivo} } \\] El modelo de Fay-Herriot estaría definido de la siguiente forma: \\[ \\begin{eqnarray*} Z \\mid \\mu,\\sigma_e &amp; \\sim &amp; N(\\mu, \\sigma_e)\\\\ \\mu &amp; = &amp; \\boldsymbol{X\\beta} + V \\\\ \\theta &amp; = &amp; \\left(sin(\\mu)\\right)^2 \\end{eqnarray*} \\] donde \\(V \\sim N(0 , \\sigma_v)\\). Suponga de las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma_{v}^{2}\\) son dadas por \\[ \\begin{eqnarray*} \\boldsymbol{\\beta} \\sim N\\left(0,1000 \\right)\\\\ \\sigma_{v}^{2} \\sim IG\\left(0.0001,0.0001\\right) \\end{eqnarray*} \\] "],["procedimiento-de-estimación-1.html", "7.1 Procedimiento de estimación", " 7.1 Procedimiento de estimación Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día2/Sesion3/Data/base_FH_2018.rds&quot;) %&gt;% transmute(dam2, ## id dominios pobreza, T_pobreza = asin(sqrt(pobreza)), ## creando zd n_effec = n_eff_FGV, ## n efectivo varhat = 1/(4*n_effec) ## varianza para zd ) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día2/Sesion3/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Uniendo las dos bases de datos. base_FH &lt;- full_join(base_FH, statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[,1:8] %&gt;% head(10)) dam2 pobreza T_pobreza n_effec varhat dam area1 sexo2 05001 0.1597 0.4111 1150.9156 0.0002 05 0.9832 0.5299 05002 0.4049 0.6897 11.4884 0.0218 05 0.3953 0.4807 05031 0.3817 0.6660 5.6901 0.0439 05 0.5766 0.4978 05034 0.4731 0.7585 7.4016 0.0338 05 0.5029 0.4815 05045 0.2876 0.5661 6.9301 0.0361 05 0.8091 0.5078 05079 0.4001 0.6848 23.8486 0.0105 05 0.4821 0.5038 05088 0.1314 0.3709 48.7553 0.0051 05 0.9569 0.5186 05093 0.3273 0.6091 6.0577 0.0413 05 0.2776 0.4862 05120 0.7049 0.9965 11.8232 0.0211 05 0.1989 0.4787 05129 0.1140 0.3444 47.8247 0.0052 05 0.8065 0.5202 Seleccionando las covariables para el modelo. names_cov &lt;- c( &quot;sexo2&quot; , &quot;anoest2&quot; , &quot;anoest3&quot;, &quot;anoest4&quot;, &quot;edad2&quot; , &quot;edad3&quot; , &quot;edad4&quot; , &quot;edad5&quot; , &quot;etnia1&quot;, &quot;etnia2&quot; , &quot;tasa_desocupacion&quot; , &quot;luces_nocturnas&quot; , &quot;cubrimiento_cultivo&quot; , &quot;alfabeta&quot; ) "],["preparando-los-insumos-para-stan-1.html", "7.2 Preparando los insumos para STAN", " 7.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(T_pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[,1:8] %&gt;% slice(1:10)) dam2 pobreza T_pobreza n_effec varhat dam area1 sexo2 05004 NA NA NA NA 05 0.3279 0.4576 05021 NA NA NA NA 05 0.5770 0.5020 05030 NA NA NA NA 05 0.4859 0.5063 05036 NA NA NA NA 05 0.3931 0.4951 05038 NA NA NA NA 05 0.2256 0.4927 05040 NA NA NA NA 05 0.4858 0.4826 05042 NA NA NA NA 05 0.6688 0.5031 05044 NA NA NA NA 05 0.1847 0.4828 05051 NA NA NA NA 05 0.3660 0.4970 05055 NA NA NA NA 05 0.4431 0.4825 Definir matriz de efectos fijos. ## Dominios observados Xdat &lt;- cbind(inter = 1,data_dir[,names_cov]) ## Dominios no observados Xs &lt;- cbind(inter = 1,data_syn[,names_cov]) Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados y = as.numeric(data_dir$T_pobreza), sigma_e = sqrt(data_dir$varhat) ) Compilando el modelo en STAN library(rstan) fit_FH_arcoseno &lt;- &quot;Recursos/Día2/Sesion3/Data/modelosStan/15FH_arcsin_normal.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_arcoseno &lt;- stan( file = fit_FH_arcoseno, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_FH_arcoseno, &quot;Recursos/Día2/Sesion3/Data/model_FH_arcoseno.rds&quot;) model_FH_arcoseno &lt;- readRDS(&quot;Recursos/Día2/Sesion3/Data/model_FH_arcoseno.rds&quot;) 7.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(patchwork) library(posterior) y_pred_B &lt;- as.array(model_FH_arcoseno, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma^2_V\\). posterior_sigma2_v &lt;- as.array(model_FH_arcoseno, pars = &quot;sigma2_v&quot;) (mcmc_dens_chains(posterior_sigma2_v) + mcmc_areas(posterior_sigma2_v) ) / mcmc_trace(posterior_sigma2_v) Estimación del FH de la pobreza en los dominios observados. theta_FH &lt;- summary(model_FH_arcoseno,pars = &quot;theta&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate(pred_arcoseno = theta_FH$mean, pred_arcoseno_EE = theta_FH$sd, Cv_pred = pred_arcoseno_EE/pred_arcoseno) Estimación del FH de la pobreza en los dominios NO observados. theta_FH_pred &lt;- summary(model_FH_arcoseno,pars = &quot;theta_pred&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate(pred_arcoseno = theta_FH_pred$mean, pred_arcoseno_EE = theta_FH_pred$sd, Cv_pred = pred_arcoseno_EE/pred_arcoseno) "],["mapa-de-pobreza-1.html", "7.3 Mapa de pobreza", " 7.3 Mapa de pobreza El siguiente bloque de código carga los paquetes sp, sf y tmap, y realiza algunas operaciones. Primero, une (rbind) las estimaciones de los dominios observados y los no observados (data_dir, data_syn) y selecciona las variables dam2, pobreza, pred_arcoseno, pred_arcoseno_EE y Cv_pred utilizando la función select(). Luego, lee un archivo Shapefile que contiene información geoespacial del país. A continuación, crea un mapa temático (tmap) utilizando la función tm_shape() y agregando capas con la función tm_polygons(). El mapa representa dos variables llamadas pobreza y pred_arcoseno, utilizando una paleta de colores llamada “YlOrRd” y establece los cortes de los intervalos de las variables con la variable brks_lp. Finalmente, la función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). library(sp) library(sf) library(tmap) data_map &lt;- rbind(data_dir, data_syn) %&gt;% select(dam2, pobreza, pred_arcoseno, pred_arcoseno_EE,Cv_pred ) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día2/Sesion3/Shape/COL_dam2.shp&quot;) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(data_map, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.15, 0.3, 0.45, 0.6, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;pobreza&quot;, &quot;pred_arcoseno&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 1.5) Mapa_lp "],["mapa-del-coeficiente-de-variación..html", "7.4 Mapa del coeficiente de variación.", " 7.4 Mapa del coeficiente de variación. Ahora, se crea un segundo mapa temático (tmap) llamado Mapa_cv. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función tm_polygons(). El mapa representa la variable Cv_pred, utilizando una paleta de colores llamada “YlOrRd” y establece el título del mapa con el parámetro title. La función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R. Mapa_cv &lt;- mapa + tm_polygons( c(&quot;Cv_pred&quot;), title = &quot;Mapa de pobreza(cv)&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 2.5) Mapa_cv "],["día-2---sesión-4--modelos-de-área---estimación-de-la-pobreza-en-familias-beta-y-binomial.html", "Capítulo 8 Día 2 - Sesión 4- Modelos de área - Estimación de la pobreza en familias beta y binomial ", " Capítulo 8 Día 2 - Sesión 4- Modelos de área - Estimación de la pobreza en familias beta y binomial "],["modelo-fay-herriot-de-variable-respuesta-beta..html", "8.1 Modelo Fay Herriot de variable respuesta beta.", " 8.1 Modelo Fay Herriot de variable respuesta beta. El modelo lineal de Fay-Herriot puede ser reemplazado por un modelo mixto lineal generalizado (GLMM). Esto se puede hacer cuando los datos observados \\(y_d\\) son inherentemente discretos, como cuando son recuentos (no ponderados) de personas u hogares muestreados con ciertas características. Uno de estos modelos supone una distribución binomial para \\(y_d\\) con probabilidad de éxito \\(p_d\\), y una logística modelo de regresión para \\(p_d\\) con errores normales en la escala logit. El modelo resultante es \\[ \\begin{eqnarray*} y_{d}\\mid p_{d},n_{d} &amp; \\sim &amp; Bin\\left(n_{d},p_{d}\\right) \\end{eqnarray*} \\] para \\(d=1,\\dots,D\\) y \\[ \\begin{eqnarray*} logit\\left(p_{d}\\right)=\\log\\left(\\frac{p_{d}}{1-p_{d}}\\right) &amp; = &amp; \\boldsymbol{x}_{d}^{T}\\boldsymbol{\\beta}+u_{d} \\end{eqnarray*} \\] donde \\(u_{d}\\sim N\\left(0,\\sigma_{u}^{2}\\right)\\) y \\(n_{d}\\) es el tamaño de la muestra para el área \\(d\\). El modelo anterior se puede aplicar fácilmente a recuentos de muestras no ponderadas \\(y_d\\), pero esto ignora cualquier aspecto complejo del diseño de la encuesta. En muestras complejas donde las \\(y_d\\) son estimaciones ponderadas, surgen dos problemas. En primer lugar, los posibles valores de el \\(y_d\\) no serán los números enteros \\(0, 1, \\dots , n_d\\) para cualquier definición directa de tamaño de muestra \\(n_d\\). En su lugar, \\(y_d\\) tomará un valor de un conjunto finito de números desigualmente espaciados determinados por las ponderaciones de la encuesta que se aplican a los casos de muestra en el dominio \\(d\\). En segundo lugar, la varianza muestral de \\(y_d\\) implícito en la distribución Binomial, es decir, \\(n_d \\times p_d (1-p_d)\\), será incorrecto. Abordamos estos dos problemas al definir un tamaño de muestra efectivo \\(\\tilde{n}_d\\), y un número de muestra efectivo de éxitos \\(\\tilde{y_d}\\) determinó mantener: (i) la estimación directa \\(\\hat{p}_i\\), de la pobreza y (ii) una estimación de la varianza de muestreo correspondiente,\\(\\widehat{Var}(\\hat{p}_d)\\). Es posible suponer que \\[ \\begin{eqnarray*} \\tilde{n}_{d} &amp; \\sim &amp; \\frac{\\check{p}_{d}\\left(1-\\check{p}_{d}\\right)}{\\widehat{Var}\\left(\\hat{p}_{d}\\right)} \\end{eqnarray*} \\] donde \\(\\check{p}_{d}\\) es una preliminar perdicción basada en el modelo para la proporción poblacional \\(p_d\\) y y \\(\\widehat{Var}\\left(\\hat{p}_{d}\\right)\\) depende de\\(\\check{p}_{d}\\) a través de una función de varianza generalizada ajustada (FGV). Note que \\(\\tilde{y}_{d}=\\tilde{n}_{d}\\times\\hat{p}_{d}\\). Suponga de las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma_{u}^{2}\\) son dadas por \\[ \\begin{eqnarray*} \\boldsymbol{\\beta} \\sim N\\left(0,10000\\right)\\\\ \\sigma_{u}^{2} \\sim IG\\left(0.0001,0.0001\\right) \\end{eqnarray*} \\] 8.1.1 Procedimiento de estimación Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día2/Sesion4/Data/base_FH_2018.rds&quot;) %&gt;% select(dam2, pobreza, n_eff_FGV) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día2/Sesion4/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Uniendo las dos bases de datos. base_FH &lt;- full_join(base_FH,statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[,1:8] %&gt;% head(10)) dam2 pobreza n_eff_FGV dam area1 sexo2 edad2 edad3 05001 0.1597 1150.9156 05 0.9832 0.5299 0.2671 0.2201 05002 0.4049 11.4884 05 0.3953 0.4807 0.2229 0.1977 05031 0.3817 5.6901 05 0.5766 0.4978 0.2695 0.1961 05034 0.4731 7.4016 05 0.5029 0.4815 0.2530 0.2052 05045 0.2876 6.9301 05 0.8091 0.5078 0.2913 0.2211 05079 0.4001 23.8486 05 0.4821 0.5038 0.2506 0.2119 05088 0.1314 48.7553 05 0.9569 0.5186 0.2785 0.2320 05093 0.3273 6.0577 05 0.2776 0.4862 0.2619 0.1949 05120 0.7049 11.8232 05 0.1989 0.4787 0.2617 0.1810 05129 0.1140 47.8247 05 0.8065 0.5202 0.2542 0.2198 Seleccionando las covariables para el modelo. names_cov &lt;- c( &quot;sexo2&quot; , &quot;anoest2&quot; , &quot;anoest3&quot;, &quot;anoest4&quot;, &quot;edad2&quot; , &quot;edad3&quot; , &quot;edad4&quot; , &quot;edad5&quot; , &quot;etnia1&quot;, &quot;etnia2&quot; , &quot;tasa_desocupacion&quot; , &quot;luces_nocturnas&quot; , &quot;cubrimiento_cultivo&quot; , &quot;alfabeta&quot; ) 8.1.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[1:10,1:8]) dam2 pobreza n_eff_FGV dam area1 sexo2 edad2 edad3 05004 NA NA 05 0.3279 0.4576 0.2376 0.2075 05021 NA NA 05 0.5770 0.5020 0.2191 0.1946 05030 NA NA 05 0.4859 0.5063 0.2571 0.2047 05036 NA NA 05 0.3931 0.4951 0.2447 0.1955 05038 NA NA 05 0.2256 0.4927 0.2659 0.1984 05040 NA NA 05 0.4858 0.4826 0.2859 0.1982 05042 NA NA 05 0.6688 0.5031 0.2556 0.2158 05044 NA NA 05 0.1847 0.4828 0.2600 0.2073 05051 NA NA 05 0.3660 0.4970 0.2466 0.1894 05055 NA NA 05 0.4431 0.4825 0.2423 0.1942 Definir matriz de efectos fijos. ## Dominios observados Xdat &lt;- data_dir[,names_cov] ## Dominios no observados Xs &lt;- data_syn[,names_cov] Obteniendo el tamaño de muestra efectivo \\(\\tilde{n}_d\\), y el número de muestra efectivo de éxitos \\(\\tilde{y_d}\\) n_effec = round(data_dir$n_eff_FGV) y_effect = round((data_dir$pobreza)*n_effec) Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados n_effec = n_effec, y_effect = y_effect # Estimación directa. ) Compilando el modelo en STAN library(rstan) fit_FH_binomial &lt;- &quot;Recursos/Día2/Sesion4/Data/modelosStan/14FH_binomial.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_Binomial &lt;- stan( file = fit_FH_binomial, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_FH_Binomial, file = &quot;Recursos/Día2/Sesion4/Data/model_FH_Binomial.rds&quot;) Leer el modelo model_FH_Binomial &lt;- readRDS(&quot;Recursos/Día2/Sesion4/Data/model_FH_Binomial.rds&quot;) 8.1.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(patchwork) library(posterior) y_pred_B &lt;- as.array(model_FH_Binomial, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma_V\\). posterior_sigma_v &lt;- as.array(model_FH_Binomial, pars = &quot;sigma_v&quot;) (mcmc_dens_chains(posterior_sigma_v) + mcmc_areas(posterior_sigma_v) ) / mcmc_trace(posterior_sigma_v) Estimación del FH de la pobreza en los dominios observados. theta_FH &lt;- summary(model_FH_Binomial,pars = &quot;theta&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate(pred_binomial = theta_FH$mean, pred_binomial_EE = theta_FH$sd, Cv_pred = pred_binomial_EE/pred_binomial) Estimación del FH de la pobreza en los dominios NO observados. theta_FH_pred &lt;- summary(model_FH_Binomial,pars = &quot;thetaLP&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate(pred_binomial = theta_FH_pred$mean, pred_binomial_EE = theta_FH_pred$sd, Cv_pred = pred_binomial_EE/pred_binomial) 8.1.2.2 Mapa de pobreza El mapa muestra el nivel de pobreza en diferentes áreas de Colombia, basado en dos variables, pobreza y pred_binomial. Primero, se cargan los paquetes necesarios sp, sf y tmap. Luego, se lee la información de los datos en R y se combinan utilizando la función rbind(). library(sp) library(sf) library(tmap) data_map &lt;- rbind(data_dir, data_syn) %&gt;% select(dam2, pobreza, pred_binomial, pred_binomial_EE,Cv_pred ) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día2/Sesion4/Shape/COL_dam2.shp&quot;) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(data_map, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.025,0.05, 0.1, 0.15, 0.2,0.4, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;pobreza&quot;, &quot;pred_binomial&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 1.5) Mapa_lp 8.1.2.3 Mapa del coeficiente de variación. Ahora, se crea un segundo mapa temático (tmap) llamado Mapa_cv. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función tm_polygons(). El mapa representa la variable Cv_pred, utilizando una paleta de colores llamada “YlOrRd” y establece el título del mapa con el parámetro title. La función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R. Mapa_cv &lt;- mapa + tm_polygons( c(&quot;Cv_pred&quot;), title = &quot;Mapa de pobreza(cv)&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 2.5) Mapa_cv "],["modelo-de-fay-herriot-de-variable-respuesta-beta..html", "8.2 Modelo de Fay Herriot de variable respuesta beta.", " 8.2 Modelo de Fay Herriot de variable respuesta beta. El modelo beta-logístico fue inicialmente considerado por Jiang y Lahiri (2006b) para un enfoque EBP en uno de sus ejemplos ilustrativos para estimar medias de dominio de población finita. El modelo Fay Herriot beta-logístico estaría dado por las siguientes expresiones \\[ \\begin{eqnarray*} \\hat{p}_{d} \\mid P_d &amp; \\sim &amp; beta(a_d, b_d)\\\\ \\end{eqnarray*} \\] La función del enlace es \\[ \\begin{eqnarray*} logit(P_{d}) \\mid \\boldsymbol{\\beta}, \\sigma^2_v &amp; \\sim &amp; N(\\boldsymbol{x_d^t\\beta},\\sigma^2_v)\\\\ \\end{eqnarray*} \\] Los parámetros \\(a_d\\) y \\(b_d\\) son estimados así: \\[ \\begin{eqnarray*} a_d &amp;=&amp; P_d \\times \\phi_d\\\\ b_d &amp;=&amp; (1 - P_d) \\times \\phi_d\\\\ \\end{eqnarray*} \\] donde \\[\\phi_d = \\frac{n_d}{\\widehat{DEFF}_d} -1 = n_{d,efecctivo} -1\\] Las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma^2_v\\) \\[ \\begin{eqnarray*} \\beta_k &amp;\\sim&amp; N(0, 10000)\\\\ \\sigma^2_v &amp;\\sim&amp; IG(0.0001,0.0001) \\end{eqnarray*} \\] 8.2.1 Procedimiento de estimación Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día2/Sesion4/Data/base_FH_2018.rds&quot;) %&gt;% select(dam2, pobreza, n_eff_FGV) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día2/Sesion4/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Uniendo las dos bases de datos. base_FH &lt;- full_join(base_FH,statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[,1:8] %&gt;% head(10)) dam2 pobreza n_eff_FGV dam area1 sexo2 edad2 edad3 05001 0.1597 1150.9156 05 0.9832 0.5299 0.2671 0.2201 05002 0.4049 11.4884 05 0.3953 0.4807 0.2229 0.1977 05031 0.3817 5.6901 05 0.5766 0.4978 0.2695 0.1961 05034 0.4731 7.4016 05 0.5029 0.4815 0.2530 0.2052 05045 0.2876 6.9301 05 0.8091 0.5078 0.2913 0.2211 05079 0.4001 23.8486 05 0.4821 0.5038 0.2506 0.2119 05088 0.1314 48.7553 05 0.9569 0.5186 0.2785 0.2320 05093 0.3273 6.0577 05 0.2776 0.4862 0.2619 0.1949 05120 0.7049 11.8232 05 0.1989 0.4787 0.2617 0.1810 05129 0.1140 47.8247 05 0.8065 0.5202 0.2542 0.2198 Seleccionando las covariables para el modelo. names_cov &lt;- c( &quot;sexo2&quot; , &quot;anoest2&quot; , &quot;anoest3&quot;, &quot;anoest4&quot;, &quot;edad2&quot; , &quot;edad3&quot; , &quot;edad4&quot; , &quot;edad5&quot; , &quot;etnia1&quot;, &quot;etnia2&quot; , &quot;tasa_desocupacion&quot; , &quot;luces_nocturnas&quot; , &quot;cubrimiento_cultivo&quot; , &quot;alfabeta&quot; ) 8.2.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[,1:8] %&gt;% slice(1:10)) dam2 pobreza n_eff_FGV dam area1 sexo2 edad2 edad3 05004 NA NA 05 0.3279 0.4576 0.2376 0.2075 05021 NA NA 05 0.5770 0.5020 0.2191 0.1946 05030 NA NA 05 0.4859 0.5063 0.2571 0.2047 05036 NA NA 05 0.3931 0.4951 0.2447 0.1955 05038 NA NA 05 0.2256 0.4927 0.2659 0.1984 05040 NA NA 05 0.4858 0.4826 0.2859 0.1982 05042 NA NA 05 0.6688 0.5031 0.2556 0.2158 05044 NA NA 05 0.1847 0.4828 0.2600 0.2073 05051 NA NA 05 0.3660 0.4970 0.2466 0.1894 05055 NA NA 05 0.4431 0.4825 0.2423 0.1942 Definir matriz de efectos fijos. ## Dominios observados Xdat &lt;- data_dir[,names_cov] ## Dominios no observados Xs &lt;- data_syn[,names_cov] Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados y = as.numeric(data_dir$pobreza), phi = data_dir$n_eff_FGV - 1 ) Compilando el modelo en STAN library(rstan) fit_FH_beta_logitic &lt;- &quot;Recursos/Día2/Sesion4/Data/modelosStan/16FH_beta_logitc.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_beta_logitic &lt;- stan( file = fit_FH_beta_logitic, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_FH_beta_logitic, file = &quot;Recursos/Día2/Sesion4/Data/model_FH_beta_logitic.rds&quot;) model_FH_beta_logitic &lt;- readRDS(&quot;Recursos/Día2/Sesion4/Data/model_FH_beta_logitic.rds&quot;) 8.2.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(patchwork) library(posterior) y_pred_B &lt;- as.array(model_FH_beta_logitic, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma^2_V\\). posterior_sigma2_v &lt;- as.array(model_FH_beta_logitic, pars = &quot;sigma2_v&quot;) (mcmc_dens_chains(posterior_sigma2_v) + mcmc_areas(posterior_sigma2_v) ) / mcmc_trace(posterior_sigma2_v) Estimación del FH de la pobreza en los dominios observados. theta_FH &lt;- summary(model_FH_beta_logitic,pars = &quot;theta&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate(pred_beta_logit = theta_FH$mean, pred_beta_logit_EE = theta_FH$sd, Cv_pred = pred_beta_logit_EE/pred_beta_logit) Estimación del FH de la pobreza en los dominios NO observados. theta_FH_pred &lt;- summary(model_FH_beta_logitic,pars = &quot;thetapred&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate(pred_beta_logit = theta_FH_pred$mean, pred_beta_logit_EE = theta_FH_pred$sd, Cv_pred = pred_beta_logit_EE/pred_beta_logit) 8.2.2.2 Mapa de pobreza El mapa muestra el nivel de pobreza en diferentes áreas de Colombia, basado en dos variables, pobreza y pred_beta_logit. Primero, se cargan los paquetes necesarios sp, sf y tmap. Luego, se lee la información de los datos en R y se combinan utilizando la función rbind(). library(sp) library(sf) library(tmap) data_map &lt;- rbind(data_dir, data_syn) %&gt;% select(dam2, pobreza, pred_beta_logit, pred_beta_logit_EE,Cv_pred ) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día2/Sesion4/Shape/COL_dam2.shp&quot;) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(data_map, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.025,0.05, 0.1, 0.15, 0.2,0.4, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;pobreza&quot;, &quot;pred_beta_logit&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 1.5) Mapa_lp 8.2.2.3 Mapa del coeficiente de variación. Ahora, se crea un segundo mapa temático (tmap) llamado Mapa_cv. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función tm_polygons(). El mapa representa la variable Cv_pred, utilizando una paleta de colores llamada “YlOrRd” y establece el título del mapa con el parámetro title. La función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R. Mapa_cv &lt;- mapa + tm_polygons( c(&quot;Cv_pred&quot;), title = &quot;Mapa de pobreza(cv)&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 2.5) Mapa_cv "],["día-3---sesión-1--modelo-de-unidad-para-la-estimación-del-ingreso-medio.html", "Capítulo 9 Día 3 - Sesión 1- Modelo de unidad para la estimación del ingreso medio", " Capítulo 9 Día 3 - Sesión 1- Modelo de unidad para la estimación del ingreso medio Uno de los primeros problemas a los que debemos enfrentarnos es la estimación del ingreso medio, la cual en una variable no simétrica que toma valores en los positivos. Sin embargo, empleando los métodos Bayesiano es posible obtener estimaciones de esta sin realizar una transformación Figura 9.1: Distribución del ingreso medio por dam2 "],["modelo-bayesiano..html", "9.1 Modelo bayesiano.", " 9.1 Modelo bayesiano. Para realizar la predicción del ingreso medio en dam2s no observadas se asume que: \\[ \\begin{eqnarray*} Y_{di} &amp;\\sim &amp; N\\left(\\mu_{di},\\sigma_y^{2}\\right)\\\\ \\mu_{di}&amp;=&amp;\\boldsymbol{X}_{di}^{T}\\boldsymbol{\\beta}+u_{d}+e_{di} \\end{eqnarray*} \\] Donde \\(Y_{di}\\) representa el ingreso medio de la \\(i-ésima\\) persona en el \\(d-ésimo\\) domino, \\(\\boldsymbol{X}\\) es la información disponible para la \\(i-ésima\\) persona del \\(d-ésimo\\) domino, \\(\\boldsymbol{\\beta}\\) es el vector de parámetros \\(u_d\\) es el efecto introducido por el \\(d-ésimo\\) dominio y \\(e_{di}\\) es el error de estimación para la \\(i-ésima\\) personas del \\(d-ésimo\\) dominio. Note, que \\(u_{d}\\sim N\\left(0,\\sigma_{u}\\right)\\) y \\(e_{di}\\sim N\\left(0,\\sigma_{e}^{2}\\right)\\). Para este caso se asumen las distribuciones previas \\[ \\begin{eqnarray*} \\beta_k &amp; \\sim &amp; N(\\mu_0, \\tau^2_0)\\\\ \\sigma^2_y &amp;\\sim &amp; Inversa-Gamma(\\alpha_1,\\alpha_2) \\end{eqnarray*} \\] las cuales se toman no informativas. A continuación se muestra el proceso realizado para la obtención de la predicción del ingreso medio en dominios no observados. "],["proceso-de-estimación-en-r.html", "9.2 Proceso de estimación en R", " 9.2 Proceso de estimación en R Para desarrollar la metodología se hace uso de las siguientes librerías. # Interprete de STAN en R library(rstan) library(rstanarm) # Manejo de bases de datos. library(tidyverse) # Gráficas de los modelos. library(bayesplot) library(patchwork) # Organizar la presentación de las tablas library(kableExtra) library(printr) Un conjunto de funciones desarrolladas para realizar de forma simplificada los procesos están consignadas en la siguiente rutina. source(&quot;Recursos/Día3/Sesion1/0Recursos/funciones_mrp.R&quot;) Entre las funciones incluidas en el archivo encuentra plot_interaction: Esta crea un diagrama de lineas donde se estudia la interacción entre las variables, en el caso de presentar un traslape de las lineas se recomienda incluir el interacción en el modelo. Plot_Compare Puesto que es necesario realizar una homologar la información del censo y la encuesta es conveniente llevar a cabo una validación de las variables que han sido homologadas, por tanto, se espera que las proporciones resultantes del censo y la encuesta estén cercanas entre sí. Aux_Agregado: Esta es función permite obtener estimaciones a diferentes niveles de agregación, toma mucha relevancia cuando se realiza un proceso repetitivo. Las funciones están diseñada específicamente para este proceso 9.2.1 Encuesta de hogares Los datos empleados en esta ocasión corresponden a la ultima encuesta de hogares, la cual ha sido estandarizada por CEPAL y se encuentra disponible en BADEHOG encuesta &lt;- readRDS(&quot;Recursos/Día3/Sesion1/Data/encuestaCOL18N1.rds&quot;) encuesta_mrp &lt;- encuesta %&gt;% transmute( dam = dam_ee, dam2, ingreso = ingcorte, lp, li, area = haven::as_factor(area_ee,levels = &quot;values&quot;), area = case_when(area == 1 ~ &quot;1&quot;, TRUE ~ &quot;0&quot;), logingreso = log(ingcorte + 1), sexo = as.character(sexo), anoest = case_when( edad &lt; 5 | anoest == -1 ~ &quot;98&quot; , #No aplica anoest == 99 | (edad&gt;=7 &amp; is.na(anoest)) ~ &quot;99&quot;, #NS/NR anoest == 0 ~ &quot;1&quot;, # Sin educación anoest %in% c(1:6) ~ &quot;2&quot;, # 1 - 6 anoest %in% c(7:12) ~ &quot;3&quot;, # 7 - 12 anoest &gt; 12 ~ &quot;4&quot;, # mas de 12 TRUE ~ &quot;Error&quot; ), edad = case_when( edad &lt; 15 ~ &quot;1&quot;, edad &lt; 30 ~ &quot;2&quot;, edad &lt; 45 ~ &quot;3&quot;, edad &lt; 65 ~ &quot;4&quot;, TRUE ~ &quot;5&quot;), etnia = case_when( etnia_ee == 1 ~ &quot;1&quot;, # Indígena etnia_ee == 2 ~ &quot;2&quot;, # Afro TRUE ~ &quot;3&quot; # Otra ), fep = `_fep` ) tba(encuesta_mrp %&gt;% head(10)) dam dam2 ingreso lp li area logingreso sexo anoest edad etnia fep 05 05360 581666.1 296845 147169 1 13.2737 1 3 3 2 127.2220 05 05360 581666.1 296845 147169 1 13.2737 2 2 3 3 127.2220 05 05360 581666.1 296845 147169 1 13.2737 1 2 1 2 127.2220 05 05360 581666.1 296845 147169 1 13.2737 1 98 1 2 127.2220 05 05360 581666.1 296845 147169 1 13.2737 1 98 1 2 127.2220 05 05360 248750.0 296845 147169 1 12.4242 1 4 3 2 125.7202 05 05360 248750.0 296845 147169 1 12.4242 2 3 3 2 125.7202 05 05360 248750.0 296845 147169 1 12.4242 2 2 1 2 125.7202 05 05360 248750.0 296845 147169 1 12.4242 1 1 1 2 125.7202 05 05360 161250.0 296845 147169 1 11.9907 1 2 4 2 115.8661 La base de datos de la encuesta tiene la siguientes columnas: dam: Corresponde al código asignado a la división administrativa mayor del país. dam2: Corresponde al código asignado a la segunda división administrativa del país. lp y li lineas de pobreza y pobreza extrema definidas por CEPAL. área división geográfica (Urbano y Rural). sexo Hombre y Mujer. etnia En estas variable se definen tres grupos: afrodescendientes, indígenas y Otros. Años de escolaridad (anoest) Rangos de edad (edad) Factor de expansión por persona (fep) Ahora, inspeccionamos el comportamiento de la variable de interés: media &lt;- mean(encuesta_mrp$logingreso) Sd &lt;- sd(encuesta_mrp$logingreso) ggplot(data = encuesta_mrp, aes(x = logingreso)) + geom_density(size =2, color = &quot;blue&quot;) + labs(y = &quot;&quot;) + stat_function(fun = dnorm, args = list(mean = media, sd = Sd), size =2) + theme_bw(base_size = 20) + theme(axis.text.y = element_blank(), axis.ticks = element_blank()) Figura 9.2: Distribuición del ingreso de las personas encuestadas La información auxiliar disponible ha sido extraída del censo e imágenes satelitales statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día3/Sesion1/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) tba(statelevel_predictors_df %&gt;% head(10)) dam dam2 area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 05 05001 0.9832 0.5299 0.2671 0.2201 0.2355 0.1060 0.0251 0.2598 0.4048 0.2287 0.0009 0.0354 0.0024 0.0258 0.0833 0.0062 4.9762 -0.5072 7.2903 2.8648 -0.3953 -0.5248 05 05002 0.3953 0.4807 0.2229 0.1977 0.2497 0.1281 0.0035 0.5644 0.2393 0.0473 0.0001 0.3416 0.0160 0.1139 0.1395 0.0000 -0.3246 -0.5749 -0.1807 -0.0439 -0.3439 -0.4224 05 05004 0.3279 0.4576 0.2376 0.2075 0.2316 0.1218 0.0199 0.4470 0.3460 0.0723 0.0000 0.3694 0.0325 0.0787 0.1557 0.0000 -0.6111 -0.5475 -0.2991 -0.8159 0.0619 -0.0654 05 05021 0.5770 0.5020 0.2191 0.1946 0.2357 0.1274 0.0031 0.5038 0.2727 0.0716 0.0000 0.2785 0.0255 0.0959 0.1025 0.0000 -0.4532 -0.6694 -0.1852 -0.3570 -0.2956 -0.3104 05 05030 0.4859 0.5063 0.2571 0.2047 0.2507 0.0997 0.0048 0.4130 0.3756 0.0828 0.0003 0.0775 0.0143 0.0844 0.1176 0.0000 1.1636 -0.5002 0.7336 1.4706 -0.3670 -0.4265 05 05031 0.5766 0.4978 0.2695 0.1961 0.2047 0.0850 0.0050 0.4618 0.2981 0.0585 0.0001 0.4010 0.0970 0.1200 0.1417 0.0000 -0.5077 -0.6806 -0.2532 -0.6818 0.0167 0.2017 05 05034 0.5029 0.4815 0.2530 0.2052 0.2324 0.1042 0.0060 0.4731 0.2976 0.0634 0.0065 0.3435 0.0069 0.1089 0.1301 0.0000 -0.2580 -0.5573 -0.2197 0.2265 -0.0293 -0.2376 05 05036 0.3931 0.4951 0.2447 0.1955 0.2435 0.1142 0.0054 0.4808 0.3010 0.0591 0.0006 0.1341 0.0227 0.1100 0.1561 0.0000 0.7139 -0.5957 -0.2053 1.0807 -0.3818 -0.5131 05 05038 0.2256 0.4927 0.2659 0.1984 0.2049 0.0904 0.0050 0.5162 0.2696 0.0281 0.0000 0.2768 0.1011 0.1544 0.2247 0.0000 -0.4100 -0.5108 -0.2644 -0.1709 -0.3398 -0.3666 05 05040 0.4858 0.4826 0.2859 0.1982 0.1678 0.0641 0.0168 0.4928 0.2738 0.0361 0.0117 0.4961 0.0824 0.1253 0.1948 0.0000 -0.5447 -0.6866 -0.2954 -0.9040 0.0470 0.1783 9.2.2 Niveles de agregación para colapsar la encuesta Después de realizar una investigación en la literatura especializada y realizar estudios de simulación fue posible evidenciar que las predicciones obtenidas con la muestra sin agregar y la muestra agregada convergen a la media del dominio. Sin embargo, el realizar estas estimaciones con la muestra agregada reduce el tiempo computacional necesario para la convergencia de las cadenas MCMC. Con esto en mente se se realiza la identificación de las variables por las cuales se agregará la encuesta. byAgrega &lt;- c(&quot;dam&quot;, &quot;dam2&quot;, &quot;area&quot;, &quot;sexo&quot;, &quot;anoest&quot;, &quot;edad&quot;, &quot;etnia&quot; ) 9.2.3 Creando base con la encuesta agregada El resultado de agregar la base de dato se muestra a continuación: encuesta_df_agg &lt;- encuesta_mrp %&gt;% # Encuesta group_by_at(all_of(byAgrega)) %&gt;% # Agrupar por el listado de variables summarise(n = n(), # Número de observaciones # Ingreso medio de las personas con características similares. logingreso = mean(logingreso), .groups = &quot;drop&quot;) %&gt;% arrange(desc(n)) # Ordenar la base. La tabla obtenida es la siguiente: dam dam2 area sexo anoest edad etnia n logingreso 47 47001 1 2 3 2 3 2636 12.7161 11 11001 1 1 3 2 3 2616 13.2541 47 47001 1 1 3 2 3 2550 12.8214 23 23001 1 2 3 2 3 2530 12.7668 11 11001 1 2 3 2 3 2441 13.1631 08 08001 1 1 3 2 3 2284 13.0227 23 23001 1 1 3 2 3 2281 12.8609 20 20001 1 2 3 2 3 2211 12.4981 08 08001 1 2 3 2 3 2150 12.9589 05 05001 1 1 3 2 3 2130 13.2175 El paso a seguir es unificar las tablas creadas. encuesta_df_agg &lt;- inner_join(encuesta_df_agg, statelevel_predictors_df) 9.2.4 Definiendo el modelo multinivel. Después de haber ordenado la encuesta, podemos pasar a la definición del modelo. options(MC.cores=parallel::detectCores()) # Permite procesar en paralelo. fit &lt;- stan_lmer( logingreso ~ # Ingreso medio (Y) (1 | dam2) + # Efecto aleatorio (ud) edad + # Efecto fijo (Variables X) sexo + tasa_desocupacion + luces_nocturnas + cubrimiento_cultivo + cubrimiento_urbano , weights = n, # Número de observaciones. data = encuesta_df_agg, # Encuesta agregada verbose = TRUE, # Muestre el avance del proceso chains = 4, # Número de cadenas. iter = 1000 # Número de realizaciones de la cadena ) saveRDS(fit, file = &quot;Data/fit_ingresos.rds&quot;) Después de esperar un tiempo prudente se obtiene el siguiente modelo. fit &lt;- readRDS(&quot;Recursos/Día3/Sesion1/Data/fit_ingresos.rds&quot;) tba(coef(fit)$dam2 %&gt;% head(10)) (Intercept) edad2 edad3 edad4 edad5 sexo2 tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano 05001 12.0223 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05002 12.1978 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05031 12.2646 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05034 12.3924 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05045 12.5292 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05079 11.6356 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05088 12.2333 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05093 12.4130 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05120 11.7266 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 05129 12.9505 0.2453 0.3546 0.5073 0.5256 -0.0424 44.0822 0.2547 0.0249 -0.07 Validación del modelo library(posterior) library(bayesplot) (mcmc_dens_chains(fit,pars = &quot;sigma&quot;) + mcmc_areas(fit,pars = &quot;sigma&quot;))/ mcmc_trace(fit,pars = &quot;sigma&quot;) var_names &lt;- c(&quot;edad2&quot;, &quot;edad3&quot;, &quot;edad4&quot;, &quot;edad5&quot;, &quot;sexo2&quot;, &quot;luces_nocturnas&quot;, &quot;cubrimiento_urbano&quot;,&quot;cubrimiento_cultivo&quot;) mcmc_areas(fit,pars = var_names) mcmc_trace(fit,pars = var_names) encuesta_mrp2 &lt;- inner_join(encuesta_mrp, statelevel_predictors_df) y_pred_B &lt;- posterior_epred(fit, newdata = encuesta_mrp2) rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(encuesta_mrp2$logingreso), y_pred2)/ ppc_dens_overlay(y = exp(as.numeric(encuesta_mrp2$logingreso))-1, (exp(y_pred2)-1)) "],["proceso-de-estimación-y-predicción.html", "9.3 Proceso de estimación y predicción", " 9.3 Proceso de estimación y predicción Obtener el modelo es solo un paso más, ahora se debe realizar la predicción en el censo, el cual a sido previamente estandarizado y homologado con la encuesta. poststrat_df &lt;- readRDS(&quot;Recursos/Día3/Sesion1/Data/censo_dam2.rds&quot;) %&gt;% left_join(statelevel_predictors_df) tba( poststrat_df %&gt;% arrange(desc(n)) %&gt;% head(10)) dam dam2 area sexo edad etnia anoest n area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 11 11001 1 1 2 3 3 602093 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 2 3 3 538416 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 3 3 4 435396 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 2 3 4 406654 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 1 1 3 2 368795 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 1 3 3 4 360435 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 1 3 3 3 359097 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 4 3 3 353834 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 3 3 3 345223 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 1 3 2 341452 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 Note que la información del censo esta agregada. 9.3.1 Distribución posterior. Para obtener una distribución posterior de cada observación se hace uso de la función posterior_epred de la siguiente forma. epred_mat &lt;- posterior_epred(fit, newdata = poststrat_df, type = &quot;response&quot;) Como el interés es realizar comparaciones entre los países de la región se presenta la estimación del ingreso medio en términos de lineas de pobreza. Para esto procedemos así: Obteniendo las lineas de pobreza por cada post-estrato (lp &lt;- encuesta_mrp %&gt;% distinct(area,lp,li)) %&gt;% tba() area lp li 1 296845 147169 0 200760 127346 Ingreso en términos de lineas de pobreza. lp &lt;- inner_join(poststrat_df,lp,by = &quot;area&quot;) %&gt;% select(lp) epred_mat &lt;- (exp(epred_mat)-1)/lp$lp 9.3.2 Estimación del ingreso medio nacional n_filtered &lt;- poststrat_df$n mrp_estimates &lt;- epred_mat %*% n_filtered / sum(n_filtered) (temp_ing &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 1.9314 0.0843 El resultado nos indica que el ingreso medio nacional es 1.93 lineas de pobreza 9.3.3 Estimación para el dam == “11”. Es importante siempre conservar el orden de la base, dado que relación entre la predicción y el censo en uno a uno. temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam == &quot;11&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam11 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 2.8997 0.1111 El resultado nos indica que el ingreso medio en el dam 11 es 2.9 lineas de pobreza 9.3.4 Estimación para la dam2 == “05001” temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam2 == &quot;05001&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam2_05001 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 2.6036 0.1615 El resultado nos indica que el ingreso medio en la dam2 05001 es 2.6 lineas de pobreza Después de comprender la forma en que se realiza la estimación de los dominios no observados procedemos el uso de la función Aux_Agregado que es desarrollada para este fin. (mrp_estimate_Ingresolp &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = NULL) ) %&gt;% tba() Nacional mrp_estimate mrp_estimate_se Nacional 1.9314 0.0843 El resultado nos indica que el ingreso medio nacional es 2 lineas de pobreza De forma similar es posible obtener los resultados para las divisiones administrativas. mrp_estimate_dam &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = &quot;dam&quot;) tba(mrp_estimate_dam %&gt;% head(10) ) dam mrp_estimate mrp_estimate_se 05 2.2323 0.1096 08 1.9997 0.0794 11 2.8997 0.1111 13 1.5097 0.0927 15 1.7070 0.1705 17 2.0380 0.0760 18 1.2386 0.0440 19 1.1672 0.1064 20 1.2072 0.1157 23 1.2985 0.0702 mrp_estimate_dam2 &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = &quot;dam2&quot;) tba(mrp_estimate_dam2 %&gt;% head(10) ) dam2 mrp_estimate mrp_estimate_se 05001 2.6036 0.1615 05002 1.0284 0.0432 05004 1.0659 0.3687 05021 1.0891 0.3753 05030 1.5752 0.5411 05031 1.0179 0.0588 05034 1.2613 0.0627 05036 1.4834 0.5120 05038 1.0906 0.3739 05040 1.0218 0.3511 El mapa resultante es el siguiente "],["día-3---sesión-2--estimación-de-la-pobreza-a-partir-del-ingreso.html", "Capítulo 10 Día 3 - Sesión 2- Estimación de la pobreza a partir del ingreso ", " Capítulo 10 Día 3 - Sesión 2- Estimación de la pobreza a partir del ingreso "],["proceso-de-estimación-y-predicción-1.html", "10.1 Proceso de estimación y predicción", " 10.1 Proceso de estimación y predicción source(&quot;Recursos/Día3/Sesion2/0Recursos/funciones_mrp.R&quot;) fit &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/fit_ingresos.rds&quot;) La información auxiliar disponible ha sido extraída del censo e imágenes satelitales statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) tba(statelevel_predictors_df %&gt;% head(10)) dam dam2 area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 05 05001 0.9832 0.5299 0.2671 0.2201 0.2355 0.1060 0.0251 0.2598 0.4048 0.2287 0.0009 0.0354 0.0024 0.0258 0.0833 0.0062 4.9762 -0.5072 7.2903 2.8648 -0.3953 -0.5248 05 05002 0.3953 0.4807 0.2229 0.1977 0.2497 0.1281 0.0035 0.5644 0.2393 0.0473 0.0001 0.3416 0.0160 0.1139 0.1395 0.0000 -0.3246 -0.5749 -0.1807 -0.0439 -0.3439 -0.4224 05 05004 0.3279 0.4576 0.2376 0.2075 0.2316 0.1218 0.0199 0.4470 0.3460 0.0723 0.0000 0.3694 0.0325 0.0787 0.1557 0.0000 -0.6111 -0.5475 -0.2991 -0.8159 0.0619 -0.0654 05 05021 0.5770 0.5020 0.2191 0.1946 0.2357 0.1274 0.0031 0.5038 0.2727 0.0716 0.0000 0.2785 0.0255 0.0959 0.1025 0.0000 -0.4532 -0.6694 -0.1852 -0.3570 -0.2956 -0.3104 05 05030 0.4859 0.5063 0.2571 0.2047 0.2507 0.0997 0.0048 0.4130 0.3756 0.0828 0.0003 0.0775 0.0143 0.0844 0.1176 0.0000 1.1636 -0.5002 0.7336 1.4706 -0.3670 -0.4265 05 05031 0.5766 0.4978 0.2695 0.1961 0.2047 0.0850 0.0050 0.4618 0.2981 0.0585 0.0001 0.4010 0.0970 0.1200 0.1417 0.0000 -0.5077 -0.6806 -0.2532 -0.6818 0.0167 0.2017 05 05034 0.5029 0.4815 0.2530 0.2052 0.2324 0.1042 0.0060 0.4731 0.2976 0.0634 0.0065 0.3435 0.0069 0.1089 0.1301 0.0000 -0.2580 -0.5573 -0.2197 0.2265 -0.0293 -0.2376 05 05036 0.3931 0.4951 0.2447 0.1955 0.2435 0.1142 0.0054 0.4808 0.3010 0.0591 0.0006 0.1341 0.0227 0.1100 0.1561 0.0000 0.7139 -0.5957 -0.2053 1.0807 -0.3818 -0.5131 05 05038 0.2256 0.4927 0.2659 0.1984 0.2049 0.0904 0.0050 0.5162 0.2696 0.0281 0.0000 0.2768 0.1011 0.1544 0.2247 0.0000 -0.4100 -0.5108 -0.2644 -0.1709 -0.3398 -0.3666 05 05040 0.4858 0.4826 0.2859 0.1982 0.1678 0.0641 0.0168 0.4928 0.2738 0.0361 0.0117 0.4961 0.0824 0.1253 0.1948 0.0000 -0.5447 -0.6866 -0.2954 -0.9040 0.0470 0.1783 Obtener el modelo es solo un paso más, ahora se debe realizar la predicción en el censo, el cual a sido previamente estandarizado y homologado con la encuesta. poststrat_df &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/censo_dam2.rds&quot;) %&gt;% left_join(statelevel_predictors_df) tba( poststrat_df %&gt;% arrange(desc(n)) %&gt;% head(10)) dam dam2 area sexo edad etnia anoest n area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 11 11001 1 1 2 3 3 602093 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 2 3 3 538416 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 3 3 4 435396 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 2 3 4 406654 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 1 1 3 2 368795 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 1 3 3 4 360435 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 1 3 3 3 359097 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 4 3 3 353834 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 3 3 3 345223 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 11 11001 1 2 1 3 2 341452 0.9979 0.5219 0.269 0.2316 0.2251 0.0886 0.0093 0.2098 0.381 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 2.0576 0.1112 4.7003 1.9002 -0.2644 -0.2257 Note que la información del censo esta agregada. 10.1.1 Distribución posterior. Para obtener una distribución posterior de cada observación se hace uso de la función posterior_epred de la siguiente forma. epred_mat &lt;- posterior_epred(fit, newdata = poststrat_df, type = &quot;response&quot;) dim(epred_mat) dim(poststrat_df) Como el interés es realizar comparaciones entre los países de la región se presenta la estimación del ingreso medio en términos de lineas de pobreza. Para esto procedemos así: Obteniendo las lineas de pobreza por cada post-estrato ( lp &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/encuestaCOL18N1.rds&quot;) %&gt;% distinct(area_ee, lp, li) %&gt;% mutate( area = ifelse( haven::as_factor(area_ee, levels = &quot;values&quot;) == 1 , &quot;1&quot;, &quot;0&quot;), area_ee = NULL ) ) %&gt;% tba() lp li area 296845 147169 1 200760 127346 0 Ingreso en términos de lineas de pobreza. lp &lt;- inner_join(poststrat_df,lp,by = &quot;area&quot;) %&gt;% select(lp) epred_mat_pobreza_lp &lt;- (exp(epred_mat)-1) &lt;= lp$lp epred_mat_pobreza_li &lt;- (exp(epred_mat)-1) &lt;= lp$li "],["estimación-de-la-pobreza.html", "10.2 Estimación de la pobreza", " 10.2 Estimación de la pobreza n_filtered &lt;- poststrat_df$n mrp_estimates &lt;- epred_mat_pobreza_lp %*% n_filtered / sum(n_filtered) (temp_ing &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0.1805 0.0542 El resultado nos indica que el ingreso medio nacional es 0.18 lineas de pobreza 10.2.1 Estimación para el dam == “44”. Es importante siempre conservar el orden de la base, dado que relación entre la predicción y el censo en uno a uno. temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam == &quot;44&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat_pobreza_lp[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam44 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0.185 0.0336 El resultado nos indica que el ingreso medio en el dam 44 es 0.18 lineas de pobreza 10.2.2 Estimación para la dam2 == “44001” temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam2 == &quot;44001&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat_pobreza_lp[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam2_44001 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0.185 0.0336 El resultado nos indica que el ingreso medio en la dam2 44001 es 0.18 lineas de pobreza Después de comprender la forma en que se realiza la estimación de los dominios no observados procedemos el uso de la función Aux_Agregado que es desarrollada para este fin. (mrp_estimate_Ingresolp &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat_pobreza_lp, byMap = NULL) ) Nacional mrp_estimate mrp_estimate_se Nacional 0.1805 0.0542 De forma similar es posible obtener los resultados para las divisiones administrativas. mrp_estimate_dam &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat_pobreza_lp, byMap = &quot;dam&quot;) tba(mrp_estimate_dam %&gt;% head(10)) dam2 mrp_estimate mrp_estimate_se 05001 0.0000 0.0000 05002 0.5176 0.0845 05004 0.5230 0.3123 05021 0.5038 0.3061 05030 0.2005 0.2373 05031 0.5409 0.0828 05034 0.2354 0.0755 05036 0.2414 0.2577 05038 0.5010 0.3142 05040 0.5639 0.3063 mrp_estimate_dam2 &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat_pobreza_lp, byMap = &quot;dam2&quot;) tba(mrp_estimate_dam2 %&gt;% head(10) ) dam2 mrp_estimate mrp_estimate_se 05001 0.0000 0.0000 05002 0.5176 0.0845 05004 0.5230 0.3123 05021 0.5038 0.3061 05030 0.2005 0.2373 05031 0.5409 0.0828 05034 0.2354 0.0755 05036 0.2414 0.2577 05038 0.5010 0.3142 05040 0.5639 0.3063 El mapa resultante es el siguiente "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
