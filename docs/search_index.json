[["index.html", "Desagregación de datos en encuestas de hogares: metodologías bayesianas para modelos de estimación en áreas pequeñas Agenda", " Desagregación de datos en encuestas de hogares: metodologías bayesianas para modelos de estimación en áreas pequeñas Andrés Gutiérrez1, Stalyn Guerrero2 2023-03-20 Agenda Experto Regional en Estadísticas Sociales - Comisión Económica para América Latina y el Caribe (CEPAL) - andres.gutierrez@cepal.org↩︎ Consultor - Comisión Económica para América Latina y el Caribe (CEPAL), guerrerostalyn@gmail.com↩︎ "],["día-1---sesión-1--no-dejar-a-nadie-atrás---ods-y-la-agenda-2030.html", "Capítulo 1 Día 1 - Sesión 1- No dejar a nadie atrás - ODS y la Agenda 2030", " Capítulo 1 Día 1 - Sesión 1- No dejar a nadie atrás - ODS y la Agenda 2030 Ver presentación "],["día-1---sesión-2--limitaciones-de-las-encuestas-de-hogares.html", "Capítulo 2 Día 1 - Sesión 2- Limitaciones de las encuestas de hogares", " Capítulo 2 Día 1 - Sesión 2- Limitaciones de las encuestas de hogares Ver presentación "],["día-1---sesión-3--censo-e-información-satelital.html", "Capítulo 3 Día 1 - Sesión 3- Censo e información satelital ", " Capítulo 3 Día 1 - Sesión 3- Censo e información satelital "],["uso-de-imágenes-satelitales-y-sae.html", "3.1 Uso de imágenes satelitales y SAE", " 3.1 Uso de imágenes satelitales y SAE Uno de los artículo pioneros de estimación de áreas pequeñas fue el artículo de Singh, R, et. al. (2002) el cual abordó la estimación del rendimiento de cultivos para los tehsil (unidad subadministrativa) del distriyo Rohtak district en Haryana (India). Las imágenes raster representan el mundo mediante un conjunto de celdas contiguas igualmente espaciadas conocidas como pixeles, estas imágenes tienen información como un sistema de información geográfico, Un sistema de referencia de coordenadas. Las imágenes almacenan un identificador, un valor en cada pixel (o un vector con diferentes valores) y cada celda tiene asociada una escala de colores. Las imágenes pueden obtenerse crudas y procesadas, estas primeras contienen solamente las capas de colores, las segundas contienen también valores que han sido procesados en cada celda (índices de vegetación, intensidad lumínica, tipo de vegetación). La información cruda puede utilizarse para entrenar características que se desean entrenar (carreteras, tipo de cultivo, bosque / no bosque), afortunadamente en Google Earth Engine encontramos muchos indicadores procesadas asociadas a un pixel. Estos indicadores pueden agregarse a nivel de un área geográfica. 3.1.1 Fuentes de datos de imágenes satelitales Algunas de las principales fuentes de imágenes satelitales son: http://earthexplorer.usgs.gov/ https://lpdaacsvc.cr.usgs.gov/appeears/ https://search.earthdata.nasa.gov/search https://scihub.coGTMnicus.eu/ https://aws.amazon.com/public-data-sets/landsat/ Sin embargo la mayor parte de estas fuentes están centralizadas en Google Earth Engine que permite buscar fuentes de datos provenientes de imágenes satelitales. GEE se puede manejar por medio de APIS en diferentes lenguajes de programación: Javascript (por defecto), Python y R (paquete rgee). "],["google-earth-eninge.html", "3.2 Google Earth Eninge", " 3.2 Google Earth Eninge Crear una cuenta en link, una vez que se ingrese a la cuenta puede buscarse los conjuntos de datos de interés: Una vez se busque el conjunto de datos se puede abrir un editor de código brindado por google en Javascript. Copiar y pegar la sintaxis que brinda el buscador de conjunto de datos para visualizar la imagen raster y disponer de sentencias que GTMmitan la obtención del conjunto de datos de interés posteriormente en R "],["instalación-de-rgee.html", "3.3 Instalación de rgee", " 3.3 Instalación de rgee Descargar e instalar anaconda o conda. (https://www.anaconda.com/products/individual) Abrir Anaconda prompt y configurar ambiente de trabajo (ambiente python rgee_py) con las siguientes sentencias: conda create -n rgee_py python=3.9 activate rgee_py pip install google-api-python-client pip install earthengine-api pip install numpy Listar los ambientes de Python disponibles en anaconda prompt conda env list Una vez identificado la ruta del ambiente ambiente rgee_py definirla en R (no se debe olvidar cambiar \\ por /). Instalar reticulate y rgee, cargar paquetes para procesamiento espacial y configurar el ambiente de trabajo como sigue: library(reticulate) # Conexión con Python library(rgee) # Conexión con Google Earth Engine library(sf) # Paquete para manejar datos geográficos library(dplyr) # Paquete para procesamiento de datos rgee_environment_dir = &quot;C://Users//sguerrero//Anaconda3//envs//rgee_py//python.exe&quot; # Configurar python (Algunas veces no es detectado y se debe reiniciar R) reticulate::use_python(rgee_environment_dir, required=T) rgee::ee_install_set_pyenv(py_path = rgee_environment_dir, py_env = &quot;rgee_py&quot;) Sys.setenv(RETICULATE_PYTHON = rgee_environment_dir) Sys.setenv(EARTHENGINE_PYTHON = rgee_environment_dir) Una vez configurado el ambiente puede iniciarlizarse una sesión de Google Earth Engine como sigue: rgee::ee_Initialize(drive = T) Notas: Se debe inicializar cada sesión con el comando rgee::ee_Initialize(drive = T). Los comandos de javascript que invoquen métodos con “.” se sustituyen por signo peso ($), por ejemplo: ee.ImageCollection().filterDate() # Javascript ee$ImageCollection()$filterDate() # R 3.3.1 Descargar información satelital Paso 1: disponer de los shapefile # shape &lt;- read_sf(&quot;Shape/COL_dam2.shp&quot;) shape &lt;- read_sf(&quot;Recursos/Día1/Sesion3/Shape/COL.shp&quot;) plot(shape[&quot;geometry&quot;]) Paso 2: Seleccionar el archivo de imágenes que desea procesar, para nuestro ejemplo luces nocturnas. luces &lt;- ee$ImageCollection(&quot;NOAA/DMSP-OLS/NIGHTTIME_LIGHTS&quot;) %&gt;% ee$ImageCollection$filterDate(&quot;2013-01-01&quot;, &quot;2014-01-01&quot;) %&gt;% ee$ImageCollection$map(function(x) x$select(&quot;stable_lights&quot;)) %&gt;% ee$ImageCollection$toBands() Paso 3: Descargar la información ## Tiempo 10 minutos shape_luces &lt;- map(unique(shape$dam), ~tryCatch(ee_extract( x = luces, y = shape[&quot;dam&quot;] %&gt;% filter(dam == .x), ee$Reducer$mean(), sf = FALSE ) %&gt;% mutate(dam = .x), error = function(e)data.frame(dam = .x))) shape_luces %&lt;&gt;% bind_rows() tba(shape_luces, cap = &quot;Promedio de luces nocturnasa&quot;) Repetir la rutina para: Tipo de suelo: crops-coverfraction (Porcentaje de cubrimiento cultivos) y urban-coverfraction (Porcentaje de cobertura urbana) disponibles en https://develoGTMs.google.com/earth-engine/datasets/catalog/COGTMNICUS_Landcover_100m_Proba-V-C3_Global#description Tiempo de viaje al hospital o clínica más cercana (accessibility) y tiempo de viaje al hospital o clínica más cercana utilizando transporte no motorizado (accessibility_walking_only) información disponible en https://develoGTMs.google.com/earth-engine/datasets/catalog/Oxford_MAP_accessibility_to_healthcare_2019 Modificación humana, donde se consideran los asentamiento humano, la agricultura, el transporte, la minería y producción de energía e infraestructura eléctrica. En el siguiente link encuentra la información satelital https://develoGTMs.google.com/earth-engine/datasets/catalog/CSP_HM_GlobalHumanModification#description Paso 4 consolidar la información. dam luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 05 2.3809 1.2755 0.6900 0.2947 181.1119 420.4946 08 13.0102 9.7734 4.7396 0.4943 28.2639 154.5701 11 21.5163 9.7879 19.8337 0.5509 60.7259 267.8848 13 1.9374 1.9246 0.6285 0.2911 216.2115 501.9515 15 2.6495 13.8033 0.5758 0.2965 115.8310 309.3832 17 4.4541 2.5939 0.8696 0.3639 62.2349 228.6569 18 0.0877 0.2771 0.0456 0.1248 1218.6141 2505.8205 19 1.4020 4.0623 0.3414 0.2231 214.3356 406.7882 20 2.6586 10.6343 0.4973 0.3349 99.1499 365.6516 23 2.2205 10.5568 0.5211 0.3331 141.3763 441.9516 Los resultados se muestran en los siguientes mapas 3.3.2 Luces nocturnas 3.3.3 Cubrimiento cultivos 3.3.4 Cubrimiento urbanos 3.3.5 Modificación humana 3.3.6 Tiempo promedio al hospital 3.3.7 Tiempo promedio al hospital en vehiculo no motorizado "],["censos-de-población-y-vivienda.html", "3.4 Censos de población y vivienda", " 3.4 Censos de población y vivienda Es necesario definir las variables del país con los que se desea trabajar. De acuerdo a esto, como primer paso se debe tener acceso al censo del país, para ello puede acceder desde el siguiente enlace https://redatam.org/en/microdata en el cual dispondrá de un archivo .zip con los microdatos del país. Ahora bien, para leer el conjunto de datos, es necesario emplear la función redatam.open de la librería redatam, la cual depende directamente del diccionario censal del software REDATAM, este es un archivo con extensión dicx y que debe encontrarse en la carpeta sobre los datos que se están leyendo. Así, es como se crea un objeto dentro de R que hace la respectiva unión del diccionario con los microdatos de la base de datos censal. La siguiente sintaxis muestra la lectura del diccionario en R y los cálculos iniciales library(redatam) colombia &lt;- redatam.open( &quot;UNFPA/D6/Data/cpv2018col-cde.dicX&quot;) CONTEOS &lt;- redatam.query(colombia, &quot;freq DEPTO.REDCODEN by CLASE.AREA by PERSONA.P_SEXO by PERSONA.P_EDAD by PERSONA.UnidasR by PERSONA.EDUCA by PERSONA.PBLOPER &quot;, tot.omit = FALSE) # Eliminando totales de la tabla CONTEOS2 &lt;- CONTEOS %&gt;% filter_at(vars(matches(&quot;_label&quot;)),all_vars(. != &quot;__tot__&quot;)) Después de realizar algunas validaciones se estandarizan las variables como muestra el siguiente código. censo_mrp &lt;- CONTEOS2 %&gt;% transmute(dam =str_pad(string = REDCODEN1_value, width = 2, pad = &quot;0&quot;), area = case_when(AREA2_value == 1 ~ &quot;1&quot;, # 1 = Urbana TRUE ~ &quot;0&quot;), sexo = as.character(P_SEXO3_value), edad = case_when( P_EDAD4_value %in% 0:14 ~ &quot;1&quot;, # 0 a 14 P_EDAD4_value %in% 15:29 ~ &quot;2&quot;, # 15 a 29 P_EDAD4_value %in% 30:44 ~ &quot;3&quot;, # 30 a 44 P_EDAD4_value %in% 45:64~ &quot;4&quot;, # 45 a 64 TRUE ~ &quot;5&quot;), # 65 o mas etnia = case_when( PBLOPER5_value %in% c(1) ~ &quot;1&quot;, # Indigena PBLOPER5_value %in% c(2)~ &quot;2&quot;, # Afro TRUE ~ &quot;3&quot;), # Otro anoest = case_when( P_EDAD4_value &lt; 6 | is.na(ANEST6_value) ~ &quot;98&quot;, # No aplica ANEST6_value == 99 ~ &quot;99&quot;, #NS/NR ANEST6_value %in% 0 ~ &quot;1&quot;, # Sin educacion ANEST6_value %in% c(1:6) ~ &quot;2&quot;, # 1-6 ANEST6_value %in% c(7:12) ~ &quot;3&quot;, # 7-12 ANEST6_value &gt; 12 ~ &quot;4&quot; , # 12 o mas TRUE ~ &quot;Error&quot; ), value) %&gt;% group_by(dam, area, sexo, edad, etnia, anoest) %&gt;% summarise(n = sum(value), .groups = &quot;drop&quot;) A partir de la base estandarizada es posible construir algunas covariables para el departamento. censo_mrp &lt;- readRDS(&quot;Recursos/Día1/Sesion3/Data/censo_mrp_dam.rds&quot;) tasa_censo &lt;- model.matrix(dam ~ -1 +., data = censo_mrp %&gt;% select(-n)) %&gt;% data.frame() %&gt;% mutate(dam = censo_mrp$dam, n = censo_mrp$n) %&gt;% group_by(dam) %&gt;% summarise_all(~weighted.mean(x = .,w = n)) %&gt;% mutate(etnia1 = 1-etnia3-etnia2) %&gt;% select(-area0,-anoest99, -anoest98,-etnia3,-n) tba(tasa_censo) dam area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 05 0.8000 0.5171 0.2620 0.2159 0.2273 0.0976 0.0522 0.3148 0.3802 0.1780 0.0063 08 0.9503 0.5131 0.2613 0.2108 0.2059 0.0843 0.0598 0.2556 0.4169 0.1847 0.0167 11 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 13 0.7529 0.5037 0.2600 0.1988 0.1915 0.0806 0.1673 0.3149 0.3749 0.1334 0.0027 15 0.6017 0.5077 0.2390 0.2018 0.2224 0.1136 0.0037 0.3712 0.3368 0.1487 0.0063 17 0.7535 0.5154 0.2374 0.2013 0.2518 0.1243 0.0159 0.3569 0.3664 0.1562 0.0604 18 0.6764 0.4928 0.2813 0.1962 0.1708 0.0643 0.0141 0.4132 0.3170 0.0834 0.0245 19 0.3958 0.5048 0.2688 0.2081 0.1867 0.0890 0.1973 0.4067 0.3344 0.0992 0.2481 20 0.7591 0.5050 0.2707 0.2000 0.1684 0.0645 0.1297 0.3214 0.3528 0.1227 0.0466 23 0.5617 0.5022 0.2570 0.1944 0.1939 0.0839 0.0659 0.3384 0.3469 0.1164 0.1303 25 0.7312 0.5059 0.2557 0.2162 0.2155 0.0924 0.0047 0.3181 0.3904 0.1622 0.0036 27 0.4934 0.5060 0.2709 0.1841 0.1463 0.0568 0.7383 0.3450 0.2785 0.0889 0.1496 41 0.6101 0.5010 0.2636 0.2005 0.1985 0.0852 0.0051 0.3953 0.3379 0.1094 0.0121 44 0.4748 0.5103 0.2799 0.1846 0.1381 0.0498 0.0733 0.3395 0.2769 0.0934 0.4782 47 0.7110 0.4995 0.2640 0.1937 0.1812 0.0739 0.0841 0.3273 0.3707 0.1085 0.0166 50 0.7655 0.4942 0.2656 0.2152 0.1973 0.0726 0.0096 0.3374 0.3630 0.1418 0.0223 52 0.4849 0.5105 0.2670 0.2134 0.1984 0.0975 0.1745 0.4223 0.3120 0.1045 0.1546 54 0.7904 0.5069 0.2654 0.2100 0.2001 0.0820 0.0041 0.3633 0.3482 0.1253 0.0034 63 0.8807 0.5180 0.2416 0.2015 0.2518 0.1281 0.0119 0.3136 0.4014 0.1668 0.0057 66 0.7832 0.5215 0.2442 0.2068 0.2394 0.1169 0.0199 0.3370 0.3782 0.1631 0.0356 68 0.7680 0.5104 0.2497 0.2125 0.2215 0.0981 0.0113 0.3281 0.3594 0.1743 0.0006 70 0.6502 0.4972 0.2557 0.1946 0.1948 0.0873 0.1190 0.3367 0.3459 0.1099 0.1214 73 0.7096 0.5044 0.2388 0.1927 0.2308 0.1173 0.0042 0.3655 0.3575 0.1324 0.0368 76 0.8555 0.5249 0.2461 0.2114 0.2369 0.1124 0.1709 0.2927 0.4084 0.1809 0.0081 81 0.6687 0.4945 0.2825 0.2065 0.1701 0.0585 0.0420 0.3898 0.3237 0.1002 0.0274 85 0.7266 0.4945 0.2749 0.2257 0.1782 0.0550 0.0161 0.3602 0.3617 0.1170 0.0181 86 0.5602 0.4954 0.2915 0.2098 0.1660 0.0625 0.0362 0.3967 0.3516 0.0913 0.1790 88 0.6658 0.5171 0.2415 0.2124 0.2561 0.0752 0.5564 0.2161 0.4525 0.2167 0.0004 91 0.5237 0.4789 0.2933 0.1792 0.1313 0.0428 0.0074 0.3517 0.3615 0.0734 0.5772 94 0.4350 0.4775 0.2902 0.1595 0.1182 0.0353 0.0104 0.4679 0.2266 0.0589 0.7490 95 0.5939 0.4653 0.2859 0.1972 0.1780 0.0524 0.0409 0.4169 0.3011 0.0917 0.0938 97 0.3066 0.4748 0.2743 0.1330 0.1129 0.0380 0.0076 0.4650 0.2663 0.0525 0.8168 99 0.3204 0.4690 0.2877 0.1697 0.1250 0.0349 0.0076 0.4315 0.2250 0.0526 0.5816 El indicador es posible definirlo a partir de una variable del censo, haciendo que el proceso seá hace más corto, para este caso es empleada la variable VIVIENDA.VC_ALC, agregada por departamento. En el primer bloque que código usando la función redatam.query() se realiza el conteo de viviendas que tienen el servicio de acueducto. Seguido de esto, eliminamos los registros que no son de interés, por ejemplo, el total en el departamento o total nacional, los cuales se identifican dentro de la base con la etiqueta __tot__. El siguiente paso es contar el número de viviendas por departamento que NO cuentan con acueducto en el censo (Pobx) y el total de viviendas que respondieron a la pregunta (PobT), para finalmente realizar el cociente de estas dos preguntas. CONTEOS &lt;- redatam.query(Colombia, &quot;freq DEPTO.REDCODEN by VIVIENDA.VB_ACU&quot;, tot.omit = FALSE) ACUEDUCTO &lt;- CONTEOS %&gt;% filter_at(vars(matches(&quot;_label&quot;)), all_vars(!. %in% c(&quot;__tot__&quot;) )) # 1 = Si # 2 = No tasa_agua &lt;- ACUEDUCTO %&gt;% mutate(Pobx = ifelse(!VB_ACU2_value %in% c(1), value, 0), PobT = value) %&gt;% group_by( dam = str_pad(string = REDCODEN1_value, width = 2, pad = &quot;0&quot;) ) %&gt;% summarise(PobT = sum(PobT), Pobx = sum(Pobx)) %&gt;% transmute(dam, tiene_acueducto = Pobx/PobT) La tabla resultante se muestra a continuación. dam tiene_acueducto 05 0.2508 08 0.1543 11 0.0759 13 0.3312 15 0.3930 17 0.2757 18 0.4201 19 0.4776 20 0.2930 23 0.3979 25 0.2825 27 0.7639 41 0.3443 44 0.5824 47 0.4155 50 0.3881 52 0.3873 54 0.3328 63 0.1720 66 0.2503 68 0.3330 70 0.2716 73 0.3293 76 0.1900 81 0.4102 85 0.3558 86 0.5738 91 0.6481 94 0.8221 95 0.6513 97 0.6797 99 0.6887 88 0.6776 El proceso se repite con otras preguntas del censo hasta consolidar la tabla siguiente. predictors_censo_dam &lt;- readRDS(&quot;Recursos/Día1/Sesion3/Data/predictors_censo_dam.rds&quot;) tba(predictors_censo_dam) dam area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion 05 0.8000 0.5171 0.2620 0.2159 0.2273 0.0976 0.0522 0.3148 0.3802 0.1780 0.0063 0.2508 0.0286 0.0447 0.1159 0.0904 08 0.9503 0.5131 0.2613 0.2108 0.2059 0.0843 0.0598 0.2556 0.4169 0.1847 0.0167 0.1543 0.0211 0.0367 0.2359 0.1359 11 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 0.0759 0.0024 0.0131 0.0848 0.0889 13 0.7529 0.5037 0.2600 0.1988 0.1915 0.0806 0.1673 0.3149 0.3749 0.1334 0.0027 0.3312 0.1367 0.0787 0.2872 0.1448 15 0.6017 0.5077 0.2390 0.2018 0.2224 0.1136 0.0037 0.3712 0.3368 0.1487 0.0063 0.3930 0.0562 0.0587 0.1323 0.1039 17 0.7535 0.5154 0.2374 0.2013 0.2518 0.1243 0.0159 0.3569 0.3664 0.1562 0.0604 0.2757 0.0150 0.0511 0.0996 0.0763 18 0.6764 0.4928 0.2813 0.1962 0.1708 0.0643 0.0141 0.4132 0.3170 0.0834 0.0245 0.4201 0.0801 0.0689 0.1773 0.0928 19 0.3958 0.5048 0.2688 0.2081 0.1867 0.0890 0.1973 0.4067 0.3344 0.0992 0.2481 0.4776 0.2088 0.0760 0.1692 0.1207 20 0.7591 0.5050 0.2707 0.2000 0.1684 0.0645 0.1297 0.3214 0.3528 0.1227 0.0466 0.2930 0.1125 0.0880 0.3177 0.1445 23 0.5617 0.5022 0.2570 0.1944 0.1939 0.0839 0.0659 0.3384 0.3469 0.1164 0.1303 0.3979 0.2975 0.1174 0.2971 0.1143 25 0.7312 0.5059 0.2557 0.2162 0.2155 0.0924 0.0047 0.3181 0.3904 0.1622 0.0036 0.2825 0.0204 0.0337 0.1152 0.0797 27 0.4934 0.5060 0.2709 0.1841 0.1463 0.0568 0.7383 0.3450 0.2785 0.0889 0.1496 0.7639 0.0560 0.1451 0.2189 0.1419 41 0.6101 0.5010 0.2636 0.2005 0.1985 0.0852 0.0051 0.3953 0.3379 0.1094 0.0121 0.3443 0.0741 0.0565 0.1689 0.0914 44 0.4748 0.5103 0.2799 0.1846 0.1381 0.0498 0.0733 0.3395 0.2769 0.0934 0.4782 0.5824 0.3918 0.1716 0.4535 0.1931 47 0.7110 0.4995 0.2640 0.1937 0.1812 0.0739 0.0841 0.3273 0.3707 0.1085 0.0166 0.4155 0.1320 0.0924 0.3424 0.1404 50 0.7655 0.4942 0.2656 0.2152 0.1973 0.0726 0.0096 0.3374 0.3630 0.1418 0.0223 0.3881 0.0514 0.0423 0.1368 0.1101 52 0.4849 0.5105 0.2670 0.2134 0.1984 0.0975 0.1745 0.4223 0.3120 0.1045 0.1546 0.3873 0.1362 0.0841 0.2128 0.1418 54 0.7904 0.5069 0.2654 0.2100 0.2001 0.0820 0.0041 0.3633 0.3482 0.1253 0.0034 0.3328 0.0688 0.0645 0.2450 0.1194 63 0.8807 0.5180 0.2416 0.2015 0.2518 0.1281 0.0119 0.3136 0.4014 0.1668 0.0057 0.1720 0.0077 0.0441 0.0853 0.1048 66 0.7832 0.5215 0.2442 0.2068 0.2394 0.1169 0.0199 0.3370 0.3782 0.1631 0.0356 0.2503 0.0065 0.0448 0.0916 0.0816 68 0.7680 0.5104 0.2497 0.2125 0.2215 0.0981 0.0113 0.3281 0.3594 0.1743 0.0006 0.3330 0.0413 0.0438 0.1414 0.1096 70 0.6502 0.4972 0.2557 0.1946 0.1948 0.0873 0.1190 0.3367 0.3459 0.1099 0.1214 0.2716 0.2175 0.1257 0.3204 0.1379 73 0.7096 0.5044 0.2388 0.1927 0.2308 0.1173 0.0042 0.3655 0.3575 0.1324 0.0368 0.3293 0.0539 0.0611 0.1430 0.0932 76 0.8555 0.5249 0.2461 0.2114 0.2369 0.1124 0.1709 0.2927 0.4084 0.1809 0.0081 0.1900 0.0080 0.0347 0.0910 0.0953 81 0.6687 0.4945 0.2825 0.2065 0.1701 0.0585 0.0420 0.3898 0.3237 0.1002 0.0274 0.4102 0.1742 0.0669 0.2458 0.1455 85 0.7266 0.4945 0.2749 0.2257 0.1782 0.0550 0.0161 0.3602 0.3617 0.1170 0.0181 0.3558 0.0605 0.0500 0.1934 0.1572 86 0.5602 0.4954 0.2915 0.2098 0.1660 0.0625 0.0362 0.3967 0.3516 0.0913 0.1790 0.5738 0.0303 0.0604 0.1764 0.1316 91 0.5237 0.4789 0.2933 0.1792 0.1313 0.0428 0.0074 0.3517 0.3615 0.0734 0.5772 0.6481 0.0470 0.0565 0.3585 0.0782 94 0.4350 0.4775 0.2902 0.1595 0.1182 0.0353 0.0104 0.4679 0.2266 0.0589 0.7490 0.8221 0.3130 0.0872 0.3781 0.1196 95 0.5939 0.4653 0.2859 0.1972 0.1780 0.0524 0.0409 0.4169 0.3011 0.0917 0.0938 0.6513 0.1052 0.0635 0.1645 0.0799 97 0.3066 0.4748 0.2743 0.1330 0.1129 0.0380 0.0076 0.4650 0.2663 0.0525 0.8168 0.6797 0.3105 0.1008 0.4443 0.1040 99 0.3204 0.4690 0.2877 0.1697 0.1250 0.0349 0.0076 0.4315 0.2250 0.0526 0.5816 0.6887 0.4305 0.1137 0.4338 0.1838 88 0.6658 0.5171 0.2415 0.2124 0.2561 0.0752 0.5564 0.2161 0.4525 0.2167 0.0004 0.6776 0.0107 0.0122 0.1879 0.0358 3.4.1 Mapas de las variables con información censal. temp2 &lt;- inner_join(shape[&quot;dam&quot;], predictors_censo_dam) for(ii in names(predictors_censo_dam[,-1])){ plot( temp2[ii], key.pos = 4, breaks = quantile(temp2[[ii]])) } "],["día-1---sesión-4--fundamentos-de-la-inferencia-bayesiana-en-r-y-stan.html", "Capítulo 4 Día 1 - Sesión 4- Fundamentos de la inferencia Bayesiana en R y STAN ", " Capítulo 4 Día 1 - Sesión 4- Fundamentos de la inferencia Bayesiana en R y STAN "],["regla-de-bayes.html", "4.1 Regla de Bayes", " 4.1 Regla de Bayes En términos de inferencia para \\(\\boldsymbol{\\theta}\\), es necesario encontrar la distribución de los parámetros condicionada a la observación de los datos. Para este fin, es necesario definir la distribución conjunta de la variable de interés con el vector de parámetros. \\[ p(\\boldsymbol{\\theta},\\mathbf{Y})=p(\\boldsymbol{\\theta})p(\\mathbf{Y} \\mid \\boldsymbol{\\theta}) \\] La distribución \\(p(\\boldsymbol{\\theta})\\) se le conoce con el nombre de distribución previa. El término \\(p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})\\) es la distribución de muestreo, verosimilitud o distribución de los datos. La distribución del vector de parámetros condicionada a los datos observados está dada por \\[ p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})=\\frac{p(\\boldsymbol{\\theta},\\mathbf{Y})}{p(\\mathbf{Y})}=\\frac{p(\\boldsymbol{\\theta})p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})}{p(\\mathbf{Y})} \\] A la distribución \\(p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})\\) se le conoce con el nombre de distribución posterior. Nótese que el denominador no depende del vector de parámetros y considerando a los datos observados como fijos, corresponde a una constante y puede ser obviada. Por lo tanto, otra representación de la regla de Bayes está dada por \\[ p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})\\propto p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) \\] "],["inferencia-bayesiana..html", "4.2 Inferencia Bayesiana.", " 4.2 Inferencia Bayesiana. En términos de estimación, inferencia y predicción, el enfoque Bayesiano supone dos momentos o etapas: Antes de la recolección de las datos, en donde el investigador propone, basado en su conocimiento, experiencia o fuentes externas, una distribución de probabilidad previa para el parámetro de interés. Después de la recolección de los datos. Siguiendo el teorema de Bayes, el investigador actualiza su conocimiento acerca del comportamiento probabilístico del parámetro de interés mediante la distribución posterior de este. "],["modelos-uniparamétricos.html", "4.3 Modelos uniparamétricos", " 4.3 Modelos uniparamétricos Los modelos que están definidos en términos de un solo parámetro que pertenece al conjunto de los números reales se definen como modelos uniparamétricos. "],["modelo-bernoulli.html", "4.4 Modelo Bernoulli", " 4.4 Modelo Bernoulli Suponga que \\(Y\\) es una variable aleatoria con distribución Bernoulli dada por: \\[ p(Y \\mid \\theta)=\\theta^y(1-\\theta)^{1-y}I_{\\{0,1\\}}(y) \\] Como el parámetro \\(\\theta\\) está restringido al espacio \\(\\Theta=[0,1]\\), entonces es posible formular varias opciones para la distribución previa del parámetro. En particular, la distribución uniforme restringida al intervalo \\([0,1]\\) o la distribución Beta parecen ser buenas opciones. Puesto que la distribución uniforme es un caso particular de la distribución Beta. Por lo tanto la distribución previa del parámetro \\(\\theta\\) estará dada por \\[ \\begin{equation} p(\\theta \\mid \\alpha,\\beta)= \\frac{1}{Beta(\\alpha,\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}I_{[0,1]}(\\theta). \\end{equation} \\] y la distribución posterior del parámetro \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta \\mid Y \\sim Beta(y+\\alpha,\\beta-y+1) \\end{equation*} \\] Cuando se tiene una muestra aleatoria \\(Y_1,\\ldots,Y_n\\) de variables con distribución Bernoulli de parámetro \\(\\theta\\), entonces la distribución posterior del parámetro de interés es \\[ \\begin{equation*} \\theta \\mid Y_1,\\ldots,Y_n \\sim Beta\\left(\\sum_{i=1}^ny_i+\\alpha,\\beta-\\sum_{i=1}^ny_i+n\\right) \\end{equation*} \\] 4.4.1 Práctica en R library(tidyverse) encuesta &lt;- readRDS(&quot;Recursos/Día1/Sesion4/Data/encuestaCOL18N1.rds&quot;) Sea \\(Y\\) la variable aleatoria \\[ Y_{i}=\\begin{cases} 1 &amp; ingreso&lt;lp\\\\ 0 &amp; ingreso\\geq lp \\end{cases} \\] El tamaño de la muestra es de 19877 Indígena datay &lt;- encuesta %&gt;% filter(etnia_ee == 1) %&gt;% transmute(y = ifelse(ingcorte &lt; lp, 1,0)) addmargins(table(datay$y)) 0 1 Sum 9579 10298 19877 Un grupo de estadístico experto decide utilizar una distribución previa Beta, definiendo los parámetros de la distribución previa como \\(Beta(\\alpha=1, \\beta=1)\\). La distribución posterior del parámetro de interés, que representa la probabilidad de estar por debajo de la linea de pobreza, es \\(Beta(1.0298\\times 10^{4} + 1, 1 - 1.0298\\times 10^{4} + 19877)=Beta(1.0299\\times 10^{4}, 9580)\\) Figura 4.1: Distribución previa (línea roja) y distribución posterior (línea negra) La estimación del parámetro estaría dado por: \\[ E(X) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{1.0299\\times 10^{4}}{1.0299\\times 10^{4}+ 9580} = 0.5180844 \\] luego, el intervalo de credibilidad para la distribución posterior es. n = length(datay$y) n1 = sum(datay$y) qbeta(c(0.025, 0.975), shape1 = 1 + n1, shape2 = 1 - n1 + n) ## [1] 0.5111369 0.5250285 4.4.2 Práctica en STAN En STAN es posible obtener el mismo tipo de inferencia creando cuatro cadenas cuya distribución de probabilidad coincide con la distribución posterior del ejemplo. ## Definir el modelo data { // Entrada el modelo int&lt;lower=0&gt; n; // Numero de observaciones int y[n]; // Vector de longitud n real a; real b; } parameters { // Definir parámetro real&lt;lower=0, upper=1&gt; theta; } model { // Definir modelo y ~ bernoulli(theta); theta ~ beta(a, b); // Distribución previa } generated quantities { real ypred[n]; // vector de longitud n for (ii in 1:n){ ypred[ii] = bernoulli_rng(theta); } } Para compilar STAN debemos definir los parámetros de entrada sample_data &lt;- list(n = nrow(datay), y = datay$y, a = 1, b = 1) Para ejecutar STAN en R tenemos la librería cmdstanr library(cmdstanr) library(rstan) # file.edit(&quot;Recursos/Día1/Sesion4/Data/modelosStan/1Bernoulli.stan&quot;) # Bernoulli &lt;- cmdstan_model(stan_file = &quot;Recursos/Día1/Sesion4/Data/modelosStan/1Bernoulli.stan&quot;) Bernoulli &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/1Bernoulli.stan&quot; # model_Bernoulli &lt;- Bernoulli$sample(data = sample_data, # chains = 4, # parallel_chains = 4, # seed = 1234, # refresh = 1000) options(mc.cores = parallel::detectCores()) model_Bernoulli &lt;- stan( file = Bernoulli, # Stan program data = sample_data, # named list of data verbose = FALSE, warmup = 500, # number of warmup iterations per chain iter = 1000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) La estimación del parámetro \\(\\theta\\) es: # model_Bernoulli$summary(variables = &quot;theta&quot;) %&gt;% # select(variable:q95) %&gt;% tba() summary(model_Bernoulli, pars = &quot;theta&quot;)$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 0.5182 1e-04 0.0034 0.5115 0.516 0.5182 0.5206 0.5243 740.5358 1.0028 Para observar las cadenas compilamos las lineas de código library(posterior) library(ggplot2) #temp &lt;- as_draws_df(model_Bernoulli$draws(variables = &quot;theta&quot;)) temp &lt;- as_draws_df(as.array(model_Bernoulli,pars = &quot;theta&quot;)) ggplot(data = temp, aes(x = theta))+ geom_density(color = &quot;blue&quot;, size = 2) + stat_function(fun = posterior1, args = list(y = datay$y), size = 2) + theme_bw(base_size = 20) + labs(x = latex2exp::TeX(&quot;\\\\theta&quot;), y = latex2exp::TeX(&quot;f(\\\\theta)&quot;)) Figura 4.2: Resultado con STAN (línea azul) y posterior teórica (línea negra) Para validar las cadenas library(bayesplot) # (mcmc_dens_chains(model_Bernoulli$draws(&quot;theta&quot;)) + # mcmc_areas(model_Bernoulli$draws(&quot;theta&quot;)))/ # mcmc_trace(model_Bernoulli$draws(&quot;theta&quot;)) posterior_theta &lt;- as.array(model_Bernoulli, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) Predicción de \\(Y\\) en cada una de las iteraciones de las cadenas. # y_pred_B &lt;- model_Bernoulli$draws(variables = &quot;ypred&quot;, format = &quot;matrix&quot;) y_pred_B &lt;- as.array(model_Bernoulli, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, 1:n] ppc_dens_overlay(y = datay$y, y_pred2) "],["modelo-binomial.html", "4.5 Modelo Binomial", " 4.5 Modelo Binomial Cuando se dispone de una muestra aleatoria de variables con distribución Bernoulli \\(Y_1,\\ldots,Y_n\\), la inferencia Bayesiana se puede llevar a cabo usando la distribución Binomial, puesto que es bien sabido que la suma de variables aleatorias Bernoulli \\[ \\begin{equation*} S=\\sum_{i=1}^nY_i \\end{equation*} \\] sigue una distribución Binomial. Es decir: \\[ \\begin{equation} p(S \\mid \\theta)=\\binom{n}{s}\\theta^s(1-\\theta)^{n-s}I_{\\{0,1,\\ldots,n\\}}(s), \\end{equation} \\] Nótese que la distribución Binomial es un caso general para la distribución Bernoulli, cuando \\(n=1\\). Por lo tanto es natural suponer que distribución previa del parámetro \\(\\theta\\) estará dada por \\[ \\begin{equation} p(\\theta \\mid \\alpha,\\beta)= \\frac{1}{Beta(\\alpha,\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}I_{[0,1]}(\\theta). \\end{equation} \\] La distribución posterior del parámetro \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta \\mid S \\sim Beta(s+\\alpha,\\beta-s+n) \\end{equation*} \\] Ahora, cuando se tiene una sucesión de variables aleatorias \\(S_1,\\ldots,S_i, \\ldots,S_k\\) independientes y con distribución \\(Binomial(n_i,\\theta_i)\\) para \\(i=1,\\ldots,k\\), entonces la distribución posterior del parámetro de interés \\(\\theta_i\\) es \\[ \\begin{equation*} \\theta_i \\mid s_i \\sim Beta\\left(s_i+\\alpha,\\ \\beta+ n_i- s_i\\right) \\end{equation*} \\] 4.5.1 Práctica en STAN Sea \\(S_k\\) el conteo de personas en condición de pobreza en el \\(k-ésimo\\) departamento en la muestra. dataS &lt;- encuesta %&gt;% transmute( dam = dam_ee, y = ifelse(ingcorte &lt; lp, 1,0) ) %&gt;% group_by(dam) %&gt;% summarise(nd = n(), #Número de ensayos Sd = sum(y) #Número de éxito ) tba(dataS) dam nd Sd 05 45467 7301 08 44321 10297 11 32213 4128 13 35610 10560 15 26485 5717 17 30764 4524 18 28842 11134 19 34357 12348 20 32454 12203 23 31986 10528 25 9068 1516 27 26828 12934 41 30728 8188 44 35618 16412 47 37634 13500 50 29317 6653 52 28927 8949 54 31384 12663 63 28276 6195 66 29199 4664 68 31778 5127 70 35525 11881 73 28416 6295 76 37556 7073 Creando código de STAN data { int&lt;lower=0&gt; K; // Número de provincia int&lt;lower=0&gt; n[K]; // Número de ensayos int&lt;lower=0&gt; s[K]; // Número de éxitos real a; real b; } parameters { real&lt;lower=0, upper=1&gt; theta[K]; // theta_d|s_d } model { for(kk in 1:K) { s[kk] ~ binomial(n[kk], theta[kk]); } to_vector(theta) ~ beta(a, b); } generated quantities { real spred[K]; // vector de longitud K for(kk in 1:K){ spred[kk] = binomial_rng(n[kk],theta[kk]); } } Preparando el código de STAN ## Definir el modelo # file.edit(&quot;Recursos/Día1/Sesion4/Data/modelosStan/3Binomial.stan&quot;) # Binomial2 &lt;- cmdstan_model(stan_file = &quot;Recursos/Día1/Sesion4/Data/modelosStan/3Binomial.stan&quot;) Binomial2 &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/3Binomial.stan&quot; Organizando datos para STAN sample_data &lt;- list(K = nrow(dataS), s = dataS$Sd, n = dataS$nd, a = 1, b = 1) Para ejecutar STAN en R tenemos la librería cmdstanr # model_Binomial2 &lt;- Binomial2$sample(data = sample_data, # chains = 4, # parallel_chains = 4, # seed = 1234, # refresh = 1000) options(mc.cores = parallel::detectCores()) model_Binomial2 &lt;- stan( file = Binomial2, # Stan program data = sample_data, # named list of data verbose = FALSE, warmup = 500, # number of warmup iterations per chain iter = 1000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) La estimación del parámetro \\(\\theta\\) es: # model_Binomial2$summary(variables = &quot;theta&quot;) %&gt;% # select(variable:q95) %&gt;% tba() summary(model_Binomial2, pars = &quot;theta&quot;)$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta[1] 0.1606 0e+00 0.0018 0.1572 0.1593 0.1606 0.1618 0.1641 4995.662 0.9987 theta[2] 0.2323 0e+00 0.0020 0.2285 0.2309 0.2323 0.2338 0.2362 5068.657 0.9991 theta[3] 0.1281 0e+00 0.0019 0.1246 0.1269 0.1281 0.1294 0.1318 4302.302 0.9989 theta[4] 0.2965 0e+00 0.0023 0.2920 0.2949 0.2965 0.2981 0.3009 5872.753 0.9982 theta[5] 0.2159 0e+00 0.0026 0.2109 0.2141 0.2158 0.2176 0.2210 4494.272 0.9993 theta[6] 0.1471 0e+00 0.0019 0.1433 0.1458 0.1471 0.1484 0.1509 6398.598 0.9992 theta[7] 0.3861 0e+00 0.0028 0.3807 0.3842 0.3861 0.3880 0.3914 5415.280 0.9986 theta[8] 0.3594 0e+00 0.0025 0.3547 0.3577 0.3594 0.3612 0.3642 4735.259 0.9985 theta[9] 0.3760 0e+00 0.0027 0.3708 0.3741 0.3760 0.3779 0.3814 4213.212 0.9986 theta[10] 0.3292 0e+00 0.0025 0.3243 0.3275 0.3292 0.3308 0.3341 5643.390 0.9989 theta[11] 0.1673 1e-04 0.0039 0.1600 0.1647 0.1673 0.1699 0.1751 4524.756 0.9998 theta[12] 0.4821 0e+00 0.0030 0.4760 0.4802 0.4820 0.4841 0.4883 6602.060 0.9987 theta[13] 0.2665 0e+00 0.0025 0.2615 0.2647 0.2665 0.2683 0.2715 6158.453 0.9989 theta[14] 0.4608 0e+00 0.0027 0.4555 0.4590 0.4608 0.4626 0.4661 5894.068 0.9983 theta[15] 0.3587 0e+00 0.0025 0.3539 0.3570 0.3587 0.3605 0.3637 5052.024 0.9988 theta[16] 0.2270 0e+00 0.0025 0.2221 0.2253 0.2271 0.2287 0.2317 4553.205 0.9985 theta[17] 0.3094 0e+00 0.0028 0.3040 0.3075 0.3093 0.3113 0.3148 5761.156 0.9983 theta[18] 0.4035 0e+00 0.0028 0.3978 0.4015 0.4035 0.4055 0.4091 4766.386 0.9999 theta[19] 0.2191 0e+00 0.0024 0.2144 0.2174 0.2190 0.2207 0.2240 5580.557 0.9987 theta[20] 0.1597 0e+00 0.0022 0.1553 0.1583 0.1598 0.1612 0.1640 4125.715 0.9988 theta[21] 0.1614 0e+00 0.0020 0.1574 0.1601 0.1614 0.1627 0.1653 5438.808 0.9990 theta[22] 0.3345 0e+00 0.0024 0.3297 0.3329 0.3344 0.3361 0.3395 4989.644 0.9994 theta[23] 0.2216 0e+00 0.0024 0.2168 0.2200 0.2216 0.2232 0.2263 4874.975 0.9993 theta[24] 0.1883 0e+00 0.0020 0.1844 0.1870 0.1883 0.1896 0.1922 4294.990 0.9984 Para validar las cadenas # mcmc_areas(model_Binomial2$draws(&quot;theta&quot;)) mcmc_areas(as.array(model_Binomial2, pars = &quot;theta&quot;)) # mcmc_trace(model_Binomial2$draws(&quot;theta&quot;)) mcmc_trace(as.array(model_Binomial2, pars = &quot;theta&quot;)) # y_pred_B &lt;- model_Binomial2$draws(variables = &quot;spred&quot;, format = &quot;matrix&quot;) y_pred_B &lt;- as.array(model_Binomial2, pars = &quot;spred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 200) y_pred2 &lt;- y_pred_B[rowsrandom, ] g1 &lt;- ggplot(data = dataS, aes(x = Sd))+ geom_histogram(aes(y = ..density..)) + geom_density(size = 2, color = &quot;blue&quot;) + labs(y = &quot;&quot;)+ theme_bw(20) g2 &lt;- ppc_dens_overlay(y = dataS$Sd, y_pred2) g1/g2 "],["modelo-normal-con-media-desconocida.html", "4.6 Modelo Normal con media desconocida", " 4.6 Modelo Normal con media desconocida Suponga que \\(Y_1,\\cdots,Y_n\\) son variables independientes e idénticamente distribuidos con distribución \\(Normal(\\theta,\\sigma^2)\\) con \\(\\theta\\) desconocido pero \\(\\sigma^2\\) conocido. De esta forma, la función de verosimilitud de los datos está dada por \\[ \\begin{align*} p(\\mathbf{Y} \\mid \\theta) &amp;=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_i-\\theta)^2\\right\\}I_\\mathbb{R}(y) \\\\ &amp;=(2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(y_i-\\theta)^2\\right\\} \\end{align*} \\] Como el parámetro \\(\\theta\\) puede tomar cualquier valor en los reales, es posible asignarle una distribución previa \\(\\theta \\sim Normal(\\mu,\\tau^2)\\). Bajo este marco de referencia se tienen los siguientes resultados La distribución posterior del parámetro de interés \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta|\\mathbf{Y} \\sim Normal(\\mu_n,\\tau^2_n) \\end{equation*} \\] En donde \\[ \\begin{equation} \\mu_n=\\frac{\\frac{n}{\\sigma^2}\\bar{Y}+\\frac{1}{\\tau^2}\\mu}{\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}} \\ \\ \\ \\ \\ \\ \\ \\text{y} \\ \\ \\ \\ \\ \\ \\ \\tau_n^2=\\left(\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}\\right)^{-1} \\end{equation} \\] 4.6.1 Práctica en STAN Sea \\(Y\\) el logaritmo del ingreso dataNormal &lt;- encuesta %&gt;% transmute( dam_ee , logIngreso = log(ingcorte +1)) %&gt;% filter(dam_ee == &quot;08&quot;) #3 media &lt;- mean(dataNormal$logIngreso) Sd &lt;- sd(dataNormal$logIngreso) g1 &lt;- ggplot(dataNormal,aes(x = logIngreso))+ geom_density(size =2, color = &quot;blue&quot;) + stat_function(fun =dnorm, args = list(mean = media, sd = Sd), size =2) + theme_bw(base_size = 20) + labs(y = &quot;&quot;, x = (&quot;Log(Ingreso)&quot;)) g2 &lt;- ggplot(dataNormal, aes(sample = logIngreso)) + stat_qq() + stat_qq_line() + theme_bw(base_size = 20) g1|g2 Figura 4.3: Resultado en la muestra (línea azul) y distribución teórica (línea negra) Creando código de STAN data { int&lt;lower=0&gt; n; // Número de observaciones real y[n]; // LogIngreso real &lt;lower=0&gt; Sigma; // Desviación estándar } parameters { real theta; } model { y ~ normal(theta, Sigma); theta ~ normal(0, 1000); // Distribución previa } generated quantities { real ypred[n]; // Vector de longitud n for(kk in 1:n){ ypred[kk] = normal_rng(theta,Sigma); } } Preparando el código de STAN # file.edit(&quot;Recursos/Día1/Sesion4/Data/modelosStan/4NormalMedia.stan&quot;) # NormalMedia &lt;- cmdstan_model(stan_file = &quot;Recursos/Día1/Sesion4/Data/modelosStan/4NormalMedia.stan&quot;) NormalMedia &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/4NormalMedia.stan&quot; Organizando datos para STAN sample_data &lt;- list(n = nrow(dataNormal), Sigma = sd(dataNormal$logIngreso), y = dataNormal$logIngreso) Para ejecutar STAN en R tenemos la librería cmdstanr # model_NormalMedia &lt;- NormalMedia$sample(data = sample_data, # chains = 4, # parallel_chains = 4, # seed = 1234, # refresh = 1000 # ) options(mc.cores = parallel::detectCores()) model_NormalMedia &lt;- stan( file = NormalMedia, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) La estimación del parámetro \\(\\theta\\) es: # model_NormalMedia$summary(variables = &quot;theta&quot;)%&gt;% # select(variable:q95) %&gt;% tba() summary(model_NormalMedia, pars = &quot;theta&quot;)$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 13.1148 1e-04 0.0039 13.1071 13.1122 13.1147 13.1175 13.1224 694.8215 1.0002 # (mcmc_dens_chains(model_NormalMedia$draws(&quot;theta&quot;)) + # mcmc_areas(model_NormalMedia$draws(&quot;theta&quot;)))/ # mcmc_trace(model_NormalMedia$draws(&quot;theta&quot;)) posterior_theta &lt;- as.array(model_NormalMedia, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) # y_pred_B &lt;- model_NormalMedia$draws(variables = &quot;ypred&quot;, format = &quot;matrix&quot;) y_pred_B &lt;- as.array(model_NormalMedia, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(dataNormal$logIngreso), y_pred2)/ ppc_dens_overlay(y = exp(as.numeric(dataNormal$logIngreso))-1, exp(y_pred2)-1) + xlim(0,5000000) "],["modelos-multiparamétricos.html", "4.7 Modelos multiparamétricos", " 4.7 Modelos multiparamétricos La distribución normal univariada que tiene dos parámetros: la media \\(\\theta\\) y la varianza \\(\\sigma^2\\). La distribución multinomial cuyo parámetro es un vector de probabilidades \\(\\boldsymbol{\\theta}\\). "],["modelo-normal-con-media-y-varianza-desconocida.html", "4.8 Modelo Normal con media y varianza desconocida", " 4.8 Modelo Normal con media y varianza desconocida Supongamos que se dispone de realizaciones de un conjunto de variables independientes e idénticamente distribuidas \\(Y_1,\\cdots,Y_n\\sim N(\\theta,\\sigma^2)\\). Cuando se desconoce tanto la media como la varianza de la distribución es necesario plantear diversos enfoques y situarse en el más conveniente, según el contexto del problema. En términos de la asignación de las distribuciones previas para \\(\\theta\\) y \\(\\sigma^2\\) es posible: Suponer que la distribución previa \\(p(\\theta)\\) es independiente de la distribución previa \\(p(\\sigma^2)\\) y que ambas distribuciones son informativas. Suponer que la distribución previa \\(p(\\theta)\\) es independiente de la distribución previa \\(p(\\sigma^2)\\) y que ambas distribuciones son no informativas. Suponer que la distribución previa para \\(\\theta\\) depende de \\(\\sigma^2\\) y escribirla como \\(p(\\theta \\mid \\sigma^2)\\), mientras que la distribución previa de \\(\\sigma^2\\) no depende de \\(\\theta\\) y se puede escribir como \\(p(\\sigma^2)\\). "],["parámetros-independientes.html", "4.9 Parámetros independientes", " 4.9 Parámetros independientes La distribución previa para el parámetro \\(\\theta\\) será \\[ \\begin{equation*} \\theta \\sim Normal(\\mu,\\tau^2) \\end{equation*} \\] Y la distribución previa para el parámetro \\(\\sigma^2\\) será \\[ \\begin{equation*} \\sigma^2 \\sim Inversa-Gamma(n_0/2,n_0\\sigma^2_0/2) \\end{equation*} \\] Asumiendo independencia previa, la distribución previa conjunta estará dada por \\[ \\begin{equation} p(\\theta,\\sigma^2)\\propto (\\sigma^2)^{-n_0/2-1}\\exp\\left\\{-\\dfrac{n_0\\sigma^2_0}{2\\sigma^2}\\right\\} \\exp\\left\\{-\\frac{1}{2\\tau^2}(\\theta-\\mu)^2\\right\\} \\end{equation} \\] La distribución posterior conjunta de los parámetros de interés está dada por \\[ \\begin{align} p(\\theta,\\sigma^2 \\mid \\mathbf{Y})&amp;\\propto (\\sigma^2)^{-(n+n_0)/2-1} \\notag \\\\ &amp;\\times \\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left[n_0\\sigma^2_0+(n-1)S^2+n(\\bar{y}-\\theta)^2\\right]-\\frac{1}{2\\tau^2}(\\theta-\\mu)^2\\right\\} \\end{align} \\] La distribución posterior condicional de \\(\\theta\\) es \\[ \\begin{equation} \\theta \\mid \\sigma^2,\\mathbf{Y} \\sim Normal(\\mu_n,\\tau_n^2) \\end{equation} \\] En donde las expresiones para \\(\\mu_n\\) y \\(\\tau_n^2\\) están dados previamente. Por otro lado, la distribución posterior condicional de \\(\\sigma^2\\) es \\[ \\begin{equation} \\sigma^2 \\mid \\theta,\\mathbf{Y} \\sim Inversa-Gamma\\left(\\dfrac{n_0+n}{2},\\dfrac{v_0}{2}\\right) \\end{equation} \\] con \\(v_0=n_0\\sigma^2_0+(n-1)S^2+n(\\bar{y}-\\theta)^2\\). 4.9.1 Práctica en STAN Sea \\(Y\\) el logaritmo del ingreso dataNormal &lt;- encuesta %&gt;% transmute(dam_ee, logIngreso = log(ingcorte +1)) %&gt;% filter(dam_ee == &quot;08&quot;) Creando código de STAN data { int&lt;lower=0&gt; n; real y[n]; } parameters { real sigma; real theta; } transformed parameters { real sigma2; sigma2 = pow(sigma, 2); } model { y ~ normal(theta, sigma); theta ~ normal(0, 1000); sigma2 ~ inv_gamma(0.001, 0.001); } generated quantities { real ypred[n]; // vector de longitud n for(kk in 1:n){ ypred[kk] = normal_rng(theta,sigma); } } Preparando el código de STAN # file.edit(&quot;Recursos/Día1/Sesion4/Data/modelosStan/5NormalMeanVar.stan&quot;) # NormalMeanVar &lt;- cmdstan_model(stan_file = &quot;Recursos/Día1/Sesion4/Data/modelosStan/5NormalMeanVar.stan&quot;) NormalMeanVar &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/5NormalMeanVar.stan&quot; Organizando datos para STAN sample_data &lt;- list(n = nrow(dataNormal), y = dataNormal$logIngreso) Para ejecutar STAN en R tenemos la librería cmdstanr # model_NormalMedia &lt;- NormalMeanVar$sample(data = sample_data, # chains = 4, # parallel_chains = 4, # seed = 1234, # refresh = 1000) options(mc.cores = parallel::detectCores()) model_NormalMedia &lt;- stan( file = NormalMeanVar, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) La estimación del parámetro \\(\\theta\\) y \\(\\sigma^2\\) es: # model_NormalMedia$summary(variables = c(&quot;theta&quot;, &quot;sigma2&quot;, &quot;sigma&quot;)) %&gt;% # select(variable:q95) %&gt;% tba() summary(model_NormalMedia, pars = c(&quot;theta&quot;, &quot;sigma2&quot;, &quot;sigma&quot;))$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 13.1147 1e-04 0.0041 13.1067 13.1119 13.1148 13.1175 13.1226 1127.412 1.0010 sigma2 0.6987 1e-04 0.0046 0.6898 0.6955 0.6987 0.7016 0.7078 1612.814 1.0017 sigma 0.8359 1e-04 0.0028 0.8305 0.8340 0.8359 0.8376 0.8413 1613.833 1.0017 # (mcmc_dens_chains(model_NormalMedia$draws(&quot;theta&quot;)) + # mcmc_areas(model_NormalMedia$draws(&quot;theta&quot;)))/ # mcmc_trace(model_NormalMedia$draws(&quot;theta&quot;)) posterior_theta &lt;- as.array(model_NormalMedia, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) # (mcmc_dens_chains(model_NormalMedia$draws(&quot;sigma2&quot;)) + # mcmc_areas(model_NormalMedia$draws(&quot;sigma2&quot;)))/ # mcmc_trace(model_NormalMedia$draws(&quot;sigma2&quot;)) posterior_sigma2 &lt;- as.array(model_NormalMedia, pars = &quot;sigma2&quot;) (mcmc_dens_chains(posterior_sigma2) + mcmc_areas(posterior_sigma2) ) / mcmc_trace(posterior_sigma2) # (mcmc_dens_chains(model_NormalMedia$draws(&quot;sigma&quot;)) + # mcmc_areas(model_NormalMedia$draws(&quot;sigma&quot;)))/ # mcmc_trace(model_NormalMedia$draws(&quot;sigma&quot;)) posterior_sigma &lt;- as.array(model_NormalMedia, pars = &quot;sigma&quot;) (mcmc_dens_chains(posterior_sigma) + mcmc_areas(posterior_sigma) ) / mcmc_trace(posterior_sigma) # y_pred_B &lt;- model_NormalMedia$draws(variables = &quot;ypred&quot;, # format = &quot;matrix&quot;) y_pred_B &lt;- as.array(model_NormalMedia, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(exp(dataNormal$logIngreso)-1), y_pred2) + xlim(0,5000000) "],["modelo-multinomial.html", "4.10 Modelo Multinomial", " 4.10 Modelo Multinomial En esta sección discutimos el modelamiento bayesiano de datos provenientes de una distribución multinomial que corresponde a una extensión multivariada de la distribución binomial. Suponga que \\(\\textbf{Y}=(Y_1,\\ldots,Y_p)&#39;\\) es un vector aleatorio con distribución multinomial, así, su distribución está parametrizada por el vector \\(\\boldsymbol{\\theta}=(\\theta_1,\\ldots,\\theta_p)&#39;\\) y está dada por la siguiente expresión \\[ \\begin{equation} p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})=\\binom{n}{y_1,\\ldots,y_p}\\prod_{i=1}^p\\theta_i^{y_i} \\ \\ \\ \\ \\ \\theta_i&gt;0 \\texttt{ , } \\sum_{i=1}^py_i=n \\texttt{ y } \\sum_{i=1}^p\\theta_i=1 \\end{equation} \\] Donde \\[ \\begin{equation*} \\binom{n}{y_1,\\ldots,y_p}=\\frac{n!}{y_1!\\cdots y_p!}. \\end{equation*} \\] Como cada parámetro \\(\\theta_i\\) está restringido al espacio \\(\\Theta=[0,1]\\), entonces es posible asignar a la distribución de Dirichlet como la distribución previa del vector de parámetros. Por lo tanto la distribución previa del vector de parámetros \\(\\boldsymbol{\\theta}\\), parametrizada por el vector de hiperparámetros \\(\\boldsymbol{\\alpha}=(\\alpha_1,\\ldots,\\alpha_p)&#39;\\), está dada por \\[ \\begin{equation} p(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\alpha})=\\frac{\\Gamma(\\alpha_1+\\cdots+\\alpha_p)}{\\Gamma(\\alpha_1)\\cdots\\Gamma(\\alpha_p)} \\prod_{i=1}^p\\theta_i^{\\alpha_i-1} \\ \\ \\ \\ \\ \\alpha_i&gt;0 \\texttt{ y } \\sum_{i=1}^p\\theta_i=1 \\end{equation} \\] La distribución posterior del parámetro \\(\\boldsymbol{\\theta}\\) sigue una distribución \\(Dirichlet(y_1+\\alpha_1,\\ldots,y_p+\\alpha_p)\\) 4.10.1 Práctica en STAN Sea \\(Y\\) condición de actividad laboral dataMult &lt;- encuesta %&gt;% filter(condact3 %in% 1:3) %&gt;% transmute( empleo = as_factor(condact3)) %&gt;% group_by(empleo) %&gt;% tally() %&gt;% mutate(theta = n/sum(n)) tba(dataMult) empleo n theta 1 348015 0.5537 2 42045 0.0669 3 238426 0.3794 donde 1 corresponde a Ocupado, 2 son los Desocupado y 3 son Inactivo Creando código de STAN data { int&lt;lower=0&gt; k; // Número de cátegoria int y[k]; // Número de exitos vector[k] alpha; // Parámetro de las distribción previa } parameters { simplex[k] theta; } transformed parameters { real delta; // Tasa de desocupación delta = theta[2]/ (theta[2] + theta[1]); // (Desocupado)/(Desocupado + Ocupado) } model { y ~ multinomial(theta); theta ~ dirichlet(alpha); } generated quantities { int ypred[k]; ypred = multinomial_rng(theta, sum(y)); } Preparando el código de STAN # file.edit(&quot;Recursos/Día1/Sesion4/Data/modelosStan/6Multinom.stan&quot;) # Multinom &lt;- cmdstan_model(stan_file = &quot;Recursos/Día1/Sesion4/Data/modelosStan/6Multinom.stan&quot;) Multinom &lt;- &quot;Recursos/Día1/Sesion4/Data/modelosStan/6Multinom.stan&quot; Organizando datos para STAN sample_data &lt;- list(k = nrow(dataMult), y = dataMult$n, alpha = c(0.5, 0.5, 0.5)) Para ejecutar STAN en R tenemos la librería cmdstanr # model_Multinom &lt;- Multinom$sample(data = sample_data, # chains = 4, # parallel_chains = 4, # seed = 1234, # refresh = 1000) options(mc.cores = parallel::detectCores()) model_Multinom &lt;- stan( file = Multinom, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) La estimación del parámetro \\(\\theta\\) y \\(\\delta\\) es: # model_Multinom$summary(variables = c(&quot;delta&quot;, &quot;theta&quot;))%&gt;% # select(variable:q95) %&gt;% tba() summary(model_Multinom, pars = c(&quot;delta&quot;, &quot;theta&quot;))$summary %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat delta 0.1078 0 5e-04 0.1068 0.1075 0.1078 0.1082 0.1088 1097.4077 1.0019 theta[1] 0.5537 0 6e-04 0.5525 0.5533 0.5537 0.5542 0.5549 1978.4575 1.0006 theta[2] 0.0669 0 3e-04 0.0663 0.0667 0.0669 0.0671 0.0675 993.4809 1.0020 theta[3] 0.3794 0 6e-04 0.3782 0.3789 0.3794 0.3798 0.3806 1556.6998 1.0007 # (mcmc_dens_chains(model_Multinom$draws(&quot;theta[1]&quot;)) + # mcmc_areas(model_Multinom$draws(&quot;theta[1]&quot;)))/ # mcmc_trace(model_Multinom$draws(&quot;theta[1]&quot;)) posterior_theta1 &lt;- as.array(model_Multinom, pars = &quot;theta[1]&quot;) (mcmc_dens_chains(posterior_theta1) + mcmc_areas(posterior_theta1) ) / mcmc_trace(posterior_theta1) # (mcmc_dens_chains(model_Multinom$draws(&quot;theta[2]&quot;)) + # mcmc_areas(model_Multinom$draws(&quot;theta[2]&quot;)))/ # mcmc_trace(model_Multinom$draws(&quot;theta[2]&quot;)) posterior_theta2 &lt;- as.array(model_Multinom, pars = &quot;theta[2]&quot;) (mcmc_dens_chains(posterior_theta2) + mcmc_areas(posterior_theta2) ) / mcmc_trace(posterior_theta2) # (mcmc_dens_chains(model_Multinom$draws(&quot;theta[3]&quot;)) + # mcmc_areas(model_Multinom$draws(&quot;theta[3]&quot;)))/ # mcmc_trace(model_Multinom$draws(&quot;theta[3]&quot;)) posterior_theta3 &lt;- as.array(model_Multinom, pars = &quot;theta[3]&quot;) (mcmc_dens_chains(posterior_theta3) + mcmc_areas(posterior_theta3) ) / mcmc_trace(posterior_theta3) # (mcmc_dens_chains(model_Multinom$draws(&quot;delta&quot;)) + # mcmc_areas(model_Multinom$draws(&quot;delta&quot;)))/ # mcmc_trace(model_Multinom$draws(&quot;delta&quot;)) posterior_delta &lt;- as.array(model_Multinom, pars = &quot;delta&quot;) (mcmc_dens_chains(posterior_delta) + mcmc_areas(posterior_delta) ) / mcmc_trace(posterior_delta) n &lt;- nrow(dataMult) # y_pred_B &lt;- model_Multinom$draws(variables = &quot;ypred&quot;, format = &quot;matrix&quot;) y_pred_B &lt;- as.array(model_Multinom, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 50) y_pred2 &lt;- y_pred_B[, 1:n] ppc_dens_overlay(y = as.numeric(dataMult$n), y_pred2) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
